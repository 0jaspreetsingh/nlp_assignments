{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a53042f6",
      "metadata": {
        "id": "a53042f6"
      },
      "source": [
        "# Task 1: Variational autoencoder based Topic Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e739aa90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e739aa90",
        "outputId": "4ce88562-3cfb-4b4b-de9a-a56363253969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6983b0",
      "metadata": {
        "id": "be6983b0"
      },
      "source": [
        "## TODO: Import the data\n",
        "Get ten year data from the downloaded file. And display top 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "78120c43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "78120c43",
        "outputId": "526ef4d5-c08e-49dd-e06c-a0a2f264c3f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading raw data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6da67617-bd4a-41f9-ba55-e625de800402\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6da67617-bd4a-41f9-ba55-e625de800402\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading nips-papers-1987-2019-updated.zip to /content\n",
            " 98% 104M/106M [00:01<00:00, 103MB/s]  \n",
            "100% 106M/106M [00:01<00:00, 82.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "print('reading raw data...')\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload() #upload kaggle api token\n",
        "! mkdir ~/.kaggle \n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "#! kaggle datasets list\n",
        "! kaggle datasets download -d rowhitswami/nips-papers-1987-2019-updated"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/nips-papers-1987-2019-updated.zip -d train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm8p4sj25IS2",
        "outputId": "a3f5538f-41d8-4bc5-d4ff-3fd58406992c"
      },
      "id": "xm8p4sj25IS2",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/nips-papers-1987-2019-updated.zip\n",
            "  inflating: train/authors.csv       \n",
            "  inflating: train/papers.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "papers = pd.read_csv(r'/content/train/papers.csv')\n",
        "\n",
        "#taking 10 years of data from the csv\n",
        "df = papers.query('year >= 1989 and year <= 1998')\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "data = df['full_text']\n",
        "data.dropna(inplace=True)\n",
        "df.shape \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKAJRM7YlETx",
        "outputId": "cc035fef-0883-45ce-99b8-043008a0c016"
      },
      "id": "MKAJRM7YlETx",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/series.py:5258: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._update_inplace(result)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1418, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s9c3fI3plEBi"
      },
      "id": "s9c3fI3plEBi"
    },
    {
      "cell_type": "markdown",
      "id": "eff99a54",
      "metadata": {
        "id": "eff99a54"
      },
      "source": [
        "## TODO: Preprocessing\n",
        "Apply preprocessing step (such as tokenization, remove stopwords, punctuations, words with word length less than three, min\\_df/max\\_df in [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to remove term with lower/higher document frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "20fd3e7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20fd3e7d",
        "outputId": "ec564cf4-da8d-4c33-f38e-6d68732c9265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "tokens = []\n",
        "\n",
        "for sent in data:\n",
        "\n",
        "  # lower case\n",
        "  sent = sent.lower() \n",
        "\n",
        "  #remove whitespaces\n",
        "  sent_w = re.sub(r'\\b\\w{1,3}\\b', '', sent)\n",
        "\n",
        "  #remove punctuations\n",
        "  sent_p = \"\".join([char for char in sent_w if char not in string.punctuation])\n",
        "\n",
        "  #remove numbers\n",
        "  sent_n =  re.sub(r'\\d+', '', sent_p)\n",
        "\n",
        "  #tokenisation\n",
        "  words = word_tokenize(sent_n)\n",
        "\n",
        "  #remove short words\n",
        "  sent_b= ' '.join(word for word in words if len(word)>3)\n",
        "  tokens.append(sent_b)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove stopwords and remove terms with lower/higher frequency\n",
        "custom_vec = CountVectorizer( stop_words = 'english',min_df = 2,max_df = 25)\n",
        "cwm = custom_vec.fit_transform(tokens)\n",
        "print(\"Shape of Tokenizer\")\n",
        "print(cwm.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-1UHb3XlM-L",
        "outputId": "ee5acf64-ea37-413d-ba89-be330423865b"
      },
      "id": "2-1UHb3XlM-L",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Tokenizer\n",
            "(1418, 20092)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a5e271a",
      "metadata": {
        "id": "0a5e271a"
      },
      "source": [
        "## TODO: Split data\n",
        "Separate your input data into training, validation, and testing subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "28b866fe",
      "metadata": {
        "id": "28b866fe"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(custom_vec.vocabulary_)\n",
        "vocab= cwm.toarray() \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "acc25305",
      "metadata": {
        "id": "acc25305"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_dl, test_dl = train_test_split(vocab, test_size=0.2)\n",
        "\n",
        "train_dl,val_dl  = train_test_split(train_dl, test_size=0.25)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl[0].shape #first batch shape is 1d but required 2d or 3d so need to reshape the array\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt15DNTc9ewS",
        "outputId": "14519658-3740-44ba-c818-5e9c0538299a"
      },
      "id": "jt15DNTc9ewS",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20092,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7ed9c167",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ed9c167",
        "outputId": "b52dc0ea-1ee7-414a-ed44-398de4aff8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 71, 20092)\n",
            "(25, 34, 20092)\n",
            "(4, 71, 20092)\n"
          ]
        }
      ],
      "source": [
        "#code to reshape\n",
        "from pandas.core.internals.managers import new_block\n",
        "from functools import reduce\n",
        "\n",
        "def func(x,n):\n",
        "    for i in range(2,n):\n",
        "      if i*x == n:\n",
        "        return i\n",
        "        \n",
        "def update(data):\n",
        "  n =  len(data)\n",
        "\n",
        "  factor = set(reduce(list.__add__,([i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0)))\n",
        "\n",
        "  factor = list(factor)\n",
        "  factor.sort()\n",
        "\n",
        "  len_f = int(len(factor)/2)\n",
        "\n",
        "  new = func(factor[len_f],n)\n",
        "  return new, factor[len_f]\n",
        "\n",
        "new, new1 = update(test_dl)\n",
        "test_new = test_dl.reshape(new, new1, len(test_dl[0]))\n",
        "\n",
        "new, new1 = update(train_dl)\n",
        "train_new = train_dl.reshape(new, new1, len(train_dl[0]))\n",
        "\n",
        "new, new1 = update(val_dl)\n",
        "val_new = val_dl.reshape(new, new1, len(val_dl[0]))\n",
        "\n",
        "print(test_new.shape)\n",
        "print(train_new.shape)\n",
        "print(val_new.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf84212",
      "metadata": {
        "id": "3bf84212"
      },
      "source": [
        "## Gaussian VAE model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0d446783",
      "metadata": {
        "id": "0d446783"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import LogNormal, Dirichlet, Gamma, Laplace\n",
        "from torch.distributions import kl_divergence\n",
        "\n",
        "class EncoderModule(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, dropout):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_layer_one = nn.Linear(vocab_size, hidden_size[0])\n",
        "        self.linear_layer_two = nn.Linear(hidden_size[0], hidden_size[1])\n",
        "        self.linear_layer_three = nn.Linear(hidden_size[1], hidden_size[2])\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        activation = nn.LeakyReLU()\n",
        "    \n",
        "        hidden_layer_one = activation(self.linear_layer_one(inputs))\n",
        "        hidden_layer_two = self.dropout(activation(self.linear_layer_two(hidden_layer_one)))\n",
        "        hidden_layer_three = self.dropout(activation(self.linear_layer_three(hidden_layer_two)))\n",
        "        return hidden_layer_three\n",
        "\n",
        "\n",
        "class DecoderModule(nn.Module):\n",
        "    def __init__(self, vocab_size, num_topics, dropout):\n",
        "        super().__init__()\n",
        "        self.topics_to_doc = nn.Linear(num_topics, vocab_size)\n",
        "        self.batch_normalization = nn.BatchNorm1d(vocab_size, affine=False)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        log_softmax = nn.LogSoftmax(dim = 1)\n",
        "        return log_softmax(self.batch_normalization(self.topics_to_doc(inputs)))\n",
        "\n",
        "\n",
        "class EncoderToLogNormal(nn.Module):\n",
        "    def __init__(self, hidden_size, num_topics):\n",
        "        super().__init__()\n",
        "        self.linear_mean = nn.Linear(hidden_size[2], num_topics)\n",
        "        self.linear_var = nn.Linear(hidden_size[2], num_topics)\n",
        "        self.batch_norm_mean = nn.BatchNorm1d(num_topics, affine=False)\n",
        "        self.batch_norm_var = nn.BatchNorm1d(num_topics, affine=False)\n",
        "    \n",
        "    def forward(self, hidden):\n",
        "        mean = self.batch_norm_mean(self.linear_mean(hidden))\n",
        "        var = 0.5 * self.batch_norm_var(self.linear_var(hidden))\n",
        "        dist = LogNormal(mean, var.exp())\n",
        "        return dist\n",
        "        \n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_topics, dropout, model_type, beta):\n",
        "        super().__init__()\n",
        "        self.encoder = EncoderModule(vocab_size, hidden_size, dropout)\n",
        "        if model_type == 1:\n",
        "            self.encoder_to_dist = EncoderToLogNormal(hidden_size, num_topics)\n",
        "        self.decoder = DecoderModule(vocab_size, num_topics, dropout)\n",
        "        self.beta = beta\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        \n",
        "        encoder_output = self.encoder(inputs)\n",
        "        dist = self.encoder_to_dist(encoder_output)\n",
        "        if self.training:\n",
        "            dist_to_decoder = dist.rsample().to(inputs.device)\n",
        "        else:\n",
        "            dist_to_decoder = dist.mean.to(inputs.device)\n",
        "        softmax = nn.Softmax(dim = 1)\n",
        "        dist_to_decoder = softmax(dist_to_decoder)\n",
        "        reconstructed_documents = self.decoder(dist_to_decoder)\n",
        "        return reconstructed_documents, dist\n",
        "    \n",
        "    def loss(self, reconstructed, original, posterior): \n",
        "        if isinstance(posterior, LogNormal):\n",
        "            loc = torch.zeros_like(posterior.loc)\n",
        "            scale = torch.ones_like(posterior.scale)        \n",
        "            prior = LogNormal(loc, scale)\n",
        "\n",
        "        NLL = - torch.sum(reconstructed*original)\n",
        "        KLD = torch.sum(kl_divergence(posterior, prior).to(reconstructed.device))\n",
        "        loss_for_training = NLL + self.beta * KLD\n",
        "        return NLL, KLD, loss_for_training\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b95ce899",
      "metadata": {
        "id": "b95ce899"
      },
      "source": [
        "## Training Gaussian VAE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a6bc4eb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6bc4eb0",
        "outputId": "1695945c-5e41-4cf7-835c-6f804f680629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'train_loss': tensor(53262.6836), 'train_loss_nll': tensor(52583.9648), 'train_loss_kld': tensor(678.7206)}\n",
            "{'epoch': 2, 'train_loss': tensor(53106.), 'train_loss_nll': tensor(52474.7461), 'train_loss_kld': tensor(631.2589)}\n",
            "{'epoch': 3, 'train_loss': tensor(52963.7969), 'train_loss_nll': tensor(52340.3867), 'train_loss_kld': tensor(623.4064)}\n",
            "{'epoch': 4, 'train_loss': tensor(52784.6250), 'train_loss_nll': tensor(52173.8750), 'train_loss_kld': tensor(610.7527)}\n",
            "{'epoch': 5, 'train_loss': tensor(52721.7734), 'train_loss_nll': tensor(52117.7266), 'train_loss_kld': tensor(604.0503)}\n",
            "{'epoch': 6, 'train_loss': tensor(52680.6562), 'train_loss_nll': tensor(52082.1641), 'train_loss_kld': tensor(598.4908)}\n",
            "{'epoch': 7, 'train_loss': tensor(52464.7617), 'train_loss_nll': tensor(51869.8633), 'train_loss_kld': tensor(594.8963)}\n",
            "{'epoch': 8, 'train_loss': tensor(52383.6367), 'train_loss_nll': tensor(51784.2109), 'train_loss_kld': tensor(599.4254)}\n",
            "{'epoch': 9, 'train_loss': tensor(52363.5781), 'train_loss_nll': tensor(51773.6992), 'train_loss_kld': tensor(589.8860)}\n",
            "{'epoch': 10, 'train_loss': tensor(52271.1602), 'train_loss_nll': tensor(51676.0391), 'train_loss_kld': tensor(595.1204)}\n",
            "{'epoch': 11, 'train_loss': tensor(52156.8281), 'train_loss_nll': tensor(51567.2305), 'train_loss_kld': tensor(589.6004)}\n",
            "{'epoch': 12, 'train_loss': tensor(52100.9688), 'train_loss_nll': tensor(51514.1406), 'train_loss_kld': tensor(586.8233)}\n",
            "{'epoch': 13, 'train_loss': tensor(51904.7500), 'train_loss_nll': tensor(51319.0195), 'train_loss_kld': tensor(585.7261)}\n",
            "{'epoch': 14, 'train_loss': tensor(51707.4062), 'train_loss_nll': tensor(51123.8164), 'train_loss_kld': tensor(583.5898)}\n",
            "{'epoch': 15, 'train_loss': tensor(51698.4219), 'train_loss_nll': tensor(51112.3906), 'train_loss_kld': tensor(586.0341)}\n",
            "{'epoch': 16, 'train_loss': tensor(51659.7812), 'train_loss_nll': tensor(51071.1211), 'train_loss_kld': tensor(588.6660)}\n",
            "{'epoch': 17, 'train_loss': tensor(51659.4141), 'train_loss_nll': tensor(51073.5117), 'train_loss_kld': tensor(585.8992)}\n",
            "{'epoch': 18, 'train_loss': tensor(51476.3516), 'train_loss_nll': tensor(50885.2852), 'train_loss_kld': tensor(591.0664)}\n",
            "{'epoch': 19, 'train_loss': tensor(51274.7500), 'train_loss_nll': tensor(50686.5312), 'train_loss_kld': tensor(588.2237)}\n",
            "{'epoch': 20, 'train_loss': tensor(51293.7891), 'train_loss_nll': tensor(50703.7148), 'train_loss_kld': tensor(590.0703)}\n",
            "{'epoch': 21, 'train_loss': tensor(51137.3711), 'train_loss_nll': tensor(50546.8164), 'train_loss_kld': tensor(590.5464)}\n",
            "{'epoch': 22, 'train_loss': tensor(50847.6445), 'train_loss_nll': tensor(50260.9141), 'train_loss_kld': tensor(586.7344)}\n",
            "{'epoch': 23, 'train_loss': tensor(50819.3984), 'train_loss_nll': tensor(50229.9453), 'train_loss_kld': tensor(589.4503)}\n",
            "{'epoch': 24, 'train_loss': tensor(50648.0508), 'train_loss_nll': tensor(50056.8984), 'train_loss_kld': tensor(591.1517)}\n",
            "{'epoch': 25, 'train_loss': tensor(50554.7617), 'train_loss_nll': tensor(49963.7266), 'train_loss_kld': tensor(591.0316)}\n",
            "{'epoch': 26, 'train_loss': tensor(50396.0938), 'train_loss_nll': tensor(49805.3516), 'train_loss_kld': tensor(590.7411)}\n",
            "{'epoch': 27, 'train_loss': tensor(50285.3945), 'train_loss_nll': tensor(49697.1484), 'train_loss_kld': tensor(588.2385)}\n",
            "{'epoch': 28, 'train_loss': tensor(50152.4531), 'train_loss_nll': tensor(49563.3867), 'train_loss_kld': tensor(589.0714)}\n",
            "{'epoch': 29, 'train_loss': tensor(50040.6562), 'train_loss_nll': tensor(49451.8281), 'train_loss_kld': tensor(588.8274)}\n",
            "{'epoch': 30, 'train_loss': tensor(49978.4531), 'train_loss_nll': tensor(49387.3711), 'train_loss_kld': tensor(591.0822)}\n",
            "{'epoch': 31, 'train_loss': tensor(49744.1797), 'train_loss_nll': tensor(49155.8906), 'train_loss_kld': tensor(588.2872)}\n",
            "{'epoch': 32, 'train_loss': tensor(49707.4336), 'train_loss_nll': tensor(49118.3008), 'train_loss_kld': tensor(589.1291)}\n",
            "{'epoch': 33, 'train_loss': tensor(49653.1484), 'train_loss_nll': tensor(49060.1914), 'train_loss_kld': tensor(592.9656)}\n",
            "{'epoch': 34, 'train_loss': tensor(49442.6289), 'train_loss_nll': tensor(48848.3359), 'train_loss_kld': tensor(594.2990)}\n",
            "{'epoch': 35, 'train_loss': tensor(49360.1914), 'train_loss_nll': tensor(48771.0586), 'train_loss_kld': tensor(589.1269)}\n",
            "{'epoch': 36, 'train_loss': tensor(49195.7617), 'train_loss_nll': tensor(48611.2461), 'train_loss_kld': tensor(584.5127)}\n",
            "{'epoch': 37, 'train_loss': tensor(49321.7109), 'train_loss_nll': tensor(48732.4648), 'train_loss_kld': tensor(589.2474)}\n",
            "{'epoch': 38, 'train_loss': tensor(49025.2461), 'train_loss_nll': tensor(48436.2305), 'train_loss_kld': tensor(589.0173)}\n",
            "{'epoch': 39, 'train_loss': tensor(49016.7617), 'train_loss_nll': tensor(48427.6289), 'train_loss_kld': tensor(589.1324)}\n",
            "{'epoch': 40, 'train_loss': tensor(48872.1797), 'train_loss_nll': tensor(48285.6094), 'train_loss_kld': tensor(586.5673)}\n",
            "{'epoch': 41, 'train_loss': tensor(48892.2852), 'train_loss_nll': tensor(48304.7617), 'train_loss_kld': tensor(587.5233)}\n",
            "{'epoch': 42, 'train_loss': tensor(48671.2852), 'train_loss_nll': tensor(48084.9648), 'train_loss_kld': tensor(586.3195)}\n",
            "{'epoch': 43, 'train_loss': tensor(48570.8242), 'train_loss_nll': tensor(47984.1406), 'train_loss_kld': tensor(586.6806)}\n",
            "{'epoch': 44, 'train_loss': tensor(48538.4219), 'train_loss_nll': tensor(47952.9883), 'train_loss_kld': tensor(585.4297)}\n",
            "{'epoch': 45, 'train_loss': tensor(48387.9531), 'train_loss_nll': tensor(47800.9805), 'train_loss_kld': tensor(586.9789)}\n",
            "{'epoch': 46, 'train_loss': tensor(48435.8711), 'train_loss_nll': tensor(47848.0469), 'train_loss_kld': tensor(587.8240)}\n",
            "{'epoch': 47, 'train_loss': tensor(48168.0508), 'train_loss_nll': tensor(47579.5195), 'train_loss_kld': tensor(588.5304)}\n",
            "{'epoch': 48, 'train_loss': tensor(48091.3242), 'train_loss_nll': tensor(47503.8906), 'train_loss_kld': tensor(587.4353)}\n",
            "{'epoch': 49, 'train_loss': tensor(48032.5000), 'train_loss_nll': tensor(47447.7266), 'train_loss_kld': tensor(584.7732)}\n",
            "{'epoch': 50, 'train_loss': tensor(47846.8008), 'train_loss_nll': tensor(47259.6289), 'train_loss_kld': tensor(587.1696)}\n",
            "{'epoch': 51, 'train_loss': tensor(47823.4336), 'train_loss_nll': tensor(47236.9219), 'train_loss_kld': tensor(586.5132)}\n",
            "{'epoch': 52, 'train_loss': tensor(47795.0781), 'train_loss_nll': tensor(47208.9805), 'train_loss_kld': tensor(586.1009)}\n",
            "{'epoch': 53, 'train_loss': tensor(47828.9219), 'train_loss_nll': tensor(47242.0195), 'train_loss_kld': tensor(586.9019)}\n",
            "{'epoch': 54, 'train_loss': tensor(47766.1992), 'train_loss_nll': tensor(47180.4414), 'train_loss_kld': tensor(585.7645)}\n",
            "{'epoch': 55, 'train_loss': tensor(47746.0117), 'train_loss_nll': tensor(47159.6797), 'train_loss_kld': tensor(586.3306)}\n",
            "{'epoch': 56, 'train_loss': tensor(47518.0938), 'train_loss_nll': tensor(46934.5547), 'train_loss_kld': tensor(583.5367)}\n",
            "{'epoch': 57, 'train_loss': tensor(47416.9844), 'train_loss_nll': tensor(46831.8867), 'train_loss_kld': tensor(585.1041)}\n",
            "{'epoch': 58, 'train_loss': tensor(47401.9531), 'train_loss_nll': tensor(46817.7305), 'train_loss_kld': tensor(584.2249)}\n",
            "{'epoch': 59, 'train_loss': tensor(47308.1992), 'train_loss_nll': tensor(46724.1367), 'train_loss_kld': tensor(584.0650)}\n",
            "{'epoch': 60, 'train_loss': tensor(47335.6953), 'train_loss_nll': tensor(46751.2656), 'train_loss_kld': tensor(584.4304)}\n",
            "{'epoch': 61, 'train_loss': tensor(47290.6016), 'train_loss_nll': tensor(46709.0547), 'train_loss_kld': tensor(581.5469)}\n",
            "{'epoch': 62, 'train_loss': tensor(47183.2852), 'train_loss_nll': tensor(46602.3789), 'train_loss_kld': tensor(580.9050)}\n",
            "{'epoch': 63, 'train_loss': tensor(46994.5938), 'train_loss_nll': tensor(46411.8281), 'train_loss_kld': tensor(582.7733)}\n",
            "{'epoch': 64, 'train_loss': tensor(47024.2188), 'train_loss_nll': tensor(46443.2891), 'train_loss_kld': tensor(580.9302)}\n",
            "{'epoch': 65, 'train_loss': tensor(46902.5117), 'train_loss_nll': tensor(46320.4336), 'train_loss_kld': tensor(582.0743)}\n",
            "{'epoch': 66, 'train_loss': tensor(47082.0312), 'train_loss_nll': tensor(46500.9453), 'train_loss_kld': tensor(581.0839)}\n",
            "{'epoch': 67, 'train_loss': tensor(47013.6953), 'train_loss_nll': tensor(46433.5117), 'train_loss_kld': tensor(580.1795)}\n",
            "{'epoch': 68, 'train_loss': tensor(46970.7031), 'train_loss_nll': tensor(46392.5508), 'train_loss_kld': tensor(578.1572)}\n",
            "{'epoch': 69, 'train_loss': tensor(47015.8164), 'train_loss_nll': tensor(46436.1484), 'train_loss_kld': tensor(579.6603)}\n",
            "{'epoch': 70, 'train_loss': tensor(46765.6836), 'train_loss_nll': tensor(46186.9844), 'train_loss_kld': tensor(578.7000)}\n",
            "{'epoch': 71, 'train_loss': tensor(46608.4961), 'train_loss_nll': tensor(46033.0703), 'train_loss_kld': tensor(575.4219)}\n",
            "{'epoch': 72, 'train_loss': tensor(46781.3789), 'train_loss_nll': tensor(46202.9062), 'train_loss_kld': tensor(578.4725)}\n",
            "{'epoch': 73, 'train_loss': tensor(46527.0195), 'train_loss_nll': tensor(45949.7383), 'train_loss_kld': tensor(577.2815)}\n",
            "{'epoch': 74, 'train_loss': tensor(46487.0312), 'train_loss_nll': tensor(45909.9219), 'train_loss_kld': tensor(577.1079)}\n",
            "{'epoch': 75, 'train_loss': tensor(46449.4219), 'train_loss_nll': tensor(45871.9805), 'train_loss_kld': tensor(577.4420)}\n",
            "{'epoch': 76, 'train_loss': tensor(46482.5352), 'train_loss_nll': tensor(45903.5039), 'train_loss_kld': tensor(579.0347)}\n",
            "{'epoch': 77, 'train_loss': tensor(46465.5039), 'train_loss_nll': tensor(45885.0195), 'train_loss_kld': tensor(580.4804)}\n",
            "{'epoch': 78, 'train_loss': tensor(46441.7031), 'train_loss_nll': tensor(45863.4102), 'train_loss_kld': tensor(578.2971)}\n",
            "{'epoch': 79, 'train_loss': tensor(46459.4648), 'train_loss_nll': tensor(45883.2539), 'train_loss_kld': tensor(576.2151)}\n",
            "{'epoch': 80, 'train_loss': tensor(46451.4688), 'train_loss_nll': tensor(45872.1719), 'train_loss_kld': tensor(579.2979)}\n",
            "{'epoch': 81, 'train_loss': tensor(46391.4336), 'train_loss_nll': tensor(45812.9219), 'train_loss_kld': tensor(578.5205)}\n",
            "{'epoch': 82, 'train_loss': tensor(46369.0859), 'train_loss_nll': tensor(45790.9688), 'train_loss_kld': tensor(578.1194)}\n",
            "{'epoch': 83, 'train_loss': tensor(46340.6602), 'train_loss_nll': tensor(45761.6914), 'train_loss_kld': tensor(578.9701)}\n",
            "{'epoch': 84, 'train_loss': tensor(46338.3984), 'train_loss_nll': tensor(45760.1641), 'train_loss_kld': tensor(578.2406)}\n",
            "{'epoch': 85, 'train_loss': tensor(46301.4492), 'train_loss_nll': tensor(45726.), 'train_loss_kld': tensor(575.4441)}\n",
            "{'epoch': 86, 'train_loss': tensor(46271.4844), 'train_loss_nll': tensor(45696.4414), 'train_loss_kld': tensor(575.0452)}\n",
            "{'epoch': 87, 'train_loss': tensor(46069.7969), 'train_loss_nll': tensor(45494.0039), 'train_loss_kld': tensor(575.7919)}\n",
            "{'epoch': 88, 'train_loss': tensor(46080.8281), 'train_loss_nll': tensor(45504.1406), 'train_loss_kld': tensor(576.6904)}\n",
            "{'epoch': 89, 'train_loss': tensor(46186.4688), 'train_loss_nll': tensor(45615.4648), 'train_loss_kld': tensor(571.0004)}\n",
            "{'epoch': 90, 'train_loss': tensor(46024.7383), 'train_loss_nll': tensor(45451.6367), 'train_loss_kld': tensor(573.1093)}\n",
            "{'epoch': 91, 'train_loss': tensor(46321.0508), 'train_loss_nll': tensor(45745.4492), 'train_loss_kld': tensor(575.5984)}\n",
            "{'epoch': 92, 'train_loss': tensor(46183.8086), 'train_loss_nll': tensor(45609.4648), 'train_loss_kld': tensor(574.3464)}\n",
            "{'epoch': 93, 'train_loss': tensor(46272.6289), 'train_loss_nll': tensor(45683.0703), 'train_loss_kld': tensor(589.5546)}\n",
            "{'epoch': 94, 'train_loss': tensor(46438.3984), 'train_loss_nll': tensor(45834.8398), 'train_loss_kld': tensor(603.5571)}\n",
            "{'epoch': 95, 'train_loss': tensor(46526.1211), 'train_loss_nll': tensor(45924.2461), 'train_loss_kld': tensor(601.8745)}\n",
            "{'epoch': 96, 'train_loss': tensor(46379.6797), 'train_loss_nll': tensor(45783.3164), 'train_loss_kld': tensor(596.3679)}\n",
            "{'epoch': 97, 'train_loss': tensor(46335.1797), 'train_loss_nll': tensor(45744.6289), 'train_loss_kld': tensor(590.5500)}\n",
            "{'epoch': 98, 'train_loss': tensor(46116.8359), 'train_loss_nll': tensor(45529.3750), 'train_loss_kld': tensor(587.4606)}\n",
            "{'epoch': 99, 'train_loss': tensor(46055.8242), 'train_loss_nll': tensor(45468.3164), 'train_loss_kld': tensor(587.5123)}\n",
            "{'epoch': 100, 'train_loss': tensor(45872.3945), 'train_loss_nll': tensor(45284.6367), 'train_loss_kld': tensor(587.7611)}\n",
            "{'epoch': 101, 'train_loss': tensor(45807.3203), 'train_loss_nll': tensor(45219.8008), 'train_loss_kld': tensor(587.5229)}\n",
            "{'epoch': 102, 'train_loss': tensor(45663.9805), 'train_loss_nll': tensor(45078.7031), 'train_loss_kld': tensor(585.2733)}\n",
            "{'epoch': 103, 'train_loss': tensor(45815.8086), 'train_loss_nll': tensor(45234.6992), 'train_loss_kld': tensor(581.1149)}\n",
            "{'epoch': 104, 'train_loss': tensor(45916.7031), 'train_loss_nll': tensor(45335.2109), 'train_loss_kld': tensor(581.4907)}\n",
            "{'epoch': 105, 'train_loss': tensor(45613.9297), 'train_loss_nll': tensor(45032.2383), 'train_loss_kld': tensor(581.6915)}\n",
            "{'epoch': 106, 'train_loss': tensor(45768.3242), 'train_loss_nll': tensor(45186.8398), 'train_loss_kld': tensor(581.4814)}\n",
            "{'epoch': 107, 'train_loss': tensor(45953.7539), 'train_loss_nll': tensor(45368.9688), 'train_loss_kld': tensor(584.7872)}\n",
            "{'epoch': 108, 'train_loss': tensor(45911.4336), 'train_loss_nll': tensor(45327.7734), 'train_loss_kld': tensor(583.6544)}\n",
            "{'epoch': 109, 'train_loss': tensor(45885.4336), 'train_loss_nll': tensor(45301.7539), 'train_loss_kld': tensor(583.6816)}\n",
            "{'epoch': 110, 'train_loss': tensor(45733.8164), 'train_loss_nll': tensor(45149.9336), 'train_loss_kld': tensor(583.8791)}\n",
            "{'epoch': 111, 'train_loss': tensor(45695.1289), 'train_loss_nll': tensor(45110.7891), 'train_loss_kld': tensor(584.3411)}\n",
            "{'epoch': 112, 'train_loss': tensor(45687.9297), 'train_loss_nll': tensor(45103.1914), 'train_loss_kld': tensor(584.7361)}\n",
            "{'epoch': 113, 'train_loss': tensor(45668.7031), 'train_loss_nll': tensor(45084.6641), 'train_loss_kld': tensor(584.0407)}\n",
            "{'epoch': 114, 'train_loss': tensor(45548.4766), 'train_loss_nll': tensor(44967.3555), 'train_loss_kld': tensor(581.1231)}\n",
            "{'epoch': 115, 'train_loss': tensor(45704.0312), 'train_loss_nll': tensor(45119.5156), 'train_loss_kld': tensor(584.5151)}\n",
            "{'epoch': 116, 'train_loss': tensor(45675.7344), 'train_loss_nll': tensor(45093.0664), 'train_loss_kld': tensor(582.6725)}\n",
            "{'epoch': 117, 'train_loss': tensor(45539.9258), 'train_loss_nll': tensor(44959.1406), 'train_loss_kld': tensor(580.7849)}\n",
            "{'epoch': 118, 'train_loss': tensor(45578.6133), 'train_loss_nll': tensor(44994.5703), 'train_loss_kld': tensor(584.0454)}\n",
            "{'epoch': 119, 'train_loss': tensor(45639.0859), 'train_loss_nll': tensor(45049.3711), 'train_loss_kld': tensor(589.7089)}\n",
            "{'epoch': 120, 'train_loss': tensor(45467.9805), 'train_loss_nll': tensor(44887.9453), 'train_loss_kld': tensor(580.0407)}\n",
            "{'epoch': 121, 'train_loss': tensor(45670.9531), 'train_loss_nll': tensor(45092.4453), 'train_loss_kld': tensor(578.5153)}\n",
            "{'epoch': 122, 'train_loss': tensor(45486.8750), 'train_loss_nll': tensor(44909.5859), 'train_loss_kld': tensor(577.2889)}\n",
            "{'epoch': 123, 'train_loss': tensor(45241.9688), 'train_loss_nll': tensor(44661.3281), 'train_loss_kld': tensor(580.6390)}\n",
            "{'epoch': 124, 'train_loss': tensor(45332.2109), 'train_loss_nll': tensor(44752.1992), 'train_loss_kld': tensor(580.0085)}\n",
            "{'epoch': 125, 'train_loss': tensor(45377.2109), 'train_loss_nll': tensor(44800.1562), 'train_loss_kld': tensor(577.0563)}\n",
            "{'epoch': 126, 'train_loss': tensor(45586.4141), 'train_loss_nll': tensor(45000.7734), 'train_loss_kld': tensor(585.6381)}\n",
            "{'epoch': 127, 'train_loss': tensor(45716.3086), 'train_loss_nll': tensor(45128.4844), 'train_loss_kld': tensor(587.8232)}\n",
            "{'epoch': 128, 'train_loss': tensor(45572.5195), 'train_loss_nll': tensor(44985.2188), 'train_loss_kld': tensor(587.2991)}\n",
            "{'epoch': 129, 'train_loss': tensor(45402.1641), 'train_loss_nll': tensor(44820.6719), 'train_loss_kld': tensor(581.4914)}\n",
            "{'epoch': 130, 'train_loss': tensor(45597.2305), 'train_loss_nll': tensor(45015.6406), 'train_loss_kld': tensor(581.5895)}\n",
            "{'epoch': 131, 'train_loss': tensor(45309.3008), 'train_loss_nll': tensor(44732.3750), 'train_loss_kld': tensor(576.9237)}\n",
            "{'epoch': 132, 'train_loss': tensor(45578.0703), 'train_loss_nll': tensor(45000.2656), 'train_loss_kld': tensor(577.8108)}\n",
            "{'epoch': 133, 'train_loss': tensor(45371.7812), 'train_loss_nll': tensor(44794.8711), 'train_loss_kld': tensor(576.9123)}\n",
            "{'epoch': 134, 'train_loss': tensor(45250.6914), 'train_loss_nll': tensor(44676.1289), 'train_loss_kld': tensor(574.5596)}\n",
            "{'epoch': 135, 'train_loss': tensor(45436.7969), 'train_loss_nll': tensor(44863.0312), 'train_loss_kld': tensor(573.7606)}\n",
            "{'epoch': 136, 'train_loss': tensor(45229.0508), 'train_loss_nll': tensor(44653.9766), 'train_loss_kld': tensor(575.0756)}\n",
            "{'epoch': 137, 'train_loss': tensor(45284.0312), 'train_loss_nll': tensor(44711.7852), 'train_loss_kld': tensor(572.2444)}\n",
            "{'epoch': 138, 'train_loss': tensor(45358.8945), 'train_loss_nll': tensor(44787.2969), 'train_loss_kld': tensor(571.5977)}\n",
            "{'epoch': 139, 'train_loss': tensor(45292.1094), 'train_loss_nll': tensor(44718.3398), 'train_loss_kld': tensor(573.7720)}\n",
            "{'epoch': 140, 'train_loss': tensor(45244.4141), 'train_loss_nll': tensor(44673.3242), 'train_loss_kld': tensor(571.0906)}\n",
            "{'epoch': 141, 'train_loss': tensor(45081.9688), 'train_loss_nll': tensor(44511.4609), 'train_loss_kld': tensor(570.5026)}\n",
            "{'epoch': 142, 'train_loss': tensor(45174.4648), 'train_loss_nll': tensor(44603.4766), 'train_loss_kld': tensor(570.9922)}\n",
            "{'epoch': 143, 'train_loss': tensor(45158.1484), 'train_loss_nll': tensor(44585.7148), 'train_loss_kld': tensor(572.4341)}\n",
            "{'epoch': 144, 'train_loss': tensor(45142.9648), 'train_loss_nll': tensor(44570.8984), 'train_loss_kld': tensor(572.0677)}\n",
            "{'epoch': 145, 'train_loss': tensor(45156.6211), 'train_loss_nll': tensor(44585.3008), 'train_loss_kld': tensor(571.3171)}\n",
            "{'epoch': 146, 'train_loss': tensor(45115.4648), 'train_loss_nll': tensor(44542.3047), 'train_loss_kld': tensor(573.1584)}\n",
            "{'epoch': 147, 'train_loss': tensor(45079.5234), 'train_loss_nll': tensor(44507.3047), 'train_loss_kld': tensor(572.2188)}\n",
            "{'epoch': 148, 'train_loss': tensor(45093.6094), 'train_loss_nll': tensor(44519.8945), 'train_loss_kld': tensor(573.7164)}\n",
            "{'epoch': 149, 'train_loss': tensor(45146.1836), 'train_loss_nll': tensor(44574.7109), 'train_loss_kld': tensor(571.4753)}\n",
            "{'epoch': 150, 'train_loss': tensor(45181.4219), 'train_loss_nll': tensor(44609.7695), 'train_loss_kld': tensor(571.6514)}\n",
            "{'epoch': 151, 'train_loss': tensor(45169.4258), 'train_loss_nll': tensor(44596.5000), 'train_loss_kld': tensor(572.9238)}\n",
            "{'epoch': 152, 'train_loss': tensor(45232.4414), 'train_loss_nll': tensor(44663.3516), 'train_loss_kld': tensor(569.0902)}\n",
            "{'epoch': 153, 'train_loss': tensor(45265.2031), 'train_loss_nll': tensor(44693.4766), 'train_loss_kld': tensor(571.7318)}\n",
            "{'epoch': 154, 'train_loss': tensor(45327.6367), 'train_loss_nll': tensor(44757.4883), 'train_loss_kld': tensor(570.1487)}\n",
            "{'epoch': 155, 'train_loss': tensor(45116.), 'train_loss_nll': tensor(44545.4219), 'train_loss_kld': tensor(570.5772)}\n",
            "{'epoch': 156, 'train_loss': tensor(45168.6055), 'train_loss_nll': tensor(44596.8945), 'train_loss_kld': tensor(571.7095)}\n",
            "{'epoch': 157, 'train_loss': tensor(45136.9492), 'train_loss_nll': tensor(44565.2383), 'train_loss_kld': tensor(571.7087)}\n",
            "{'epoch': 158, 'train_loss': tensor(45143.3008), 'train_loss_nll': tensor(44570.8086), 'train_loss_kld': tensor(572.4944)}\n",
            "{'epoch': 159, 'train_loss': tensor(45212.0156), 'train_loss_nll': tensor(44642.5586), 'train_loss_kld': tensor(569.4592)}\n",
            "{'epoch': 160, 'train_loss': tensor(45020.7344), 'train_loss_nll': tensor(44450.5469), 'train_loss_kld': tensor(570.1888)}\n",
            "{'epoch': 161, 'train_loss': tensor(44947.2148), 'train_loss_nll': tensor(44376.2031), 'train_loss_kld': tensor(571.0095)}\n",
            "{'epoch': 162, 'train_loss': tensor(45108.1719), 'train_loss_nll': tensor(44540.8242), 'train_loss_kld': tensor(567.3427)}\n",
            "{'epoch': 163, 'train_loss': tensor(44960.0312), 'train_loss_nll': tensor(44387.7812), 'train_loss_kld': tensor(572.2502)}\n",
            "{'epoch': 164, 'train_loss': tensor(44937.8359), 'train_loss_nll': tensor(44367.0234), 'train_loss_kld': tensor(570.8127)}\n",
            "{'epoch': 165, 'train_loss': tensor(44996.9219), 'train_loss_nll': tensor(44427.2109), 'train_loss_kld': tensor(569.7127)}\n",
            "{'epoch': 166, 'train_loss': tensor(44887.8906), 'train_loss_nll': tensor(44319.3008), 'train_loss_kld': tensor(568.5835)}\n",
            "{'epoch': 167, 'train_loss': tensor(45147.4414), 'train_loss_nll': tensor(44578.4609), 'train_loss_kld': tensor(568.9803)}\n",
            "{'epoch': 168, 'train_loss': tensor(44829.5195), 'train_loss_nll': tensor(44262.5352), 'train_loss_kld': tensor(566.9867)}\n",
            "{'epoch': 169, 'train_loss': tensor(45097.0391), 'train_loss_nll': tensor(44529.3867), 'train_loss_kld': tensor(567.6609)}\n",
            "{'epoch': 170, 'train_loss': tensor(44934.1953), 'train_loss_nll': tensor(44368.1602), 'train_loss_kld': tensor(566.0316)}\n",
            "{'epoch': 171, 'train_loss': tensor(44872.1406), 'train_loss_nll': tensor(44306.9805), 'train_loss_kld': tensor(565.1646)}\n",
            "{'epoch': 172, 'train_loss': tensor(44988.), 'train_loss_nll': tensor(44424.1016), 'train_loss_kld': tensor(563.8980)}\n",
            "{'epoch': 173, 'train_loss': tensor(44879.1719), 'train_loss_nll': tensor(44315.8086), 'train_loss_kld': tensor(563.3572)}\n",
            "{'epoch': 174, 'train_loss': tensor(45054.3086), 'train_loss_nll': tensor(44490.1094), 'train_loss_kld': tensor(564.2026)}\n",
            "{'epoch': 175, 'train_loss': tensor(44899.9688), 'train_loss_nll': tensor(44337.6719), 'train_loss_kld': tensor(562.2938)}\n",
            "{'epoch': 176, 'train_loss': tensor(45060.5508), 'train_loss_nll': tensor(44492.6094), 'train_loss_kld': tensor(567.9424)}\n",
            "{'epoch': 177, 'train_loss': tensor(44991.), 'train_loss_nll': tensor(44423.6602), 'train_loss_kld': tensor(567.3464)}\n",
            "{'epoch': 178, 'train_loss': tensor(44978.4297), 'train_loss_nll': tensor(44413.0234), 'train_loss_kld': tensor(565.4017)}\n",
            "{'epoch': 179, 'train_loss': tensor(44903.6836), 'train_loss_nll': tensor(44337.3086), 'train_loss_kld': tensor(566.3723)}\n",
            "{'epoch': 180, 'train_loss': tensor(45175.5352), 'train_loss_nll': tensor(44609.4648), 'train_loss_kld': tensor(566.0743)}\n",
            "{'epoch': 181, 'train_loss': tensor(44923.2383), 'train_loss_nll': tensor(44357.8203), 'train_loss_kld': tensor(565.4171)}\n",
            "{'epoch': 182, 'train_loss': tensor(45008.7969), 'train_loss_nll': tensor(44441.4805), 'train_loss_kld': tensor(567.3130)}\n",
            "{'epoch': 183, 'train_loss': tensor(44903.1445), 'train_loss_nll': tensor(44335.5195), 'train_loss_kld': tensor(567.6301)}\n",
            "{'epoch': 184, 'train_loss': tensor(44967.7617), 'train_loss_nll': tensor(44403.4805), 'train_loss_kld': tensor(564.2775)}\n",
            "{'epoch': 185, 'train_loss': tensor(44787.3711), 'train_loss_nll': tensor(44226.6758), 'train_loss_kld': tensor(560.6922)}\n",
            "{'epoch': 186, 'train_loss': tensor(44934.6836), 'train_loss_nll': tensor(44371.1797), 'train_loss_kld': tensor(563.5015)}\n",
            "{'epoch': 187, 'train_loss': tensor(44946.7344), 'train_loss_nll': tensor(44386.6914), 'train_loss_kld': tensor(560.0414)}\n",
            "{'epoch': 188, 'train_loss': tensor(45027.7656), 'train_loss_nll': tensor(44465.4688), 'train_loss_kld': tensor(562.2963)}\n",
            "{'epoch': 189, 'train_loss': tensor(45072.5898), 'train_loss_nll': tensor(44505.8008), 'train_loss_kld': tensor(566.7873)}\n",
            "{'epoch': 190, 'train_loss': tensor(44766.1641), 'train_loss_nll': tensor(44202.5859), 'train_loss_kld': tensor(563.5769)}\n",
            "{'epoch': 191, 'train_loss': tensor(44841.2031), 'train_loss_nll': tensor(44276.4766), 'train_loss_kld': tensor(564.7290)}\n",
            "{'epoch': 192, 'train_loss': tensor(44930.4297), 'train_loss_nll': tensor(44365.9062), 'train_loss_kld': tensor(564.5249)}\n",
            "{'epoch': 193, 'train_loss': tensor(44808.0586), 'train_loss_nll': tensor(44242.4844), 'train_loss_kld': tensor(565.5728)}\n",
            "{'epoch': 194, 'train_loss': tensor(44776.1250), 'train_loss_nll': tensor(44209.9648), 'train_loss_kld': tensor(566.1590)}\n",
            "{'epoch': 195, 'train_loss': tensor(44816.2891), 'train_loss_nll': tensor(44247.8086), 'train_loss_kld': tensor(568.4841)}\n",
            "{'epoch': 196, 'train_loss': tensor(44833.5703), 'train_loss_nll': tensor(44265.4219), 'train_loss_kld': tensor(568.1524)}\n",
            "{'epoch': 197, 'train_loss': tensor(45104.2109), 'train_loss_nll': tensor(44536.7539), 'train_loss_kld': tensor(567.4570)}\n",
            "{'epoch': 198, 'train_loss': tensor(45002.8086), 'train_loss_nll': tensor(44434.8867), 'train_loss_kld': tensor(567.9261)}\n",
            "{'epoch': 199, 'train_loss': tensor(44967.8750), 'train_loss_nll': tensor(44397.8281), 'train_loss_kld': tensor(570.0475)}\n",
            "{'epoch': 200, 'train_loss': tensor(45073.1094), 'train_loss_nll': tensor(44502.1914), 'train_loss_kld': tensor(570.9185)}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def train_one_epoch(train_dl, model, optim, device):\n",
        "    model.train()\n",
        "    epoch_total_loss, epoch_nll_loss, epoch_kld_loss = [], [], []\n",
        "    for batch in train_dl:\n",
        "        batch_total_loss, batch_nll_loss, batch_kld_loss = train_one_batch(batch, model, optim, device)\n",
        "        epoch_total_loss.append(batch_total_loss), epoch_nll_loss.append(batch_nll_loss), epoch_kld_loss.append(batch_kld_loss)\n",
        "    loss ={'total_loss': torch.mean(torch.Tensor(epoch_total_loss)), 'nll_loss': torch.mean(torch.Tensor(epoch_nll_loss)), 'kld_loss': torch.mean(torch.Tensor(epoch_kld_loss))}\n",
        "    return loss\n",
        "\n",
        "def train_one_batch(batch, model, optim, device):\n",
        "    docs = torch.from_numpy(batch.astype(np.float32)).to(torch.device(device))\n",
        "    optim.zero_grad()\n",
        "    out, posterior = model(docs)\n",
        "    nll, kld, loss_for_training = model.loss(out, docs, posterior)\n",
        "    loss = nll + kld\n",
        "    loss_for_training.backward()\n",
        "    optim.step()\n",
        "    return loss.item(), nll.item(), kld.item()\n",
        "\n",
        "def validate_one_epoch(val_dl, model, device):\n",
        "    model.eval()\n",
        "    epoch_total_loss, epoch_nll_loss, epoch_kld_loss = [], [], []\n",
        "    for batch in val_dl:\n",
        "        batch_total_loss, batch_nll_loss, batch_kld_loss = validate_one_batch(batch, model, device)\n",
        "        epoch_total_loss.append(batch_total_loss), epoch_nll_loss.append(batch_nll_loss), epoch_kld_loss.append(batch_kld_loss)\n",
        "    loss ={'total_loss': torch.mean(torch.Tensor(epoch_total_loss)), 'nll_loss': torch.mean(torch.Tensor(epoch_nll_loss)), 'kld_loss': torch.mean(torch.Tensor(epoch_kld_loss))}\n",
        "    return loss\n",
        "\n",
        "def validate_one_batch(batch, model, device):\n",
        "    docs = torch.from_numpy(batch.astype(np.float32)).to(torch.device(device))\n",
        "    out, posterior = model(docs)\n",
        "    nll, kld, _ = model.loss(out, docs, posterior)\n",
        "    loss = nll + kld\n",
        "    return loss.item(), nll.item(), kld.item()\n",
        "\n",
        "def fit(epochs, train_dl, val_dl, model, optim, device, path, writer):\n",
        "    history = []\n",
        "    for epoch in range(epochs):\n",
        "        epoch_train_loss = train_one_epoch(train_dl, model, optim, device)\n",
        "        epoch_validation_loss = validate_one_epoch(val_dl, model, device)\n",
        "        writer.add_scalar(\"Loss/train\", epoch_train_loss['total_loss'], epoch)\n",
        "        writer.add_scalar(\"Loss/eval\", epoch_validation_loss['total_loss'], epoch)\n",
        "        log = {\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': epoch_train_loss['total_loss'],\n",
        "                'train_loss_nll': epoch_train_loss['nll_loss'],\n",
        "                'train_loss_kld': epoch_train_loss['kld_loss'],\n",
        "            }\n",
        "        history.append(log)\n",
        "        print(log)\n",
        "    beta = model.decoder.topics_to_doc.weight.cpu().detach().T\n",
        "    return beta, history\n",
        "\n",
        "torch.manual_seed(3)\n",
        "hidden_size = [512, 256, 128]\n",
        "num_topics = 25\n",
        "dropout = 0.2\n",
        "epochs = 200\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Declaring model and optimizer\n",
        "model = VAE(vocab_size, hidden_size, num_topics, dropout, 1, 3)\n",
        "model = model.to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "path = '/content'\n",
        "writer = SummaryWriter()\n",
        "\n",
        "# Run, trainings\n",
        "beta, history = fit(epochs, train_new, val_new, model, optim,device,path,writer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af0e9257",
      "metadata": {
        "id": "af0e9257"
      },
      "source": [
        "## TODO: Implement Dirichlet VAE\n",
        "Use Gaussian VAE model as reference which is given above and implement Dirichlet VAE by using Dirichlet distribution as a prior on the latent variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0879f247",
      "metadata": {
        "id": "0879f247"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import LogNormal, Dirichlet, Gamma, Laplace\n",
        "from torch.distributions import kl_divergence\n",
        "import tensorflow as tf\n",
        "\n",
        "def prior(K, alpha):\n",
        "    \"\"\"\n",
        "    Prior for the model.\n",
        "    :K: number of categories\n",
        "    :alpha: Hyper param of Dir\n",
        "    :return: mean and variance tensors\n",
        "    \"\"\"\n",
        "    # Approximate to normal distribution using Laplace approximation\n",
        "    a = torch.Tensor(1, K).float().fill_(alpha)\n",
        "    mean = a.log().t() - a.log().mean(1)\n",
        "    var = ((1 - 2.0 / K) * a.reciprocal()).t() + (1.0 / K ** 2) * a.reciprocal().sum(1)\n",
        "    return mean.t(), var.t() # Parameters of prior distribution after approximation\n",
        "\n",
        "\n",
        "class EncoderModule(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, dropout):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_layer_one = nn.Linear(vocab_size, hidden_size[0])\n",
        "        self.linear_layer_two = nn.Linear(hidden_size[0], hidden_size[1])\n",
        "        self.linear_layer_three = nn.Linear(hidden_size[1], hidden_size[2])\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        activation = nn.LeakyReLU()\n",
        "    \n",
        "        hidden_layer_one = activation(self.linear_layer_one(inputs))\n",
        "        hidden_layer_two = self.dropout(activation(self.linear_layer_two(hidden_layer_one)))\n",
        "        hidden_layer_three = self.dropout(activation(self.linear_layer_three(hidden_layer_two)))\n",
        "        return hidden_layer_three\n",
        "\n",
        "\n",
        "class DecoderModule(nn.Module):\n",
        "    def __init__(self, vocab_size, num_topics, dropout):\n",
        "        super().__init__()\n",
        "        self.topics_to_doc = nn.Linear(num_topics, vocab_size)\n",
        "        self.batch_normalization = nn.BatchNorm1d(vocab_size, affine=False)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        log_softmax = nn.LogSoftmax(dim = 1)\n",
        "        return log_softmax(self.batch_normalization(self.topics_to_doc(inputs)))\n",
        "\n",
        "\n",
        "class EncoderToLogNormal(nn.Module):\n",
        "    def __init__(self, hidden_size, num_topics,alpha):\n",
        "        super().__init__()\n",
        "        self.linear_mean = nn.Linear(hidden_size[2], num_topics)\n",
        "        self.linear_var = nn.Linear(hidden_size[2], num_topics)\n",
        "        self.batch_norm_mean = nn.BatchNorm1d(num_topics, affine=False)\n",
        "        self.batch_norm_var = nn.BatchNorm1d(num_topics, affine=False)\n",
        "    \n",
        "    def forward(self, hidden):\n",
        "        self.prior_mean, self.prior_var = map(nn.Parameter, prior(num_topics, alpha))\n",
        "        #print('new aplpha' +alpha+) # 0.3 is a hyper param of Dirichlet distribution\n",
        "        self.prior_logvar = nn.Parameter(self.prior_var.log())\n",
        "        self.prior_mean.requires_grad = False\n",
        "        self.prior_var.requires_grad = False\n",
        "        self.prior_logvar.requires_grad = False\n",
        "        dist = LogNormal(self.prior_mean, self.prior_var.exp())\n",
        "        return dist\n",
        "\n",
        "class VAE1(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_topics, dropout, model_type, beta,alpha):\n",
        "        super().__init__()\n",
        "        self.encoder = EncoderModule(vocab_size, hidden_size, dropout)\n",
        "        if model_type == 1:\n",
        "            self.encoder_to_dist = EncoderToLogNormal(hidden_size, num_topics,alpha)\n",
        "        self.decoder = DecoderModule(vocab_size, num_topics, dropout)\n",
        "        self.beta = beta\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        \n",
        "        encoder_output = self.encoder(inputs)\n",
        "        dist = self.encoder_to_dist(encoder_output)\n",
        "        if self.training:\n",
        "            dist_to_decoder = dist.rsample().to(inputs.device)\n",
        "        else:\n",
        "            dist_to_decoder = dist.mean.to(inputs.device)\n",
        "        softmax = nn.Softmax(dim = 1)\n",
        "        dist_to_decoder = softmax(dist_to_decoder)\n",
        "        reconstructed_documents = self.decoder(dist_to_decoder)\n",
        "        return reconstructed_documents, dist\n",
        "    \n",
        "    def loss(self, reconstructed, original, posterior): \n",
        "        if isinstance(posterior, LogNormal):\n",
        "            loc = torch.zeros_like(posterior.loc)\n",
        "            scale = torch.ones_like(posterior.scale)        \n",
        "            prior = LogNormal(loc, scale)\n",
        "\n",
        "        NLL = - torch.sum(reconstructed*original)\n",
        "        KLD = torch.sum(kl_divergence(posterior, prior).to(reconstructed.device))\n",
        "        loss_for_training = NLL + self.beta * KLD\n",
        "        return NLL, KLD, loss_for_training\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaaef9f2",
      "metadata": {
        "id": "eaaef9f2"
      },
      "source": [
        "## Train the Dirichlet VAE Model\n",
        "Use Training Gaussian VAE as a reference code and train Dirichlet VAE Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "335d822b",
      "metadata": {
        "id": "335d822b"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_one_epoch(train_dl, model, optim, device):\n",
        "    model.train()\n",
        "    epoch_total_loss, epoch_nll_loss, epoch_kld_loss = [], [], []\n",
        "    for batch in train_dl:\n",
        "        batch_total_loss, batch_nll_loss, batch_kld_loss = train_one_batch(batch, model, optim, device)\n",
        "        epoch_total_loss.append(batch_total_loss), epoch_nll_loss.append(batch_nll_loss), epoch_kld_loss.append(batch_kld_loss)\n",
        "    loss ={'total_loss': torch.mean(torch.Tensor(epoch_total_loss)), 'nll_loss': torch.mean(torch.Tensor(epoch_nll_loss)), 'kld_loss': torch.mean(torch.Tensor(epoch_kld_loss))}\n",
        "    return loss\n",
        "\n",
        "def train_one_batch(batch, model, optim, device):\n",
        "    docs = torch.from_numpy(batch.astype(np.float32)).to(torch.device(device))\n",
        "    optim.zero_grad()\n",
        "    out, posterior = model(docs)\n",
        "    nll, kld, loss_for_training = model.loss(out, docs, posterior)\n",
        "    loss = nll + kld\n",
        "    loss_for_training.backward()\n",
        "    optim.step()\n",
        "    return loss.item(), nll.item(), kld.item()\n",
        "\n",
        "def validate_one_epoch(val_dl, model, device):\n",
        "    model.eval()\n",
        "    epoch_total_loss, epoch_nll_loss, epoch_kld_loss = [], [], []\n",
        "    for batch in val_dl:\n",
        "        batch_total_loss, batch_nll_loss, batch_kld_loss = validate_one_batch(batch, model, device)\n",
        "        epoch_total_loss.append(batch_total_loss), epoch_nll_loss.append(batch_nll_loss), epoch_kld_loss.append(batch_kld_loss)\n",
        "    loss ={'total_loss': torch.mean(torch.Tensor(epoch_total_loss)), 'nll_loss': torch.mean(torch.Tensor(epoch_nll_loss)), 'kld_loss': torch.mean(torch.Tensor(epoch_kld_loss))}\n",
        "    return loss\n",
        "\n",
        "def validate_one_batch(batch, model, device):\n",
        "    docs = torch.from_numpy(batch.astype(np.float32)).to(torch.device(device))\n",
        "    out, posterior = model(docs)\n",
        "    nll, kld, _ = model.loss(out, docs, posterior)\n",
        "    loss = nll + kld\n",
        "    return loss.item(), nll.item(), kld.item()\n",
        "\n",
        "def fit(epochs, train_dl, val_dl, model, optim, device, path, writer):\n",
        "    history = []\n",
        "    for epoch in range(epochs):\n",
        "        epoch_train_loss = train_one_epoch(train_dl, model, optim, device)\n",
        "        epoch_validation_loss = validate_one_epoch(val_dl, model, device)\n",
        "        writer.add_scalar(\"Loss/train\", epoch_train_loss['total_loss'], epoch)\n",
        "        writer.add_scalar(\"Loss/eval\", epoch_validation_loss['total_loss'], epoch)\n",
        "        log = {\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': epoch_train_loss['total_loss'],\n",
        "                'train_loss_nll': epoch_train_loss['nll_loss'],\n",
        "                'train_loss_kld': epoch_train_loss['kld_loss'],\n",
        "            }\n",
        "        history.append(log)\n",
        "        print(log)\n",
        "    beta = model.decoder.topics_to_doc.weight.cpu().detach().T\n",
        "    return beta, history\n",
        "\n",
        "torch.manual_seed(3)\n",
        "hidden_size = [512, 256, 128]\n",
        "num_topics = 25\n",
        "dropout = 0.2\n",
        "epochs = 200\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def new_alphas(alpha):\n",
        "  # Declaring model and optimizer\n",
        "  model1 = VAE1(vocab_size, hidden_size, num_topics, dropout, 1, 3,alpha)\n",
        "  model1 = model.to(device)\n",
        "  optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "  from torch.utils.tensorboard import SummaryWriter\n",
        "  path = '/content'\n",
        "  writer = SummaryWriter()\n",
        "\n",
        "  # Run, trainings\n",
        "  beta, history = fit(epochs, train_new, val_new, model1, optim,device,path,writer)\n",
        "  return beta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b387072b",
      "metadata": {
        "id": "b387072b"
      },
      "source": [
        "## TODO: Get 25 topics using Dirichlet VAE model with five different values for $\\alpha\\in\\{0.1,0.5,1.0,2.0,10.0\\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8a3e1cbf",
      "metadata": {
        "id": "8a3e1cbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37768260-c9c2-4a92-e8da-3047ef641f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'train_loss': tensor(44990.3203), 'train_loss_nll': tensor(44423.8594), 'train_loss_kld': tensor(566.4604)}\n",
            "{'epoch': 2, 'train_loss': tensor(44904.6836), 'train_loss_nll': tensor(44344.4492), 'train_loss_kld': tensor(560.2332)}\n",
            "{'epoch': 3, 'train_loss': tensor(45088.6289), 'train_loss_nll': tensor(44527.6641), 'train_loss_kld': tensor(560.9651)}\n",
            "{'epoch': 4, 'train_loss': tensor(44771.1641), 'train_loss_nll': tensor(44209.0781), 'train_loss_kld': tensor(562.0801)}\n",
            "{'epoch': 5, 'train_loss': tensor(44819.5195), 'train_loss_nll': tensor(44261.0547), 'train_loss_kld': tensor(558.4646)}\n",
            "{'epoch': 6, 'train_loss': tensor(44934.2344), 'train_loss_nll': tensor(44379.0195), 'train_loss_kld': tensor(555.2210)}\n",
            "{'epoch': 7, 'train_loss': tensor(44775.6484), 'train_loss_nll': tensor(44223.8633), 'train_loss_kld': tensor(551.7836)}\n",
            "{'epoch': 8, 'train_loss': tensor(44684.0938), 'train_loss_nll': tensor(44131.1445), 'train_loss_kld': tensor(552.9487)}\n",
            "{'epoch': 9, 'train_loss': tensor(45083.9609), 'train_loss_nll': tensor(44528.6094), 'train_loss_kld': tensor(555.3476)}\n",
            "{'epoch': 10, 'train_loss': tensor(44773.8398), 'train_loss_nll': tensor(44220.0781), 'train_loss_kld': tensor(553.7634)}\n",
            "{'epoch': 11, 'train_loss': tensor(45006.7461), 'train_loss_nll': tensor(44451.4258), 'train_loss_kld': tensor(555.3209)}\n",
            "{'epoch': 12, 'train_loss': tensor(44732.6953), 'train_loss_nll': tensor(44181.2266), 'train_loss_kld': tensor(551.4684)}\n",
            "{'epoch': 13, 'train_loss': tensor(44683.1367), 'train_loss_nll': tensor(44132.1211), 'train_loss_kld': tensor(551.0208)}\n",
            "{'epoch': 14, 'train_loss': tensor(44759.2695), 'train_loss_nll': tensor(44207.9492), 'train_loss_kld': tensor(551.3216)}\n",
            "{'epoch': 15, 'train_loss': tensor(44733.3867), 'train_loss_nll': tensor(44180.2852), 'train_loss_kld': tensor(553.0976)}\n",
            "{'epoch': 16, 'train_loss': tensor(44832.5547), 'train_loss_nll': tensor(44279.2695), 'train_loss_kld': tensor(553.2789)}\n",
            "{'epoch': 17, 'train_loss': tensor(44600.9805), 'train_loss_nll': tensor(44048.9453), 'train_loss_kld': tensor(552.0348)}\n",
            "{'epoch': 18, 'train_loss': tensor(44788.7812), 'train_loss_nll': tensor(44236.8789), 'train_loss_kld': tensor(551.9011)}\n",
            "{'epoch': 19, 'train_loss': tensor(44637.1562), 'train_loss_nll': tensor(44085.8906), 'train_loss_kld': tensor(551.2675)}\n",
            "{'epoch': 20, 'train_loss': tensor(44688.5938), 'train_loss_nll': tensor(44135.7109), 'train_loss_kld': tensor(552.8883)}\n",
            "{'epoch': 21, 'train_loss': tensor(44777.0391), 'train_loss_nll': tensor(44224.8750), 'train_loss_kld': tensor(552.1668)}\n",
            "{'epoch': 22, 'train_loss': tensor(44868.8516), 'train_loss_nll': tensor(44315.4688), 'train_loss_kld': tensor(553.3832)}\n",
            "{'epoch': 23, 'train_loss': tensor(44747.1758), 'train_loss_nll': tensor(44195.8047), 'train_loss_kld': tensor(551.3697)}\n",
            "{'epoch': 24, 'train_loss': tensor(44657.5781), 'train_loss_nll': tensor(44107.2461), 'train_loss_kld': tensor(550.3317)}\n",
            "{'epoch': 25, 'train_loss': tensor(44648.8359), 'train_loss_nll': tensor(44099.0938), 'train_loss_kld': tensor(549.7379)}\n",
            "{'epoch': 26, 'train_loss': tensor(44811.7891), 'train_loss_nll': tensor(44263.5742), 'train_loss_kld': tensor(548.2133)}\n",
            "{'epoch': 27, 'train_loss': tensor(44673.8984), 'train_loss_nll': tensor(44124.7383), 'train_loss_kld': tensor(549.1628)}\n",
            "{'epoch': 28, 'train_loss': tensor(44813.7969), 'train_loss_nll': tensor(44266.4336), 'train_loss_kld': tensor(547.3627)}\n",
            "{'epoch': 29, 'train_loss': tensor(44834.4688), 'train_loss_nll': tensor(44285.6797), 'train_loss_kld': tensor(548.7870)}\n",
            "{'epoch': 30, 'train_loss': tensor(44679.3008), 'train_loss_nll': tensor(44131.1953), 'train_loss_kld': tensor(548.1061)}\n",
            "{'epoch': 31, 'train_loss': tensor(44752.0195), 'train_loss_nll': tensor(44206.5000), 'train_loss_kld': tensor(545.5210)}\n",
            "{'epoch': 32, 'train_loss': tensor(44605.0195), 'train_loss_nll': tensor(44056.5742), 'train_loss_kld': tensor(548.4431)}\n",
            "{'epoch': 33, 'train_loss': tensor(44732.6211), 'train_loss_nll': tensor(44184.2969), 'train_loss_kld': tensor(548.3229)}\n",
            "{'epoch': 34, 'train_loss': tensor(44599.8711), 'train_loss_nll': tensor(44051.4102), 'train_loss_kld': tensor(548.4626)}\n",
            "{'epoch': 35, 'train_loss': tensor(44560.2148), 'train_loss_nll': tensor(44010.5039), 'train_loss_kld': tensor(549.7078)}\n",
            "{'epoch': 36, 'train_loss': tensor(44540.2695), 'train_loss_nll': tensor(43988.4766), 'train_loss_kld': tensor(551.7890)}\n",
            "{'epoch': 37, 'train_loss': tensor(44598.0898), 'train_loss_nll': tensor(44049.9531), 'train_loss_kld': tensor(548.1371)}\n",
            "{'epoch': 38, 'train_loss': tensor(44551.7266), 'train_loss_nll': tensor(44005.4883), 'train_loss_kld': tensor(546.2401)}\n",
            "{'epoch': 39, 'train_loss': tensor(44630.5898), 'train_loss_nll': tensor(44085.1836), 'train_loss_kld': tensor(545.4009)}\n",
            "{'epoch': 40, 'train_loss': tensor(44599.6367), 'train_loss_nll': tensor(44050.7617), 'train_loss_kld': tensor(548.8731)}\n",
            "{'epoch': 41, 'train_loss': tensor(44587.3164), 'train_loss_nll': tensor(44040.5547), 'train_loss_kld': tensor(546.7603)}\n",
            "{'epoch': 42, 'train_loss': tensor(44598.9883), 'train_loss_nll': tensor(44051.0742), 'train_loss_kld': tensor(547.9210)}\n",
            "{'epoch': 43, 'train_loss': tensor(44715.7383), 'train_loss_nll': tensor(44161.2344), 'train_loss_kld': tensor(554.5045)}\n",
            "{'epoch': 44, 'train_loss': tensor(44767.0156), 'train_loss_nll': tensor(44208.7734), 'train_loss_kld': tensor(558.2463)}\n",
            "{'epoch': 45, 'train_loss': tensor(44548.5898), 'train_loss_nll': tensor(43994.5742), 'train_loss_kld': tensor(554.0089)}\n",
            "{'epoch': 46, 'train_loss': tensor(44619.0234), 'train_loss_nll': tensor(44066.4883), 'train_loss_kld': tensor(552.5397)}\n",
            "{'epoch': 47, 'train_loss': tensor(44579.3984), 'train_loss_nll': tensor(44029.1797), 'train_loss_kld': tensor(550.2214)}\n",
            "{'epoch': 48, 'train_loss': tensor(44563.7344), 'train_loss_nll': tensor(44012.3359), 'train_loss_kld': tensor(551.3975)}\n",
            "{'epoch': 49, 'train_loss': tensor(44552.4297), 'train_loss_nll': tensor(44001.2656), 'train_loss_kld': tensor(551.1683)}\n",
            "{'epoch': 50, 'train_loss': tensor(44606.3711), 'train_loss_nll': tensor(44055.2617), 'train_loss_kld': tensor(551.1100)}\n",
            "{'epoch': 51, 'train_loss': tensor(44601.9102), 'train_loss_nll': tensor(44050.1211), 'train_loss_kld': tensor(551.7886)}\n",
            "{'epoch': 52, 'train_loss': tensor(44731.3711), 'train_loss_nll': tensor(44178.5781), 'train_loss_kld': tensor(552.7883)}\n",
            "{'epoch': 53, 'train_loss': tensor(44598.1211), 'train_loss_nll': tensor(44050.0391), 'train_loss_kld': tensor(548.0794)}\n",
            "{'epoch': 54, 'train_loss': tensor(44698.7188), 'train_loss_nll': tensor(44149.4062), 'train_loss_kld': tensor(549.3158)}\n",
            "{'epoch': 55, 'train_loss': tensor(44490.6758), 'train_loss_nll': tensor(43940.8281), 'train_loss_kld': tensor(549.8418)}\n",
            "{'epoch': 56, 'train_loss': tensor(44712.2734), 'train_loss_nll': tensor(44162.9102), 'train_loss_kld': tensor(549.3566)}\n",
            "{'epoch': 57, 'train_loss': tensor(44507.), 'train_loss_nll': tensor(43958.0664), 'train_loss_kld': tensor(548.9349)}\n",
            "{'epoch': 58, 'train_loss': tensor(44676.3984), 'train_loss_nll': tensor(44127.7891), 'train_loss_kld': tensor(548.6096)}\n",
            "{'epoch': 59, 'train_loss': tensor(44478.1094), 'train_loss_nll': tensor(43928.1914), 'train_loss_kld': tensor(549.9216)}\n",
            "{'epoch': 60, 'train_loss': tensor(44349.8398), 'train_loss_nll': tensor(43800.9688), 'train_loss_kld': tensor(548.8689)}\n",
            "{'epoch': 61, 'train_loss': tensor(44374.3438), 'train_loss_nll': tensor(43824.7734), 'train_loss_kld': tensor(549.5709)}\n",
            "{'epoch': 62, 'train_loss': tensor(44419.1055), 'train_loss_nll': tensor(43870.4102), 'train_loss_kld': tensor(548.6930)}\n",
            "{'epoch': 63, 'train_loss': tensor(44408.3438), 'train_loss_nll': tensor(43858.7539), 'train_loss_kld': tensor(549.5905)}\n",
            "{'epoch': 64, 'train_loss': tensor(44445.9609), 'train_loss_nll': tensor(43898.2812), 'train_loss_kld': tensor(547.6845)}\n",
            "{'epoch': 65, 'train_loss': tensor(44372.9492), 'train_loss_nll': tensor(43825.8008), 'train_loss_kld': tensor(547.1505)}\n",
            "{'epoch': 66, 'train_loss': tensor(44511.9414), 'train_loss_nll': tensor(43964.9883), 'train_loss_kld': tensor(546.9483)}\n",
            "{'epoch': 67, 'train_loss': tensor(44309.4258), 'train_loss_nll': tensor(43762.9844), 'train_loss_kld': tensor(546.4373)}\n",
            "{'epoch': 68, 'train_loss': tensor(44387.2695), 'train_loss_nll': tensor(43840.3750), 'train_loss_kld': tensor(546.8964)}\n",
            "{'epoch': 69, 'train_loss': tensor(44484.0469), 'train_loss_nll': tensor(43939.7734), 'train_loss_kld': tensor(544.2679)}\n",
            "{'epoch': 70, 'train_loss': tensor(44304.6016), 'train_loss_nll': tensor(43759.9258), 'train_loss_kld': tensor(544.6789)}\n",
            "{'epoch': 71, 'train_loss': tensor(44232.6055), 'train_loss_nll': tensor(43689.1016), 'train_loss_kld': tensor(543.5072)}\n",
            "{'epoch': 72, 'train_loss': tensor(44301.7695), 'train_loss_nll': tensor(43759.4688), 'train_loss_kld': tensor(542.3019)}\n",
            "{'epoch': 73, 'train_loss': tensor(44315.4609), 'train_loss_nll': tensor(43772.3438), 'train_loss_kld': tensor(543.1099)}\n",
            "{'epoch': 74, 'train_loss': tensor(44368.1367), 'train_loss_nll': tensor(43826.5039), 'train_loss_kld': tensor(541.6318)}\n",
            "{'epoch': 75, 'train_loss': tensor(44444.7852), 'train_loss_nll': tensor(43903.1641), 'train_loss_kld': tensor(541.6213)}\n",
            "{'epoch': 76, 'train_loss': tensor(44362.1953), 'train_loss_nll': tensor(43819.4141), 'train_loss_kld': tensor(542.7800)}\n",
            "{'epoch': 77, 'train_loss': tensor(44441.7891), 'train_loss_nll': tensor(43898.7305), 'train_loss_kld': tensor(543.0573)}\n",
            "{'epoch': 78, 'train_loss': tensor(44587.1016), 'train_loss_nll': tensor(44046.3984), 'train_loss_kld': tensor(540.6986)}\n",
            "{'epoch': 79, 'train_loss': tensor(44273.8516), 'train_loss_nll': tensor(43731.6602), 'train_loss_kld': tensor(542.1902)}\n",
            "{'epoch': 80, 'train_loss': tensor(44388.7969), 'train_loss_nll': tensor(43843.9805), 'train_loss_kld': tensor(544.8184)}\n",
            "{'epoch': 81, 'train_loss': tensor(44306.8359), 'train_loss_nll': tensor(43762.1914), 'train_loss_kld': tensor(544.6455)}\n",
            "{'epoch': 82, 'train_loss': tensor(44349.3594), 'train_loss_nll': tensor(43803.4062), 'train_loss_kld': tensor(545.9532)}\n",
            "{'epoch': 83, 'train_loss': tensor(44453.1719), 'train_loss_nll': tensor(43909.1133), 'train_loss_kld': tensor(544.0481)}\n",
            "{'epoch': 84, 'train_loss': tensor(44276.2617), 'train_loss_nll': tensor(43733.5312), 'train_loss_kld': tensor(542.7330)}\n",
            "{'epoch': 85, 'train_loss': tensor(44275.3242), 'train_loss_nll': tensor(43733.4805), 'train_loss_kld': tensor(541.8513)}\n",
            "{'epoch': 86, 'train_loss': tensor(44531.5664), 'train_loss_nll': tensor(43988.1836), 'train_loss_kld': tensor(543.3776)}\n",
            "{'epoch': 87, 'train_loss': tensor(44303.5547), 'train_loss_nll': tensor(43759.9805), 'train_loss_kld': tensor(543.5715)}\n",
            "{'epoch': 88, 'train_loss': tensor(44236.1016), 'train_loss_nll': tensor(43691.5352), 'train_loss_kld': tensor(544.5671)}\n",
            "{'epoch': 89, 'train_loss': tensor(44310.1602), 'train_loss_nll': tensor(43766.6836), 'train_loss_kld': tensor(543.4762)}\n",
            "{'epoch': 90, 'train_loss': tensor(44173.1406), 'train_loss_nll': tensor(43632.0352), 'train_loss_kld': tensor(541.1098)}\n",
            "{'epoch': 91, 'train_loss': tensor(44152.8203), 'train_loss_nll': tensor(43610.2617), 'train_loss_kld': tensor(542.5579)}\n",
            "{'epoch': 92, 'train_loss': tensor(44338.7812), 'train_loss_nll': tensor(43797.1367), 'train_loss_kld': tensor(541.6427)}\n",
            "{'epoch': 93, 'train_loss': tensor(44341.5039), 'train_loss_nll': tensor(43798.1211), 'train_loss_kld': tensor(543.3846)}\n",
            "{'epoch': 94, 'train_loss': tensor(44238.8086), 'train_loss_nll': tensor(43693.6367), 'train_loss_kld': tensor(545.1748)}\n",
            "{'epoch': 95, 'train_loss': tensor(44349.2852), 'train_loss_nll': tensor(43806.4453), 'train_loss_kld': tensor(542.8434)}\n",
            "{'epoch': 96, 'train_loss': tensor(44436.5117), 'train_loss_nll': tensor(43890.1602), 'train_loss_kld': tensor(546.3473)}\n",
            "{'epoch': 97, 'train_loss': tensor(44308.8086), 'train_loss_nll': tensor(43760.7109), 'train_loss_kld': tensor(548.0935)}\n",
            "{'epoch': 98, 'train_loss': tensor(44444.2109), 'train_loss_nll': tensor(43892.1953), 'train_loss_kld': tensor(552.0098)}\n",
            "{'epoch': 99, 'train_loss': tensor(44277.9336), 'train_loss_nll': tensor(43724.7539), 'train_loss_kld': tensor(553.1789)}\n",
            "{'epoch': 100, 'train_loss': tensor(44194.3516), 'train_loss_nll': tensor(43640.1562), 'train_loss_kld': tensor(554.1898)}\n",
            "{'epoch': 101, 'train_loss': tensor(44225.6836), 'train_loss_nll': tensor(43675.0898), 'train_loss_kld': tensor(550.5930)}\n",
            "{'epoch': 102, 'train_loss': tensor(44258.8008), 'train_loss_nll': tensor(43706.4961), 'train_loss_kld': tensor(552.3007)}\n",
            "{'epoch': 103, 'train_loss': tensor(44159.7852), 'train_loss_nll': tensor(43608.3203), 'train_loss_kld': tensor(551.4603)}\n",
            "{'epoch': 104, 'train_loss': tensor(44475.7852), 'train_loss_nll': tensor(43921.7461), 'train_loss_kld': tensor(554.0416)}\n",
            "{'epoch': 105, 'train_loss': tensor(44084.6367), 'train_loss_nll': tensor(43534.), 'train_loss_kld': tensor(550.6335)}\n",
            "{'epoch': 106, 'train_loss': tensor(44138.), 'train_loss_nll': tensor(43587.4102), 'train_loss_kld': tensor(550.5886)}\n",
            "{'epoch': 107, 'train_loss': tensor(44131.5469), 'train_loss_nll': tensor(43583.0195), 'train_loss_kld': tensor(548.5196)}\n",
            "{'epoch': 108, 'train_loss': tensor(44282.8555), 'train_loss_nll': tensor(43730.5391), 'train_loss_kld': tensor(552.3199)}\n",
            "{'epoch': 109, 'train_loss': tensor(44123.5859), 'train_loss_nll': tensor(43573.6016), 'train_loss_kld': tensor(549.9828)}\n",
            "{'epoch': 110, 'train_loss': tensor(44178.1797), 'train_loss_nll': tensor(43630.1055), 'train_loss_kld': tensor(548.0740)}\n",
            "{'epoch': 111, 'train_loss': tensor(44064.8398), 'train_loss_nll': tensor(43515.6133), 'train_loss_kld': tensor(549.2234)}\n",
            "{'epoch': 112, 'train_loss': tensor(44019.7305), 'train_loss_nll': tensor(43468.4531), 'train_loss_kld': tensor(551.2775)}\n",
            "{'epoch': 113, 'train_loss': tensor(44119.9805), 'train_loss_nll': tensor(43569.6641), 'train_loss_kld': tensor(550.3104)}\n",
            "{'epoch': 114, 'train_loss': tensor(44062.1602), 'train_loss_nll': tensor(43513.9805), 'train_loss_kld': tensor(548.1827)}\n",
            "{'epoch': 115, 'train_loss': tensor(44119.3398), 'train_loss_nll': tensor(43570.2852), 'train_loss_kld': tensor(549.0570)}\n",
            "{'epoch': 116, 'train_loss': tensor(44123.0195), 'train_loss_nll': tensor(43575.4961), 'train_loss_kld': tensor(547.5193)}\n",
            "{'epoch': 117, 'train_loss': tensor(44191.8203), 'train_loss_nll': tensor(43646.2461), 'train_loss_kld': tensor(545.5797)}\n",
            "{'epoch': 118, 'train_loss': tensor(44293.4805), 'train_loss_nll': tensor(43744.5234), 'train_loss_kld': tensor(548.9565)}\n",
            "{'epoch': 119, 'train_loss': tensor(44180.6055), 'train_loss_nll': tensor(43631.3945), 'train_loss_kld': tensor(549.2037)}\n",
            "{'epoch': 120, 'train_loss': tensor(44154.3555), 'train_loss_nll': tensor(43606.9141), 'train_loss_kld': tensor(547.4363)}\n",
            "{'epoch': 121, 'train_loss': tensor(44149.9141), 'train_loss_nll': tensor(43602.3281), 'train_loss_kld': tensor(547.5842)}\n",
            "{'epoch': 122, 'train_loss': tensor(44071.0352), 'train_loss_nll': tensor(43526.3359), 'train_loss_kld': tensor(544.7053)}\n",
            "{'epoch': 123, 'train_loss': tensor(44140.3047), 'train_loss_nll': tensor(43591.1914), 'train_loss_kld': tensor(549.1162)}\n",
            "{'epoch': 124, 'train_loss': tensor(44048.1992), 'train_loss_nll': tensor(43499.8008), 'train_loss_kld': tensor(548.3945)}\n",
            "{'epoch': 125, 'train_loss': tensor(44112.2617), 'train_loss_nll': tensor(43566.), 'train_loss_kld': tensor(546.2609)}\n",
            "{'epoch': 126, 'train_loss': tensor(44202.0547), 'train_loss_nll': tensor(43654.0703), 'train_loss_kld': tensor(547.9829)}\n",
            "{'epoch': 127, 'train_loss': tensor(44051.7188), 'train_loss_nll': tensor(43505.9648), 'train_loss_kld': tensor(545.7548)}\n",
            "{'epoch': 128, 'train_loss': tensor(44250.5195), 'train_loss_nll': tensor(43704.7031), 'train_loss_kld': tensor(545.8183)}\n",
            "{'epoch': 129, 'train_loss': tensor(43919.5898), 'train_loss_nll': tensor(43375.6055), 'train_loss_kld': tensor(543.9849)}\n",
            "{'epoch': 130, 'train_loss': tensor(44039.6953), 'train_loss_nll': tensor(43495.9414), 'train_loss_kld': tensor(543.7569)}\n",
            "{'epoch': 131, 'train_loss': tensor(44067.4062), 'train_loss_nll': tensor(43524.6562), 'train_loss_kld': tensor(542.7538)}\n",
            "{'epoch': 132, 'train_loss': tensor(44198.4062), 'train_loss_nll': tensor(43657.1758), 'train_loss_kld': tensor(541.2294)}\n",
            "{'epoch': 133, 'train_loss': tensor(44114.1758), 'train_loss_nll': tensor(43573.4062), 'train_loss_kld': tensor(540.7723)}\n",
            "{'epoch': 134, 'train_loss': tensor(43958.3242), 'train_loss_nll': tensor(43419.4883), 'train_loss_kld': tensor(538.8388)}\n",
            "{'epoch': 135, 'train_loss': tensor(44059.6992), 'train_loss_nll': tensor(43519.2188), 'train_loss_kld': tensor(540.4828)}\n",
            "{'epoch': 136, 'train_loss': tensor(44173.2695), 'train_loss_nll': tensor(43625.0195), 'train_loss_kld': tensor(548.2516)}\n",
            "{'epoch': 137, 'train_loss': tensor(44104.7383), 'train_loss_nll': tensor(43549.4336), 'train_loss_kld': tensor(555.3077)}\n",
            "{'epoch': 138, 'train_loss': tensor(44182.9414), 'train_loss_nll': tensor(43628.5000), 'train_loss_kld': tensor(554.4392)}\n",
            "{'epoch': 139, 'train_loss': tensor(44105.9688), 'train_loss_nll': tensor(43551.3359), 'train_loss_kld': tensor(554.6331)}\n",
            "{'epoch': 140, 'train_loss': tensor(44276.8438), 'train_loss_nll': tensor(43724.2031), 'train_loss_kld': tensor(552.6359)}\n",
            "{'epoch': 141, 'train_loss': tensor(44047.7656), 'train_loss_nll': tensor(43497.8398), 'train_loss_kld': tensor(549.9256)}\n",
            "{'epoch': 142, 'train_loss': tensor(44208.1406), 'train_loss_nll': tensor(43655.3984), 'train_loss_kld': tensor(552.7383)}\n",
            "{'epoch': 143, 'train_loss': tensor(44051.0938), 'train_loss_nll': tensor(43497.9648), 'train_loss_kld': tensor(553.1375)}\n",
            "{'epoch': 144, 'train_loss': tensor(44024.7969), 'train_loss_nll': tensor(43475.6797), 'train_loss_kld': tensor(549.1139)}\n",
            "{'epoch': 145, 'train_loss': tensor(44181.0391), 'train_loss_nll': tensor(43632.9492), 'train_loss_kld': tensor(548.0865)}\n",
            "{'epoch': 146, 'train_loss': tensor(44173.7656), 'train_loss_nll': tensor(43627.0547), 'train_loss_kld': tensor(546.7075)}\n",
            "{'epoch': 147, 'train_loss': tensor(44096.5312), 'train_loss_nll': tensor(43550.4648), 'train_loss_kld': tensor(546.0642)}\n",
            "{'epoch': 148, 'train_loss': tensor(44060.6602), 'train_loss_nll': tensor(43514.9336), 'train_loss_kld': tensor(545.7264)}\n",
            "{'epoch': 149, 'train_loss': tensor(44032.1289), 'train_loss_nll': tensor(43487.1836), 'train_loss_kld': tensor(544.9436)}\n",
            "{'epoch': 150, 'train_loss': tensor(44238.7266), 'train_loss_nll': tensor(43694.6094), 'train_loss_kld': tensor(544.1121)}\n",
            "{'epoch': 151, 'train_loss': tensor(44238.0586), 'train_loss_nll': tensor(43694.4414), 'train_loss_kld': tensor(543.6172)}\n",
            "{'epoch': 152, 'train_loss': tensor(44134.0352), 'train_loss_nll': tensor(43593.8242), 'train_loss_kld': tensor(540.2072)}\n",
            "{'epoch': 153, 'train_loss': tensor(44010.2734), 'train_loss_nll': tensor(43468.8555), 'train_loss_kld': tensor(541.4194)}\n",
            "{'epoch': 154, 'train_loss': tensor(44055.7266), 'train_loss_nll': tensor(43514.5859), 'train_loss_kld': tensor(541.1381)}\n",
            "{'epoch': 155, 'train_loss': tensor(44067.9961), 'train_loss_nll': tensor(43527.4336), 'train_loss_kld': tensor(540.5577)}\n",
            "{'epoch': 156, 'train_loss': tensor(44194.4102), 'train_loss_nll': tensor(43650.6250), 'train_loss_kld': tensor(543.7842)}\n",
            "{'epoch': 157, 'train_loss': tensor(44059.2266), 'train_loss_nll': tensor(43514.9531), 'train_loss_kld': tensor(544.2719)}\n",
            "{'epoch': 158, 'train_loss': tensor(44125.0234), 'train_loss_nll': tensor(43580.8945), 'train_loss_kld': tensor(544.1259)}\n",
            "{'epoch': 159, 'train_loss': tensor(44180.0117), 'train_loss_nll': tensor(43638.6367), 'train_loss_kld': tensor(541.3703)}\n",
            "{'epoch': 160, 'train_loss': tensor(43993.7891), 'train_loss_nll': tensor(43452.8945), 'train_loss_kld': tensor(540.8908)}\n",
            "{'epoch': 161, 'train_loss': tensor(44093.5742), 'train_loss_nll': tensor(43549.7812), 'train_loss_kld': tensor(543.7982)}\n",
            "{'epoch': 162, 'train_loss': tensor(44010.1992), 'train_loss_nll': tensor(43469.1602), 'train_loss_kld': tensor(541.0345)}\n",
            "{'epoch': 163, 'train_loss': tensor(43890.4492), 'train_loss_nll': tensor(43348.9453), 'train_loss_kld': tensor(541.5071)}\n",
            "{'epoch': 164, 'train_loss': tensor(44014.6367), 'train_loss_nll': tensor(43471.8438), 'train_loss_kld': tensor(542.7908)}\n",
            "{'epoch': 165, 'train_loss': tensor(44011.4414), 'train_loss_nll': tensor(43467.3086), 'train_loss_kld': tensor(544.1288)}\n",
            "{'epoch': 166, 'train_loss': tensor(43870.6602), 'train_loss_nll': tensor(43328.2305), 'train_loss_kld': tensor(542.4278)}\n",
            "{'epoch': 167, 'train_loss': tensor(44194.), 'train_loss_nll': tensor(43651.5898), 'train_loss_kld': tensor(542.4087)}\n",
            "{'epoch': 168, 'train_loss': tensor(44034.1406), 'train_loss_nll': tensor(43491.7031), 'train_loss_kld': tensor(542.4370)}\n",
            "{'epoch': 169, 'train_loss': tensor(44108.8594), 'train_loss_nll': tensor(43561.4453), 'train_loss_kld': tensor(547.4174)}\n",
            "{'epoch': 170, 'train_loss': tensor(44049.5781), 'train_loss_nll': tensor(43502.1562), 'train_loss_kld': tensor(547.4272)}\n",
            "{'epoch': 171, 'train_loss': tensor(43986.7734), 'train_loss_nll': tensor(43442.3750), 'train_loss_kld': tensor(544.4044)}\n",
            "{'epoch': 172, 'train_loss': tensor(43968.1484), 'train_loss_nll': tensor(43421.3281), 'train_loss_kld': tensor(546.8185)}\n",
            "{'epoch': 173, 'train_loss': tensor(44017.6445), 'train_loss_nll': tensor(43469.1641), 'train_loss_kld': tensor(548.4771)}\n",
            "{'epoch': 174, 'train_loss': tensor(44029.7188), 'train_loss_nll': tensor(43479.4297), 'train_loss_kld': tensor(550.2870)}\n",
            "{'epoch': 175, 'train_loss': tensor(44155.1602), 'train_loss_nll': tensor(43608.1641), 'train_loss_kld': tensor(546.9943)}\n",
            "{'epoch': 176, 'train_loss': tensor(44186.0195), 'train_loss_nll': tensor(43636.8594), 'train_loss_kld': tensor(549.1619)}\n",
            "{'epoch': 177, 'train_loss': tensor(44235.2617), 'train_loss_nll': tensor(43687.4492), 'train_loss_kld': tensor(547.8131)}\n",
            "{'epoch': 178, 'train_loss': tensor(44163.1602), 'train_loss_nll': tensor(43618.9258), 'train_loss_kld': tensor(544.2432)}\n",
            "{'epoch': 179, 'train_loss': tensor(43966.0117), 'train_loss_nll': tensor(43422.1016), 'train_loss_kld': tensor(543.9116)}\n",
            "{'epoch': 180, 'train_loss': tensor(44356.6484), 'train_loss_nll': tensor(43815.3516), 'train_loss_kld': tensor(541.3081)}\n",
            "{'epoch': 181, 'train_loss': tensor(44294.6719), 'train_loss_nll': tensor(43749.6914), 'train_loss_kld': tensor(544.9799)}\n",
            "{'epoch': 182, 'train_loss': tensor(43964.3242), 'train_loss_nll': tensor(43421.7539), 'train_loss_kld': tensor(542.5659)}\n",
            "{'epoch': 183, 'train_loss': tensor(44099.4961), 'train_loss_nll': tensor(43553.6367), 'train_loss_kld': tensor(545.8554)}\n",
            "{'epoch': 184, 'train_loss': tensor(44025.2539), 'train_loss_nll': tensor(43474.8906), 'train_loss_kld': tensor(550.3647)}\n",
            "{'epoch': 185, 'train_loss': tensor(43982.4297), 'train_loss_nll': tensor(43437.0508), 'train_loss_kld': tensor(545.3850)}\n",
            "{'epoch': 186, 'train_loss': tensor(44077.4297), 'train_loss_nll': tensor(43532.9531), 'train_loss_kld': tensor(544.4784)}\n",
            "{'epoch': 187, 'train_loss': tensor(44185.6016), 'train_loss_nll': tensor(43643.2031), 'train_loss_kld': tensor(542.3944)}\n",
            "{'epoch': 188, 'train_loss': tensor(44223.2617), 'train_loss_nll': tensor(43676.8633), 'train_loss_kld': tensor(546.3940)}\n",
            "{'epoch': 189, 'train_loss': tensor(44089.3008), 'train_loss_nll': tensor(43541.7734), 'train_loss_kld': tensor(547.5261)}\n",
            "{'epoch': 190, 'train_loss': tensor(44035.7031), 'train_loss_nll': tensor(43488.2734), 'train_loss_kld': tensor(547.4266)}\n",
            "{'epoch': 191, 'train_loss': tensor(44241.1016), 'train_loss_nll': tensor(43693.2188), 'train_loss_kld': tensor(547.8828)}\n",
            "{'epoch': 192, 'train_loss': tensor(44062.1953), 'train_loss_nll': tensor(43510.5508), 'train_loss_kld': tensor(551.6483)}\n",
            "{'epoch': 193, 'train_loss': tensor(44152.9766), 'train_loss_nll': tensor(43603.7148), 'train_loss_kld': tensor(549.2617)}\n",
            "{'epoch': 194, 'train_loss': tensor(44005.1406), 'train_loss_nll': tensor(43455.6836), 'train_loss_kld': tensor(549.4496)}\n",
            "{'epoch': 195, 'train_loss': tensor(44050.0703), 'train_loss_nll': tensor(43503.6992), 'train_loss_kld': tensor(546.3748)}\n",
            "{'epoch': 196, 'train_loss': tensor(43914.1367), 'train_loss_nll': tensor(43369.3438), 'train_loss_kld': tensor(544.7920)}\n",
            "{'epoch': 197, 'train_loss': tensor(44231.2344), 'train_loss_nll': tensor(43683.4688), 'train_loss_kld': tensor(547.7643)}\n",
            "{'epoch': 198, 'train_loss': tensor(43962.5898), 'train_loss_nll': tensor(43415.5742), 'train_loss_kld': tensor(547.0117)}\n",
            "{'epoch': 199, 'train_loss': tensor(43994.0312), 'train_loss_nll': tensor(43449.0547), 'train_loss_kld': tensor(544.9783)}\n",
            "{'epoch': 200, 'train_loss': tensor(43983.3086), 'train_loss_nll': tensor(43435.7266), 'train_loss_kld': tensor(547.5914)}\n",
            "{'epoch': 1, 'train_loss': tensor(44006.2617), 'train_loss_nll': tensor(43463.4336), 'train_loss_kld': tensor(542.8197)}\n",
            "{'epoch': 2, 'train_loss': tensor(44027.9883), 'train_loss_nll': tensor(43487.6211), 'train_loss_kld': tensor(540.3649)}\n",
            "{'epoch': 3, 'train_loss': tensor(44037.5547), 'train_loss_nll': tensor(43500.7852), 'train_loss_kld': tensor(536.7700)}\n",
            "{'epoch': 4, 'train_loss': tensor(43913.7266), 'train_loss_nll': tensor(43372.9688), 'train_loss_kld': tensor(540.7524)}\n",
            "{'epoch': 5, 'train_loss': tensor(44209.1641), 'train_loss_nll': tensor(43671.4609), 'train_loss_kld': tensor(537.7076)}\n",
            "{'epoch': 6, 'train_loss': tensor(44229.5391), 'train_loss_nll': tensor(43691.1602), 'train_loss_kld': tensor(538.3763)}\n",
            "{'epoch': 7, 'train_loss': tensor(43995.7148), 'train_loss_nll': tensor(43457.1367), 'train_loss_kld': tensor(538.5773)}\n",
            "{'epoch': 8, 'train_loss': tensor(44059.5195), 'train_loss_nll': tensor(43522.2383), 'train_loss_kld': tensor(537.2767)}\n",
            "{'epoch': 9, 'train_loss': tensor(43928.6211), 'train_loss_nll': tensor(43391.8594), 'train_loss_kld': tensor(536.7607)}\n",
            "{'epoch': 10, 'train_loss': tensor(43886.5742), 'train_loss_nll': tensor(43347.6289), 'train_loss_kld': tensor(538.9500)}\n",
            "{'epoch': 11, 'train_loss': tensor(44090.9766), 'train_loss_nll': tensor(43551.3789), 'train_loss_kld': tensor(539.5975)}\n",
            "{'epoch': 12, 'train_loss': tensor(44185.9336), 'train_loss_nll': tensor(43646.1367), 'train_loss_kld': tensor(539.7996)}\n",
            "{'epoch': 13, 'train_loss': tensor(43921.7812), 'train_loss_nll': tensor(43380.5586), 'train_loss_kld': tensor(541.2213)}\n",
            "{'epoch': 14, 'train_loss': tensor(44028.7148), 'train_loss_nll': tensor(43485.5234), 'train_loss_kld': tensor(543.1918)}\n",
            "{'epoch': 15, 'train_loss': tensor(44204.2500), 'train_loss_nll': tensor(43660.3750), 'train_loss_kld': tensor(543.8747)}\n",
            "{'epoch': 16, 'train_loss': tensor(44342.0547), 'train_loss_nll': tensor(43798.7188), 'train_loss_kld': tensor(543.3384)}\n",
            "{'epoch': 17, 'train_loss': tensor(44068.8789), 'train_loss_nll': tensor(43529.0664), 'train_loss_kld': tensor(539.8140)}\n",
            "{'epoch': 18, 'train_loss': tensor(44060.5781), 'train_loss_nll': tensor(43520.1797), 'train_loss_kld': tensor(540.4020)}\n",
            "{'epoch': 19, 'train_loss': tensor(43842.0938), 'train_loss_nll': tensor(43305.0859), 'train_loss_kld': tensor(537.0118)}\n",
            "{'epoch': 20, 'train_loss': tensor(43941.1211), 'train_loss_nll': tensor(43405.2500), 'train_loss_kld': tensor(535.8724)}\n",
            "{'epoch': 21, 'train_loss': tensor(43906.6836), 'train_loss_nll': tensor(43371.6914), 'train_loss_kld': tensor(534.9949)}\n",
            "{'epoch': 22, 'train_loss': tensor(43972.7891), 'train_loss_nll': tensor(43432.9766), 'train_loss_kld': tensor(539.8160)}\n",
            "{'epoch': 23, 'train_loss': tensor(43997.6133), 'train_loss_nll': tensor(43457.2461), 'train_loss_kld': tensor(540.3711)}\n",
            "{'epoch': 24, 'train_loss': tensor(43822.7188), 'train_loss_nll': tensor(43282.1406), 'train_loss_kld': tensor(540.5828)}\n",
            "{'epoch': 25, 'train_loss': tensor(43834.4453), 'train_loss_nll': tensor(43293.3633), 'train_loss_kld': tensor(541.0757)}\n",
            "{'epoch': 26, 'train_loss': tensor(43908.0039), 'train_loss_nll': tensor(43369.5547), 'train_loss_kld': tensor(538.4508)}\n",
            "{'epoch': 27, 'train_loss': tensor(43896.9883), 'train_loss_nll': tensor(43358.3203), 'train_loss_kld': tensor(538.6753)}\n",
            "{'epoch': 28, 'train_loss': tensor(43942.3242), 'train_loss_nll': tensor(43402.6211), 'train_loss_kld': tensor(539.7110)}\n",
            "{'epoch': 29, 'train_loss': tensor(43851.2734), 'train_loss_nll': tensor(43310.6992), 'train_loss_kld': tensor(540.5809)}\n",
            "{'epoch': 30, 'train_loss': tensor(43780.9648), 'train_loss_nll': tensor(43239.6484), 'train_loss_kld': tensor(541.3221)}\n",
            "{'epoch': 31, 'train_loss': tensor(44100.2969), 'train_loss_nll': tensor(43558.7305), 'train_loss_kld': tensor(541.5711)}\n",
            "{'epoch': 32, 'train_loss': tensor(44003.2969), 'train_loss_nll': tensor(43462.4219), 'train_loss_kld': tensor(540.8801)}\n",
            "{'epoch': 33, 'train_loss': tensor(43871.3008), 'train_loss_nll': tensor(43329.8750), 'train_loss_kld': tensor(541.4249)}\n",
            "{'epoch': 34, 'train_loss': tensor(43725.2344), 'train_loss_nll': tensor(43184.3594), 'train_loss_kld': tensor(540.8741)}\n",
            "{'epoch': 35, 'train_loss': tensor(43667.5664), 'train_loss_nll': tensor(43126.0859), 'train_loss_kld': tensor(541.4821)}\n",
            "{'epoch': 36, 'train_loss': tensor(43900.0547), 'train_loss_nll': tensor(43358.0234), 'train_loss_kld': tensor(542.0267)}\n",
            "{'epoch': 37, 'train_loss': tensor(43749.0039), 'train_loss_nll': tensor(43204.1055), 'train_loss_kld': tensor(544.8987)}\n",
            "{'epoch': 38, 'train_loss': tensor(44041.8945), 'train_loss_nll': tensor(43496.5508), 'train_loss_kld': tensor(545.3482)}\n",
            "{'epoch': 39, 'train_loss': tensor(43863.6797), 'train_loss_nll': tensor(43308.6289), 'train_loss_kld': tensor(555.0496)}\n",
            "{'epoch': 40, 'train_loss': tensor(44510.9492), 'train_loss_nll': tensor(43946.6914), 'train_loss_kld': tensor(564.2642)}\n",
            "{'epoch': 41, 'train_loss': tensor(44102.3242), 'train_loss_nll': tensor(43537.9258), 'train_loss_kld': tensor(564.4012)}\n",
            "{'epoch': 42, 'train_loss': tensor(44210.2695), 'train_loss_nll': tensor(43648.8633), 'train_loss_kld': tensor(561.4048)}\n",
            "{'epoch': 43, 'train_loss': tensor(43977.0039), 'train_loss_nll': tensor(43419.6992), 'train_loss_kld': tensor(557.2994)}\n",
            "{'epoch': 44, 'train_loss': tensor(44015.4805), 'train_loss_nll': tensor(43458.4141), 'train_loss_kld': tensor(557.0598)}\n",
            "{'epoch': 45, 'train_loss': tensor(43936.4648), 'train_loss_nll': tensor(43381.0742), 'train_loss_kld': tensor(555.3823)}\n",
            "{'epoch': 46, 'train_loss': tensor(43964.1250), 'train_loss_nll': tensor(43409.4609), 'train_loss_kld': tensor(554.6656)}\n",
            "{'epoch': 47, 'train_loss': tensor(43965.8516), 'train_loss_nll': tensor(43411.2109), 'train_loss_kld': tensor(554.6467)}\n",
            "{'epoch': 48, 'train_loss': tensor(43975.7500), 'train_loss_nll': tensor(43421.3203), 'train_loss_kld': tensor(554.4307)}\n",
            "{'epoch': 49, 'train_loss': tensor(43923.2109), 'train_loss_nll': tensor(43366.6016), 'train_loss_kld': tensor(556.6088)}\n",
            "{'epoch': 50, 'train_loss': tensor(43772.5859), 'train_loss_nll': tensor(43213.6289), 'train_loss_kld': tensor(558.9496)}\n",
            "{'epoch': 51, 'train_loss': tensor(44064.2969), 'train_loss_nll': tensor(43509.4766), 'train_loss_kld': tensor(554.8195)}\n",
            "{'epoch': 52, 'train_loss': tensor(43895.2734), 'train_loss_nll': tensor(43340.5195), 'train_loss_kld': tensor(554.7551)}\n",
            "{'epoch': 53, 'train_loss': tensor(43793.5547), 'train_loss_nll': tensor(43240.0117), 'train_loss_kld': tensor(553.5482)}\n",
            "{'epoch': 54, 'train_loss': tensor(43854.9492), 'train_loss_nll': tensor(43302.3086), 'train_loss_kld': tensor(552.6412)}\n",
            "{'epoch': 55, 'train_loss': tensor(43926.4102), 'train_loss_nll': tensor(43375.8438), 'train_loss_kld': tensor(550.5683)}\n",
            "{'epoch': 56, 'train_loss': tensor(44007.8203), 'train_loss_nll': tensor(43454.4258), 'train_loss_kld': tensor(553.3954)}\n",
            "{'epoch': 57, 'train_loss': tensor(43820.4531), 'train_loss_nll': tensor(43270.7383), 'train_loss_kld': tensor(549.7163)}\n",
            "{'epoch': 58, 'train_loss': tensor(43841.6602), 'train_loss_nll': tensor(43290.9414), 'train_loss_kld': tensor(550.7225)}\n",
            "{'epoch': 59, 'train_loss': tensor(43559.1016), 'train_loss_nll': tensor(43007.4805), 'train_loss_kld': tensor(551.6160)}\n",
            "{'epoch': 60, 'train_loss': tensor(43621.9414), 'train_loss_nll': tensor(43072.3984), 'train_loss_kld': tensor(549.5440)}\n",
            "{'epoch': 61, 'train_loss': tensor(43731.8281), 'train_loss_nll': tensor(43180.8633), 'train_loss_kld': tensor(550.9626)}\n",
            "{'epoch': 62, 'train_loss': tensor(43901.2539), 'train_loss_nll': tensor(43351.6016), 'train_loss_kld': tensor(549.6627)}\n",
            "{'epoch': 63, 'train_loss': tensor(43623.9102), 'train_loss_nll': tensor(43073.6719), 'train_loss_kld': tensor(550.2424)}\n",
            "{'epoch': 64, 'train_loss': tensor(43875.3984), 'train_loss_nll': tensor(43325.9297), 'train_loss_kld': tensor(549.4722)}\n",
            "{'epoch': 65, 'train_loss': tensor(43780.9219), 'train_loss_nll': tensor(43233.7852), 'train_loss_kld': tensor(547.1364)}\n",
            "{'epoch': 66, 'train_loss': tensor(43828.5312), 'train_loss_nll': tensor(43279.8086), 'train_loss_kld': tensor(548.7247)}\n",
            "{'epoch': 67, 'train_loss': tensor(43632.0859), 'train_loss_nll': tensor(43082.3359), 'train_loss_kld': tensor(549.7542)}\n",
            "{'epoch': 68, 'train_loss': tensor(43669.8008), 'train_loss_nll': tensor(43121.4414), 'train_loss_kld': tensor(548.3584)}\n",
            "{'epoch': 69, 'train_loss': tensor(43779.3164), 'train_loss_nll': tensor(43230.3086), 'train_loss_kld': tensor(548.9977)}\n",
            "{'epoch': 70, 'train_loss': tensor(43526.6133), 'train_loss_nll': tensor(42980.7891), 'train_loss_kld': tensor(545.8223)}\n",
            "{'epoch': 71, 'train_loss': tensor(43571.3633), 'train_loss_nll': tensor(43026.3594), 'train_loss_kld': tensor(545.0068)}\n",
            "{'epoch': 72, 'train_loss': tensor(43616.7695), 'train_loss_nll': tensor(43068.9258), 'train_loss_kld': tensor(547.8475)}\n",
            "{'epoch': 73, 'train_loss': tensor(43601.8281), 'train_loss_nll': tensor(43055.9102), 'train_loss_kld': tensor(545.9161)}\n",
            "{'epoch': 74, 'train_loss': tensor(43610.7383), 'train_loss_nll': tensor(43064.6719), 'train_loss_kld': tensor(546.0683)}\n",
            "{'epoch': 75, 'train_loss': tensor(43923.7656), 'train_loss_nll': tensor(43377.9961), 'train_loss_kld': tensor(545.7709)}\n",
            "{'epoch': 76, 'train_loss': tensor(43570.3555), 'train_loss_nll': tensor(43024.5156), 'train_loss_kld': tensor(545.8445)}\n",
            "{'epoch': 77, 'train_loss': tensor(43635.7695), 'train_loss_nll': tensor(43088.6367), 'train_loss_kld': tensor(547.1376)}\n",
            "{'epoch': 78, 'train_loss': tensor(43709.6797), 'train_loss_nll': tensor(43164.8164), 'train_loss_kld': tensor(544.8713)}\n",
            "{'epoch': 79, 'train_loss': tensor(43682.9883), 'train_loss_nll': tensor(43141.6484), 'train_loss_kld': tensor(541.3392)}\n",
            "{'epoch': 80, 'train_loss': tensor(43634.4336), 'train_loss_nll': tensor(43090.8867), 'train_loss_kld': tensor(543.5449)}\n",
            "{'epoch': 81, 'train_loss': tensor(43484.1641), 'train_loss_nll': tensor(42938.6836), 'train_loss_kld': tensor(545.4813)}\n",
            "{'epoch': 82, 'train_loss': tensor(43744.2734), 'train_loss_nll': tensor(43194.5039), 'train_loss_kld': tensor(549.7689)}\n",
            "{'epoch': 83, 'train_loss': tensor(43707.1602), 'train_loss_nll': tensor(43157.0195), 'train_loss_kld': tensor(550.1453)}\n",
            "{'epoch': 84, 'train_loss': tensor(43619.0547), 'train_loss_nll': tensor(43070.7812), 'train_loss_kld': tensor(548.2725)}\n",
            "{'epoch': 85, 'train_loss': tensor(43653.1914), 'train_loss_nll': tensor(43104.0508), 'train_loss_kld': tensor(549.1458)}\n",
            "{'epoch': 86, 'train_loss': tensor(43835.0391), 'train_loss_nll': tensor(43287.6992), 'train_loss_kld': tensor(547.3357)}\n",
            "{'epoch': 87, 'train_loss': tensor(43587.1406), 'train_loss_nll': tensor(43043.2617), 'train_loss_kld': tensor(543.8815)}\n",
            "{'epoch': 88, 'train_loss': tensor(43507.9336), 'train_loss_nll': tensor(42962.9297), 'train_loss_kld': tensor(545.0046)}\n",
            "{'epoch': 89, 'train_loss': tensor(43965.9258), 'train_loss_nll': tensor(43420.3984), 'train_loss_kld': tensor(545.5281)}\n",
            "{'epoch': 90, 'train_loss': tensor(43704.1914), 'train_loss_nll': tensor(43161.5664), 'train_loss_kld': tensor(542.6295)}\n",
            "{'epoch': 91, 'train_loss': tensor(43530.7891), 'train_loss_nll': tensor(42983.9531), 'train_loss_kld': tensor(546.8339)}\n",
            "{'epoch': 92, 'train_loss': tensor(43589.9805), 'train_loss_nll': tensor(43043.3242), 'train_loss_kld': tensor(546.6570)}\n",
            "{'epoch': 93, 'train_loss': tensor(43719.), 'train_loss_nll': tensor(43168.9141), 'train_loss_kld': tensor(550.0834)}\n",
            "{'epoch': 94, 'train_loss': tensor(43733.9102), 'train_loss_nll': tensor(43186.2031), 'train_loss_kld': tensor(547.7020)}\n",
            "{'epoch': 95, 'train_loss': tensor(43459.3906), 'train_loss_nll': tensor(42912.8516), 'train_loss_kld': tensor(546.5408)}\n",
            "{'epoch': 96, 'train_loss': tensor(43483.0039), 'train_loss_nll': tensor(42937.6289), 'train_loss_kld': tensor(545.3776)}\n",
            "{'epoch': 97, 'train_loss': tensor(43491.8203), 'train_loss_nll': tensor(42946.2305), 'train_loss_kld': tensor(545.5933)}\n",
            "{'epoch': 98, 'train_loss': tensor(43580.3047), 'train_loss_nll': tensor(43024.4141), 'train_loss_kld': tensor(555.8878)}\n",
            "{'epoch': 99, 'train_loss': tensor(43481.1211), 'train_loss_nll': tensor(42917.7891), 'train_loss_kld': tensor(563.3286)}\n",
            "{'epoch': 100, 'train_loss': tensor(43591.6367), 'train_loss_nll': tensor(43031.7109), 'train_loss_kld': tensor(559.9222)}\n",
            "{'epoch': 101, 'train_loss': tensor(43610.1055), 'train_loss_nll': tensor(43050.1445), 'train_loss_kld': tensor(559.9603)}\n",
            "{'epoch': 102, 'train_loss': tensor(43687.3789), 'train_loss_nll': tensor(43130.8086), 'train_loss_kld': tensor(556.5751)}\n",
            "{'epoch': 103, 'train_loss': tensor(43716.3242), 'train_loss_nll': tensor(43159.3047), 'train_loss_kld': tensor(557.0173)}\n",
            "{'epoch': 104, 'train_loss': tensor(43256.2109), 'train_loss_nll': tensor(42696.5039), 'train_loss_kld': tensor(559.7075)}\n",
            "{'epoch': 105, 'train_loss': tensor(43474.7305), 'train_loss_nll': tensor(42920.5508), 'train_loss_kld': tensor(554.1751)}\n",
            "{'epoch': 106, 'train_loss': tensor(43457.1484), 'train_loss_nll': tensor(42902.2852), 'train_loss_kld': tensor(554.8674)}\n",
            "{'epoch': 107, 'train_loss': tensor(43344.8984), 'train_loss_nll': tensor(42791.3867), 'train_loss_kld': tensor(553.5068)}\n",
            "{'epoch': 108, 'train_loss': tensor(43560.0234), 'train_loss_nll': tensor(43005.0938), 'train_loss_kld': tensor(554.9260)}\n",
            "{'epoch': 109, 'train_loss': tensor(43537.7344), 'train_loss_nll': tensor(42985.2305), 'train_loss_kld': tensor(552.5047)}\n",
            "{'epoch': 110, 'train_loss': tensor(43800.2695), 'train_loss_nll': tensor(43248.5000), 'train_loss_kld': tensor(551.7706)}\n",
            "{'epoch': 111, 'train_loss': tensor(43497.9492), 'train_loss_nll': tensor(42943.8984), 'train_loss_kld': tensor(554.0518)}\n",
            "{'epoch': 112, 'train_loss': tensor(43516.6094), 'train_loss_nll': tensor(42962.4844), 'train_loss_kld': tensor(554.1272)}\n",
            "{'epoch': 113, 'train_loss': tensor(43623.5195), 'train_loss_nll': tensor(43067.8242), 'train_loss_kld': tensor(555.6947)}\n",
            "{'epoch': 114, 'train_loss': tensor(43402.7891), 'train_loss_nll': tensor(42848.4062), 'train_loss_kld': tensor(554.3833)}\n",
            "{'epoch': 115, 'train_loss': tensor(43516.1719), 'train_loss_nll': tensor(42962.2656), 'train_loss_kld': tensor(553.9066)}\n",
            "{'epoch': 116, 'train_loss': tensor(43726.1094), 'train_loss_nll': tensor(43173.1211), 'train_loss_kld': tensor(552.9882)}\n",
            "{'epoch': 117, 'train_loss': tensor(43477.6602), 'train_loss_nll': tensor(42923.4453), 'train_loss_kld': tensor(554.2193)}\n",
            "{'epoch': 118, 'train_loss': tensor(43558.1250), 'train_loss_nll': tensor(43008.5195), 'train_loss_kld': tensor(549.5994)}\n",
            "{'epoch': 119, 'train_loss': tensor(43448.2305), 'train_loss_nll': tensor(42895.9961), 'train_loss_kld': tensor(552.2407)}\n",
            "{'epoch': 120, 'train_loss': tensor(43376.8789), 'train_loss_nll': tensor(42826.0195), 'train_loss_kld': tensor(550.8529)}\n",
            "{'epoch': 121, 'train_loss': tensor(43529.0352), 'train_loss_nll': tensor(42977.6094), 'train_loss_kld': tensor(551.4269)}\n",
            "{'epoch': 122, 'train_loss': tensor(43538.8047), 'train_loss_nll': tensor(42990.2656), 'train_loss_kld': tensor(548.5433)}\n",
            "{'epoch': 123, 'train_loss': tensor(43295.1719), 'train_loss_nll': tensor(42747.3906), 'train_loss_kld': tensor(547.7816)}\n",
            "{'epoch': 124, 'train_loss': tensor(43366.6719), 'train_loss_nll': tensor(42817.6055), 'train_loss_kld': tensor(549.0631)}\n",
            "{'epoch': 125, 'train_loss': tensor(43431.6914), 'train_loss_nll': tensor(42881.3945), 'train_loss_kld': tensor(550.2958)}\n",
            "{'epoch': 126, 'train_loss': tensor(43443.6289), 'train_loss_nll': tensor(42894.0586), 'train_loss_kld': tensor(549.5756)}\n",
            "{'epoch': 127, 'train_loss': tensor(43479.5703), 'train_loss_nll': tensor(42927.3047), 'train_loss_kld': tensor(552.2683)}\n",
            "{'epoch': 128, 'train_loss': tensor(43593.1016), 'train_loss_nll': tensor(43040.6758), 'train_loss_kld': tensor(552.4239)}\n",
            "{'epoch': 129, 'train_loss': tensor(43409.6602), 'train_loss_nll': tensor(42860.2305), 'train_loss_kld': tensor(549.4292)}\n",
            "{'epoch': 130, 'train_loss': tensor(43474.3633), 'train_loss_nll': tensor(42924.8789), 'train_loss_kld': tensor(549.4794)}\n",
            "{'epoch': 131, 'train_loss': tensor(43419.1797), 'train_loss_nll': tensor(42874.2188), 'train_loss_kld': tensor(544.9622)}\n",
            "{'epoch': 132, 'train_loss': tensor(43418.9062), 'train_loss_nll': tensor(42873.0234), 'train_loss_kld': tensor(545.8790)}\n",
            "{'epoch': 133, 'train_loss': tensor(43261.9688), 'train_loss_nll': tensor(42715.0469), 'train_loss_kld': tensor(546.9277)}\n",
            "{'epoch': 134, 'train_loss': tensor(43351.6289), 'train_loss_nll': tensor(42806.7695), 'train_loss_kld': tensor(544.8610)}\n",
            "{'epoch': 135, 'train_loss': tensor(43256.7109), 'train_loss_nll': tensor(42711.4766), 'train_loss_kld': tensor(545.2368)}\n",
            "{'epoch': 136, 'train_loss': tensor(43365.4492), 'train_loss_nll': tensor(42818.7383), 'train_loss_kld': tensor(546.7144)}\n",
            "{'epoch': 137, 'train_loss': tensor(43072.2109), 'train_loss_nll': tensor(42528.2344), 'train_loss_kld': tensor(543.9652)}\n",
            "{'epoch': 138, 'train_loss': tensor(43339.9062), 'train_loss_nll': tensor(42796.0586), 'train_loss_kld': tensor(543.8398)}\n",
            "{'epoch': 139, 'train_loss': tensor(43459.9805), 'train_loss_nll': tensor(42917.5469), 'train_loss_kld': tensor(542.4330)}\n",
            "{'epoch': 140, 'train_loss': tensor(43371.5156), 'train_loss_nll': tensor(42828.3633), 'train_loss_kld': tensor(543.1497)}\n",
            "{'epoch': 141, 'train_loss': tensor(43305.9805), 'train_loss_nll': tensor(42763.0547), 'train_loss_kld': tensor(542.9268)}\n",
            "{'epoch': 142, 'train_loss': tensor(43261.1602), 'train_loss_nll': tensor(42716.0156), 'train_loss_kld': tensor(545.1436)}\n",
            "{'epoch': 143, 'train_loss': tensor(43404.5195), 'train_loss_nll': tensor(42861.7500), 'train_loss_kld': tensor(542.7717)}\n",
            "{'epoch': 144, 'train_loss': tensor(43298.5391), 'train_loss_nll': tensor(42757.4258), 'train_loss_kld': tensor(541.1199)}\n",
            "{'epoch': 145, 'train_loss': tensor(43268.2969), 'train_loss_nll': tensor(42725.0859), 'train_loss_kld': tensor(543.2095)}\n",
            "{'epoch': 146, 'train_loss': tensor(43231.0508), 'train_loss_nll': tensor(42689.3281), 'train_loss_kld': tensor(541.7174)}\n",
            "{'epoch': 147, 'train_loss': tensor(43291.6133), 'train_loss_nll': tensor(42748.9805), 'train_loss_kld': tensor(542.6352)}\n",
            "{'epoch': 148, 'train_loss': tensor(43154.8164), 'train_loss_nll': tensor(42611.9961), 'train_loss_kld': tensor(542.8240)}\n",
            "{'epoch': 149, 'train_loss': tensor(43277.5234), 'train_loss_nll': tensor(42733.8281), 'train_loss_kld': tensor(543.6969)}\n",
            "{'epoch': 150, 'train_loss': tensor(43327.6484), 'train_loss_nll': tensor(42781.8086), 'train_loss_kld': tensor(545.8392)}\n",
            "{'epoch': 151, 'train_loss': tensor(43227.7305), 'train_loss_nll': tensor(42681.1211), 'train_loss_kld': tensor(546.6100)}\n",
            "{'epoch': 152, 'train_loss': tensor(43134.4102), 'train_loss_nll': tensor(42589.3594), 'train_loss_kld': tensor(545.0508)}\n",
            "{'epoch': 153, 'train_loss': tensor(43267.4961), 'train_loss_nll': tensor(42722.6133), 'train_loss_kld': tensor(544.8775)}\n",
            "{'epoch': 154, 'train_loss': tensor(43141.2969), 'train_loss_nll': tensor(42597.1094), 'train_loss_kld': tensor(544.1829)}\n",
            "{'epoch': 155, 'train_loss': tensor(43427.5781), 'train_loss_nll': tensor(42882.9453), 'train_loss_kld': tensor(544.6358)}\n",
            "{'epoch': 156, 'train_loss': tensor(43434.3984), 'train_loss_nll': tensor(42888.7812), 'train_loss_kld': tensor(545.6265)}\n",
            "{'epoch': 157, 'train_loss': tensor(43230.4102), 'train_loss_nll': tensor(42688.2305), 'train_loss_kld': tensor(542.1828)}\n",
            "{'epoch': 158, 'train_loss': tensor(43386.3984), 'train_loss_nll': tensor(42844.9648), 'train_loss_kld': tensor(541.4323)}\n",
            "{'epoch': 159, 'train_loss': tensor(43199.6484), 'train_loss_nll': tensor(42659.5664), 'train_loss_kld': tensor(540.0871)}\n",
            "{'epoch': 160, 'train_loss': tensor(43340.9297), 'train_loss_nll': tensor(42798.3945), 'train_loss_kld': tensor(542.5341)}\n",
            "{'epoch': 161, 'train_loss': tensor(43493.1914), 'train_loss_nll': tensor(42951.0117), 'train_loss_kld': tensor(542.1815)}\n",
            "{'epoch': 162, 'train_loss': tensor(43198.6133), 'train_loss_nll': tensor(42657.7969), 'train_loss_kld': tensor(540.8217)}\n",
            "{'epoch': 163, 'train_loss': tensor(43120.3398), 'train_loss_nll': tensor(42579.9336), 'train_loss_kld': tensor(540.3986)}\n",
            "{'epoch': 164, 'train_loss': tensor(43323.7266), 'train_loss_nll': tensor(42781.4531), 'train_loss_kld': tensor(542.2729)}\n",
            "{'epoch': 165, 'train_loss': tensor(43179.5859), 'train_loss_nll': tensor(42638.2539), 'train_loss_kld': tensor(541.3311)}\n",
            "{'epoch': 166, 'train_loss': tensor(43282.9844), 'train_loss_nll': tensor(42737.9688), 'train_loss_kld': tensor(545.0162)}\n",
            "{'epoch': 167, 'train_loss': tensor(43433.9414), 'train_loss_nll': tensor(42890.3359), 'train_loss_kld': tensor(543.6002)}\n",
            "{'epoch': 168, 'train_loss': tensor(43397.3906), 'train_loss_nll': tensor(42850.7891), 'train_loss_kld': tensor(546.6000)}\n",
            "{'epoch': 169, 'train_loss': tensor(43259.6406), 'train_loss_nll': tensor(42716.2344), 'train_loss_kld': tensor(543.4085)}\n",
            "{'epoch': 170, 'train_loss': tensor(43180.5039), 'train_loss_nll': tensor(42635.5586), 'train_loss_kld': tensor(544.9465)}\n",
            "{'epoch': 171, 'train_loss': tensor(43263.2695), 'train_loss_nll': tensor(42720.6641), 'train_loss_kld': tensor(542.6008)}\n",
            "{'epoch': 172, 'train_loss': tensor(43292.3789), 'train_loss_nll': tensor(42747.6055), 'train_loss_kld': tensor(544.7716)}\n",
            "{'epoch': 173, 'train_loss': tensor(43190.2734), 'train_loss_nll': tensor(42643.3789), 'train_loss_kld': tensor(546.8916)}\n",
            "{'epoch': 174, 'train_loss': tensor(43417.2812), 'train_loss_nll': tensor(42869.5742), 'train_loss_kld': tensor(547.7045)}\n",
            "{'epoch': 175, 'train_loss': tensor(43050.8711), 'train_loss_nll': tensor(42505.4297), 'train_loss_kld': tensor(545.4437)}\n",
            "{'epoch': 176, 'train_loss': tensor(43310.3047), 'train_loss_nll': tensor(42764.6836), 'train_loss_kld': tensor(545.6169)}\n",
            "{'epoch': 177, 'train_loss': tensor(43221.0742), 'train_loss_nll': tensor(42678.9219), 'train_loss_kld': tensor(542.1608)}\n",
            "{'epoch': 178, 'train_loss': tensor(43341.3164), 'train_loss_nll': tensor(42796.7617), 'train_loss_kld': tensor(544.5571)}\n",
            "{'epoch': 179, 'train_loss': tensor(43135.1484), 'train_loss_nll': tensor(42591.4883), 'train_loss_kld': tensor(543.6590)}\n",
            "{'epoch': 180, 'train_loss': tensor(43438.5117), 'train_loss_nll': tensor(42893.5703), 'train_loss_kld': tensor(544.9421)}\n",
            "{'epoch': 181, 'train_loss': tensor(43346.6992), 'train_loss_nll': tensor(42804.6836), 'train_loss_kld': tensor(542.0134)}\n",
            "{'epoch': 182, 'train_loss': tensor(43223.9453), 'train_loss_nll': tensor(42681.6602), 'train_loss_kld': tensor(542.2855)}\n",
            "{'epoch': 183, 'train_loss': tensor(43271.9609), 'train_loss_nll': tensor(42728.4492), 'train_loss_kld': tensor(543.5065)}\n",
            "{'epoch': 184, 'train_loss': tensor(43396.1484), 'train_loss_nll': tensor(42850.8633), 'train_loss_kld': tensor(545.2800)}\n",
            "{'epoch': 185, 'train_loss': tensor(43421.4883), 'train_loss_nll': tensor(42879.5352), 'train_loss_kld': tensor(541.9490)}\n",
            "{'epoch': 186, 'train_loss': tensor(43207.9414), 'train_loss_nll': tensor(42665.9531), 'train_loss_kld': tensor(541.9866)}\n",
            "{'epoch': 187, 'train_loss': tensor(43184.2031), 'train_loss_nll': tensor(42642.2617), 'train_loss_kld': tensor(541.9458)}\n",
            "{'epoch': 188, 'train_loss': tensor(43072.2852), 'train_loss_nll': tensor(42532.4297), 'train_loss_kld': tensor(539.8499)}\n",
            "{'epoch': 189, 'train_loss': tensor(43213.3281), 'train_loss_nll': tensor(42670.2109), 'train_loss_kld': tensor(543.1183)}\n",
            "{'epoch': 190, 'train_loss': tensor(43152.3438), 'train_loss_nll': tensor(42609.8750), 'train_loss_kld': tensor(542.4696)}\n",
            "{'epoch': 191, 'train_loss': tensor(43026.9336), 'train_loss_nll': tensor(42483.2852), 'train_loss_kld': tensor(543.6475)}\n",
            "{'epoch': 192, 'train_loss': tensor(43073.9414), 'train_loss_nll': tensor(42530.0391), 'train_loss_kld': tensor(543.8962)}\n",
            "{'epoch': 193, 'train_loss': tensor(43145.9688), 'train_loss_nll': tensor(42602.0352), 'train_loss_kld': tensor(543.9368)}\n",
            "{'epoch': 194, 'train_loss': tensor(43191.4141), 'train_loss_nll': tensor(42647.3008), 'train_loss_kld': tensor(544.1133)}\n",
            "{'epoch': 195, 'train_loss': tensor(43170.6016), 'train_loss_nll': tensor(42625.9336), 'train_loss_kld': tensor(544.6664)}\n",
            "{'epoch': 196, 'train_loss': tensor(42960.5781), 'train_loss_nll': tensor(42417.0234), 'train_loss_kld': tensor(543.5500)}\n",
            "{'epoch': 197, 'train_loss': tensor(43207.0703), 'train_loss_nll': tensor(42664.4414), 'train_loss_kld': tensor(542.6266)}\n",
            "{'epoch': 198, 'train_loss': tensor(43107.2344), 'train_loss_nll': tensor(42563.8438), 'train_loss_kld': tensor(543.3878)}\n",
            "{'epoch': 199, 'train_loss': tensor(43164.1055), 'train_loss_nll': tensor(42619.1602), 'train_loss_kld': tensor(544.9440)}\n",
            "{'epoch': 200, 'train_loss': tensor(43216.8555), 'train_loss_nll': tensor(42670.9531), 'train_loss_kld': tensor(545.8979)}\n",
            "{'epoch': 1, 'train_loss': tensor(43261.2617), 'train_loss_nll': tensor(42717.4102), 'train_loss_kld': tensor(543.8480)}\n",
            "{'epoch': 2, 'train_loss': tensor(43183.3281), 'train_loss_nll': tensor(42641.9648), 'train_loss_kld': tensor(541.3683)}\n",
            "{'epoch': 3, 'train_loss': tensor(43325.9648), 'train_loss_nll': tensor(42786.7188), 'train_loss_kld': tensor(539.2404)}\n",
            "{'epoch': 4, 'train_loss': tensor(42984.6133), 'train_loss_nll': tensor(42444.8047), 'train_loss_kld': tensor(539.8108)}\n",
            "{'epoch': 5, 'train_loss': tensor(43263.2188), 'train_loss_nll': tensor(42724.6836), 'train_loss_kld': tensor(538.5392)}\n",
            "{'epoch': 6, 'train_loss': tensor(43125.1992), 'train_loss_nll': tensor(42587.7656), 'train_loss_kld': tensor(537.4318)}\n",
            "{'epoch': 7, 'train_loss': tensor(43096.5508), 'train_loss_nll': tensor(42559.6914), 'train_loss_kld': tensor(536.8655)}\n",
            "{'epoch': 8, 'train_loss': tensor(43243.3086), 'train_loss_nll': tensor(42706.5352), 'train_loss_kld': tensor(536.7748)}\n",
            "{'epoch': 9, 'train_loss': tensor(43193.3359), 'train_loss_nll': tensor(42657.3164), 'train_loss_kld': tensor(536.0168)}\n",
            "{'epoch': 10, 'train_loss': tensor(43141.5703), 'train_loss_nll': tensor(42605.0898), 'train_loss_kld': tensor(536.4730)}\n",
            "{'epoch': 11, 'train_loss': tensor(43139.9961), 'train_loss_nll': tensor(42602.4414), 'train_loss_kld': tensor(537.5549)}\n",
            "{'epoch': 12, 'train_loss': tensor(43107.0039), 'train_loss_nll': tensor(42571.5156), 'train_loss_kld': tensor(535.4865)}\n",
            "{'epoch': 13, 'train_loss': tensor(43174.8945), 'train_loss_nll': tensor(42639.4062), 'train_loss_kld': tensor(535.4894)}\n",
            "{'epoch': 14, 'train_loss': tensor(43446.2852), 'train_loss_nll': tensor(42908.8047), 'train_loss_kld': tensor(537.4855)}\n",
            "{'epoch': 15, 'train_loss': tensor(43133.7461), 'train_loss_nll': tensor(42593.3789), 'train_loss_kld': tensor(540.3668)}\n",
            "{'epoch': 16, 'train_loss': tensor(43412.6406), 'train_loss_nll': tensor(42873.3633), 'train_loss_kld': tensor(539.2700)}\n",
            "{'epoch': 17, 'train_loss': tensor(43156.5312), 'train_loss_nll': tensor(42617.5391), 'train_loss_kld': tensor(538.9941)}\n",
            "{'epoch': 18, 'train_loss': tensor(43076.8867), 'train_loss_nll': tensor(42538.5742), 'train_loss_kld': tensor(538.3051)}\n",
            "{'epoch': 19, 'train_loss': tensor(43141.0195), 'train_loss_nll': tensor(42601.7266), 'train_loss_kld': tensor(539.2932)}\n",
            "{'epoch': 20, 'train_loss': tensor(43249.9297), 'train_loss_nll': tensor(42701.9844), 'train_loss_kld': tensor(547.9480)}\n",
            "{'epoch': 21, 'train_loss': tensor(43310.5586), 'train_loss_nll': tensor(42758.6094), 'train_loss_kld': tensor(551.9505)}\n",
            "{'epoch': 22, 'train_loss': tensor(43336.7383), 'train_loss_nll': tensor(42788.8711), 'train_loss_kld': tensor(547.8727)}\n",
            "{'epoch': 23, 'train_loss': tensor(43175.1953), 'train_loss_nll': tensor(42630.6016), 'train_loss_kld': tensor(544.5941)}\n",
            "{'epoch': 24, 'train_loss': tensor(43131.9219), 'train_loss_nll': tensor(42588.7617), 'train_loss_kld': tensor(543.1669)}\n",
            "{'epoch': 25, 'train_loss': tensor(43300.5117), 'train_loss_nll': tensor(42757.8438), 'train_loss_kld': tensor(542.6683)}\n",
            "{'epoch': 26, 'train_loss': tensor(43368.7969), 'train_loss_nll': tensor(42826.2617), 'train_loss_kld': tensor(542.5320)}\n",
            "{'epoch': 27, 'train_loss': tensor(43032.3945), 'train_loss_nll': tensor(42491.1914), 'train_loss_kld': tensor(541.2080)}\n",
            "{'epoch': 28, 'train_loss': tensor(43081.9062), 'train_loss_nll': tensor(42539.3008), 'train_loss_kld': tensor(542.6051)}\n",
            "{'epoch': 29, 'train_loss': tensor(43121.8906), 'train_loss_nll': tensor(42580.4336), 'train_loss_kld': tensor(541.4554)}\n",
            "{'epoch': 30, 'train_loss': tensor(43292.8906), 'train_loss_nll': tensor(42750.6211), 'train_loss_kld': tensor(542.2715)}\n",
            "{'epoch': 31, 'train_loss': tensor(43092.2188), 'train_loss_nll': tensor(42552.6992), 'train_loss_kld': tensor(539.5217)}\n",
            "{'epoch': 32, 'train_loss': tensor(43079.4453), 'train_loss_nll': tensor(42538.0391), 'train_loss_kld': tensor(541.4022)}\n",
            "{'epoch': 33, 'train_loss': tensor(43144.7461), 'train_loss_nll': tensor(42606.9688), 'train_loss_kld': tensor(537.7725)}\n",
            "{'epoch': 34, 'train_loss': tensor(43039.2148), 'train_loss_nll': tensor(42501.0391), 'train_loss_kld': tensor(538.1750)}\n",
            "{'epoch': 35, 'train_loss': tensor(43014.8242), 'train_loss_nll': tensor(42476.4453), 'train_loss_kld': tensor(538.3835)}\n",
            "{'epoch': 36, 'train_loss': tensor(43095.9883), 'train_loss_nll': tensor(42556.6719), 'train_loss_kld': tensor(539.3221)}\n",
            "{'epoch': 37, 'train_loss': tensor(43291.8711), 'train_loss_nll': tensor(42754.), 'train_loss_kld': tensor(537.8696)}\n",
            "{'epoch': 38, 'train_loss': tensor(43007.8516), 'train_loss_nll': tensor(42469.5312), 'train_loss_kld': tensor(538.3187)}\n",
            "{'epoch': 39, 'train_loss': tensor(43152.4492), 'train_loss_nll': tensor(42613.), 'train_loss_kld': tensor(539.4445)}\n",
            "{'epoch': 40, 'train_loss': tensor(43192.7148), 'train_loss_nll': tensor(42654.4141), 'train_loss_kld': tensor(538.2979)}\n",
            "{'epoch': 41, 'train_loss': tensor(43006.5195), 'train_loss_nll': tensor(42471.1719), 'train_loss_kld': tensor(535.3503)}\n",
            "{'epoch': 42, 'train_loss': tensor(43137.5664), 'train_loss_nll': tensor(42599.7461), 'train_loss_kld': tensor(537.8181)}\n",
            "{'epoch': 43, 'train_loss': tensor(42988.7852), 'train_loss_nll': tensor(42451.5000), 'train_loss_kld': tensor(537.2819)}\n",
            "{'epoch': 44, 'train_loss': tensor(43130.1367), 'train_loss_nll': tensor(42590.9492), 'train_loss_kld': tensor(539.1835)}\n",
            "{'epoch': 45, 'train_loss': tensor(43161.1719), 'train_loss_nll': tensor(42623.6719), 'train_loss_kld': tensor(537.4968)}\n",
            "{'epoch': 46, 'train_loss': tensor(43015.8203), 'train_loss_nll': tensor(42476.3281), 'train_loss_kld': tensor(539.4893)}\n",
            "{'epoch': 47, 'train_loss': tensor(42993.6562), 'train_loss_nll': tensor(42456.1953), 'train_loss_kld': tensor(537.4613)}\n",
            "{'epoch': 48, 'train_loss': tensor(43083.7656), 'train_loss_nll': tensor(42543.6602), 'train_loss_kld': tensor(540.1023)}\n",
            "{'epoch': 49, 'train_loss': tensor(43043.4766), 'train_loss_nll': tensor(42506.6133), 'train_loss_kld': tensor(536.8566)}\n",
            "{'epoch': 50, 'train_loss': tensor(43003.7383), 'train_loss_nll': tensor(42464.8359), 'train_loss_kld': tensor(538.9055)}\n",
            "{'epoch': 51, 'train_loss': tensor(43279.8906), 'train_loss_nll': tensor(42741.5781), 'train_loss_kld': tensor(538.3079)}\n",
            "{'epoch': 52, 'train_loss': tensor(43174.0664), 'train_loss_nll': tensor(42634.3086), 'train_loss_kld': tensor(539.7523)}\n",
            "{'epoch': 53, 'train_loss': tensor(43153.9258), 'train_loss_nll': tensor(42613.6992), 'train_loss_kld': tensor(540.2187)}\n",
            "{'epoch': 54, 'train_loss': tensor(42958.6836), 'train_loss_nll': tensor(42419.9688), 'train_loss_kld': tensor(538.7149)}\n",
            "{'epoch': 55, 'train_loss': tensor(43059.2812), 'train_loss_nll': tensor(42519.2734), 'train_loss_kld': tensor(540.0030)}\n",
            "{'epoch': 56, 'train_loss': tensor(42798.6602), 'train_loss_nll': tensor(42257.6562), 'train_loss_kld': tensor(541.0066)}\n",
            "{'epoch': 57, 'train_loss': tensor(42883.0469), 'train_loss_nll': tensor(42344.6758), 'train_loss_kld': tensor(538.3736)}\n",
            "{'epoch': 58, 'train_loss': tensor(43023.4414), 'train_loss_nll': tensor(42486.8047), 'train_loss_kld': tensor(536.6382)}\n",
            "{'epoch': 59, 'train_loss': tensor(43041.3945), 'train_loss_nll': tensor(42502.3945), 'train_loss_kld': tensor(539.0022)}\n",
            "{'epoch': 60, 'train_loss': tensor(43195.0508), 'train_loss_nll': tensor(42657.6211), 'train_loss_kld': tensor(537.4304)}\n",
            "{'epoch': 61, 'train_loss': tensor(43104.9531), 'train_loss_nll': tensor(42569.6055), 'train_loss_kld': tensor(535.3544)}\n",
            "{'epoch': 62, 'train_loss': tensor(42663.1406), 'train_loss_nll': tensor(42125.9258), 'train_loss_kld': tensor(537.2193)}\n",
            "{'epoch': 63, 'train_loss': tensor(42825.3594), 'train_loss_nll': tensor(42289.2266), 'train_loss_kld': tensor(536.1345)}\n",
            "{'epoch': 64, 'train_loss': tensor(43003.0742), 'train_loss_nll': tensor(42467.1914), 'train_loss_kld': tensor(535.8826)}\n",
            "{'epoch': 65, 'train_loss': tensor(43020.7461), 'train_loss_nll': tensor(42484.0703), 'train_loss_kld': tensor(536.6690)}\n",
            "{'epoch': 66, 'train_loss': tensor(42922.3164), 'train_loss_nll': tensor(42387.4688), 'train_loss_kld': tensor(534.8481)}\n",
            "{'epoch': 67, 'train_loss': tensor(43118.1562), 'train_loss_nll': tensor(42579.6445), 'train_loss_kld': tensor(538.5087)}\n",
            "{'epoch': 68, 'train_loss': tensor(42863.1250), 'train_loss_nll': tensor(42324.6367), 'train_loss_kld': tensor(538.4864)}\n",
            "{'epoch': 69, 'train_loss': tensor(43042.0508), 'train_loss_nll': tensor(42503.8281), 'train_loss_kld': tensor(538.2228)}\n",
            "{'epoch': 70, 'train_loss': tensor(43010.1211), 'train_loss_nll': tensor(42469.5742), 'train_loss_kld': tensor(540.5441)}\n",
            "{'epoch': 71, 'train_loss': tensor(43043.0117), 'train_loss_nll': tensor(42505.7500), 'train_loss_kld': tensor(537.2635)}\n",
            "{'epoch': 72, 'train_loss': tensor(43004.4336), 'train_loss_nll': tensor(42464.9844), 'train_loss_kld': tensor(539.4455)}\n",
            "{'epoch': 73, 'train_loss': tensor(42892.4492), 'train_loss_nll': tensor(42354.8867), 'train_loss_kld': tensor(537.5717)}\n",
            "{'epoch': 74, 'train_loss': tensor(42963.9297), 'train_loss_nll': tensor(42426.6289), 'train_loss_kld': tensor(537.2989)}\n",
            "{'epoch': 75, 'train_loss': tensor(43127.4102), 'train_loss_nll': tensor(42589.3750), 'train_loss_kld': tensor(538.0319)}\n",
            "{'epoch': 76, 'train_loss': tensor(42891.9219), 'train_loss_nll': tensor(42354.8516), 'train_loss_kld': tensor(537.0728)}\n",
            "{'epoch': 77, 'train_loss': tensor(42953.6094), 'train_loss_nll': tensor(42418.5703), 'train_loss_kld': tensor(535.0389)}\n",
            "{'epoch': 78, 'train_loss': tensor(42860.5508), 'train_loss_nll': tensor(42322.5547), 'train_loss_kld': tensor(537.9963)}\n",
            "{'epoch': 79, 'train_loss': tensor(43027.4688), 'train_loss_nll': tensor(42488.7812), 'train_loss_kld': tensor(538.6868)}\n",
            "{'epoch': 80, 'train_loss': tensor(43043.0664), 'train_loss_nll': tensor(42504.2812), 'train_loss_kld': tensor(538.7885)}\n",
            "{'epoch': 81, 'train_loss': tensor(43085.2617), 'train_loss_nll': tensor(42546.1719), 'train_loss_kld': tensor(539.0860)}\n",
            "{'epoch': 82, 'train_loss': tensor(42935.1250), 'train_loss_nll': tensor(42395.2891), 'train_loss_kld': tensor(539.8353)}\n",
            "{'epoch': 83, 'train_loss': tensor(43066.7461), 'train_loss_nll': tensor(42526.5195), 'train_loss_kld': tensor(540.2268)}\n",
            "{'epoch': 84, 'train_loss': tensor(43059.6836), 'train_loss_nll': tensor(42519.8906), 'train_loss_kld': tensor(539.7971)}\n",
            "{'epoch': 85, 'train_loss': tensor(43088.6641), 'train_loss_nll': tensor(42546.3086), 'train_loss_kld': tensor(542.3574)}\n",
            "{'epoch': 86, 'train_loss': tensor(43014.5664), 'train_loss_nll': tensor(42472.5234), 'train_loss_kld': tensor(542.0430)}\n",
            "{'epoch': 87, 'train_loss': tensor(42981.2812), 'train_loss_nll': tensor(42439.4453), 'train_loss_kld': tensor(541.8388)}\n",
            "{'epoch': 88, 'train_loss': tensor(43019.5781), 'train_loss_nll': tensor(42476.8789), 'train_loss_kld': tensor(542.6966)}\n",
            "{'epoch': 89, 'train_loss': tensor(43123.2188), 'train_loss_nll': tensor(42580.1602), 'train_loss_kld': tensor(543.0665)}\n",
            "{'epoch': 90, 'train_loss': tensor(43179.4219), 'train_loss_nll': tensor(42632.1016), 'train_loss_kld': tensor(547.3219)}\n",
            "{'epoch': 91, 'train_loss': tensor(43121.2383), 'train_loss_nll': tensor(42571.7383), 'train_loss_kld': tensor(549.4988)}\n",
            "{'epoch': 92, 'train_loss': tensor(42815.2617), 'train_loss_nll': tensor(42266.7539), 'train_loss_kld': tensor(548.5060)}\n",
            "{'epoch': 93, 'train_loss': tensor(42840.7344), 'train_loss_nll': tensor(42295.3203), 'train_loss_kld': tensor(545.4172)}\n",
            "{'epoch': 94, 'train_loss': tensor(43101.9258), 'train_loss_nll': tensor(42558.4102), 'train_loss_kld': tensor(543.5203)}\n",
            "{'epoch': 95, 'train_loss': tensor(43001.4805), 'train_loss_nll': tensor(42458.3867), 'train_loss_kld': tensor(543.0995)}\n",
            "{'epoch': 96, 'train_loss': tensor(42940.8047), 'train_loss_nll': tensor(42396.0156), 'train_loss_kld': tensor(544.7915)}\n",
            "{'epoch': 97, 'train_loss': tensor(43010.2852), 'train_loss_nll': tensor(42462.2617), 'train_loss_kld': tensor(548.0247)}\n",
            "{'epoch': 98, 'train_loss': tensor(42797.2344), 'train_loss_nll': tensor(42248.8984), 'train_loss_kld': tensor(548.3342)}\n",
            "{'epoch': 99, 'train_loss': tensor(43086.2539), 'train_loss_nll': tensor(42541.1445), 'train_loss_kld': tensor(545.1085)}\n",
            "{'epoch': 100, 'train_loss': tensor(42934.3086), 'train_loss_nll': tensor(42389.7305), 'train_loss_kld': tensor(544.5736)}\n",
            "{'epoch': 101, 'train_loss': tensor(42950.2617), 'train_loss_nll': tensor(42405.9141), 'train_loss_kld': tensor(544.3459)}\n",
            "{'epoch': 102, 'train_loss': tensor(42977.1641), 'train_loss_nll': tensor(42434.1055), 'train_loss_kld': tensor(543.0594)}\n",
            "{'epoch': 103, 'train_loss': tensor(42914.0938), 'train_loss_nll': tensor(42370.6641), 'train_loss_kld': tensor(543.4343)}\n",
            "{'epoch': 104, 'train_loss': tensor(42925.5586), 'train_loss_nll': tensor(42382.7383), 'train_loss_kld': tensor(542.8176)}\n",
            "{'epoch': 105, 'train_loss': tensor(42860.3281), 'train_loss_nll': tensor(42317.3906), 'train_loss_kld': tensor(542.9422)}\n",
            "{'epoch': 106, 'train_loss': tensor(43245.6914), 'train_loss_nll': tensor(42700.3750), 'train_loss_kld': tensor(545.3218)}\n",
            "{'epoch': 107, 'train_loss': tensor(43137.6289), 'train_loss_nll': tensor(42586.0156), 'train_loss_kld': tensor(551.6143)}\n",
            "{'epoch': 108, 'train_loss': tensor(42861.7539), 'train_loss_nll': tensor(42307.3086), 'train_loss_kld': tensor(554.4464)}\n",
            "{'epoch': 109, 'train_loss': tensor(43058.9492), 'train_loss_nll': tensor(42505.1133), 'train_loss_kld': tensor(553.8353)}\n",
            "{'epoch': 110, 'train_loss': tensor(42960.6211), 'train_loss_nll': tensor(42409.8711), 'train_loss_kld': tensor(550.7482)}\n",
            "{'epoch': 111, 'train_loss': tensor(42981.3867), 'train_loss_nll': tensor(42425.0703), 'train_loss_kld': tensor(556.3124)}\n",
            "{'epoch': 112, 'train_loss': tensor(43413.4883), 'train_loss_nll': tensor(42859.7148), 'train_loss_kld': tensor(553.7752)}\n",
            "{'epoch': 113, 'train_loss': tensor(42819.7031), 'train_loss_nll': tensor(42267.7734), 'train_loss_kld': tensor(551.9290)}\n",
            "{'epoch': 114, 'train_loss': tensor(42988.4688), 'train_loss_nll': tensor(42440.4492), 'train_loss_kld': tensor(548.0125)}\n",
            "{'epoch': 115, 'train_loss': tensor(43188.5391), 'train_loss_nll': tensor(42640.2812), 'train_loss_kld': tensor(548.2597)}\n",
            "{'epoch': 116, 'train_loss': tensor(43095.9883), 'train_loss_nll': tensor(42546.4531), 'train_loss_kld': tensor(549.5403)}\n",
            "{'epoch': 117, 'train_loss': tensor(42984.3711), 'train_loss_nll': tensor(42438.0352), 'train_loss_kld': tensor(546.3334)}\n",
            "{'epoch': 118, 'train_loss': tensor(42995.4219), 'train_loss_nll': tensor(42447.2344), 'train_loss_kld': tensor(548.1819)}\n",
            "{'epoch': 119, 'train_loss': tensor(42907.5469), 'train_loss_nll': tensor(42356.5586), 'train_loss_kld': tensor(550.9825)}\n",
            "{'epoch': 120, 'train_loss': tensor(42927.0898), 'train_loss_nll': tensor(42374.1719), 'train_loss_kld': tensor(552.9203)}\n",
            "{'epoch': 121, 'train_loss': tensor(43382.7461), 'train_loss_nll': tensor(42822.5938), 'train_loss_kld': tensor(560.1519)}\n",
            "{'epoch': 122, 'train_loss': tensor(43310.2109), 'train_loss_nll': tensor(42736.3438), 'train_loss_kld': tensor(573.8657)}\n",
            "{'epoch': 123, 'train_loss': tensor(43404.7109), 'train_loss_nll': tensor(42826.0938), 'train_loss_kld': tensor(578.6111)}\n",
            "{'epoch': 124, 'train_loss': tensor(43557.6367), 'train_loss_nll': tensor(42982.4102), 'train_loss_kld': tensor(575.2264)}\n",
            "{'epoch': 125, 'train_loss': tensor(43331.3086), 'train_loss_nll': tensor(42755.8906), 'train_loss_kld': tensor(575.4257)}\n",
            "{'epoch': 126, 'train_loss': tensor(43339.6602), 'train_loss_nll': tensor(42771.7266), 'train_loss_kld': tensor(567.9353)}\n",
            "{'epoch': 127, 'train_loss': tensor(43147.5352), 'train_loss_nll': tensor(42580.7188), 'train_loss_kld': tensor(566.8159)}\n",
            "{'epoch': 128, 'train_loss': tensor(43287.3438), 'train_loss_nll': tensor(42721.9609), 'train_loss_kld': tensor(565.3878)}\n",
            "{'epoch': 129, 'train_loss': tensor(43161.3398), 'train_loss_nll': tensor(42594.9805), 'train_loss_kld': tensor(566.3631)}\n",
            "{'epoch': 130, 'train_loss': tensor(43317.8594), 'train_loss_nll': tensor(42754.0312), 'train_loss_kld': tensor(563.8317)}\n",
            "{'epoch': 131, 'train_loss': tensor(43242.8047), 'train_loss_nll': tensor(42685.8203), 'train_loss_kld': tensor(556.9896)}\n",
            "{'epoch': 132, 'train_loss': tensor(43345.4883), 'train_loss_nll': tensor(42785.6367), 'train_loss_kld': tensor(559.8510)}\n",
            "{'epoch': 133, 'train_loss': tensor(43223.2812), 'train_loss_nll': tensor(42667.5039), 'train_loss_kld': tensor(555.7722)}\n",
            "{'epoch': 134, 'train_loss': tensor(43190.3242), 'train_loss_nll': tensor(42635.3008), 'train_loss_kld': tensor(555.0211)}\n",
            "{'epoch': 135, 'train_loss': tensor(42861.8516), 'train_loss_nll': tensor(42306.6289), 'train_loss_kld': tensor(555.2205)}\n",
            "{'epoch': 136, 'train_loss': tensor(43062.3281), 'train_loss_nll': tensor(42509.6797), 'train_loss_kld': tensor(552.6534)}\n",
            "{'epoch': 137, 'train_loss': tensor(43109.9531), 'train_loss_nll': tensor(42556.8398), 'train_loss_kld': tensor(553.1151)}\n",
            "{'epoch': 138, 'train_loss': tensor(43215.3594), 'train_loss_nll': tensor(42661.5117), 'train_loss_kld': tensor(553.8566)}\n",
            "{'epoch': 139, 'train_loss': tensor(43290.8438), 'train_loss_nll': tensor(42738.9336), 'train_loss_kld': tensor(551.9077)}\n",
            "{'epoch': 140, 'train_loss': tensor(43285.0469), 'train_loss_nll': tensor(42729.9531), 'train_loss_kld': tensor(555.0969)}\n",
            "{'epoch': 141, 'train_loss': tensor(43122.4531), 'train_loss_nll': tensor(42563.1953), 'train_loss_kld': tensor(559.2600)}\n",
            "{'epoch': 142, 'train_loss': tensor(43549.4219), 'train_loss_nll': tensor(42996.7031), 'train_loss_kld': tensor(552.7198)}\n",
            "{'epoch': 143, 'train_loss': tensor(43188.9336), 'train_loss_nll': tensor(42634.6094), 'train_loss_kld': tensor(554.3285)}\n",
            "{'epoch': 144, 'train_loss': tensor(42967.8086), 'train_loss_nll': tensor(42413.5703), 'train_loss_kld': tensor(554.2388)}\n",
            "{'epoch': 145, 'train_loss': tensor(43071.7812), 'train_loss_nll': tensor(42517.7969), 'train_loss_kld': tensor(553.9819)}\n",
            "{'epoch': 146, 'train_loss': tensor(43139.2812), 'train_loss_nll': tensor(42586.4844), 'train_loss_kld': tensor(552.7979)}\n",
            "{'epoch': 147, 'train_loss': tensor(43100.8594), 'train_loss_nll': tensor(42549.9844), 'train_loss_kld': tensor(550.8791)}\n",
            "{'epoch': 148, 'train_loss': tensor(43095.9492), 'train_loss_nll': tensor(42545.0781), 'train_loss_kld': tensor(550.8611)}\n",
            "{'epoch': 149, 'train_loss': tensor(43399.8359), 'train_loss_nll': tensor(42850.5195), 'train_loss_kld': tensor(549.3141)}\n",
            "{'epoch': 150, 'train_loss': tensor(43052.4531), 'train_loss_nll': tensor(42501.8086), 'train_loss_kld': tensor(550.6459)}\n",
            "{'epoch': 151, 'train_loss': tensor(42895.0508), 'train_loss_nll': tensor(42345.2891), 'train_loss_kld': tensor(549.7563)}\n",
            "{'epoch': 152, 'train_loss': tensor(42993.6016), 'train_loss_nll': tensor(42445.4414), 'train_loss_kld': tensor(548.1568)}\n",
            "{'epoch': 153, 'train_loss': tensor(42980.1914), 'train_loss_nll': tensor(42431.7969), 'train_loss_kld': tensor(548.3862)}\n",
            "{'epoch': 154, 'train_loss': tensor(43212.9062), 'train_loss_nll': tensor(42663.6133), 'train_loss_kld': tensor(549.2828)}\n",
            "{'epoch': 155, 'train_loss': tensor(42935.6016), 'train_loss_nll': tensor(42385.6758), 'train_loss_kld': tensor(549.9257)}\n",
            "{'epoch': 156, 'train_loss': tensor(43091.3906), 'train_loss_nll': tensor(42540.5312), 'train_loss_kld': tensor(550.8624)}\n",
            "{'epoch': 157, 'train_loss': tensor(43041.2812), 'train_loss_nll': tensor(42493.1094), 'train_loss_kld': tensor(548.1697)}\n",
            "{'epoch': 158, 'train_loss': tensor(42944.3906), 'train_loss_nll': tensor(42394.5703), 'train_loss_kld': tensor(549.8171)}\n",
            "{'epoch': 159, 'train_loss': tensor(42799.1211), 'train_loss_nll': tensor(42248.6211), 'train_loss_kld': tensor(550.5027)}\n",
            "{'epoch': 160, 'train_loss': tensor(43042.5039), 'train_loss_nll': tensor(42495.4766), 'train_loss_kld': tensor(547.0277)}\n",
            "{'epoch': 161, 'train_loss': tensor(42960.4688), 'train_loss_nll': tensor(42411.8867), 'train_loss_kld': tensor(548.5873)}\n",
            "{'epoch': 162, 'train_loss': tensor(42930.5898), 'train_loss_nll': tensor(42383.1992), 'train_loss_kld': tensor(547.3904)}\n",
            "{'epoch': 163, 'train_loss': tensor(43037.9883), 'train_loss_nll': tensor(42488.5547), 'train_loss_kld': tensor(549.4391)}\n",
            "{'epoch': 164, 'train_loss': tensor(42978.8711), 'train_loss_nll': tensor(42431.8984), 'train_loss_kld': tensor(546.9765)}\n",
            "{'epoch': 165, 'train_loss': tensor(42831.6055), 'train_loss_nll': tensor(42281.4531), 'train_loss_kld': tensor(550.1513)}\n",
            "{'epoch': 166, 'train_loss': tensor(42764.2539), 'train_loss_nll': tensor(42219.0938), 'train_loss_kld': tensor(545.1561)}\n",
            "{'epoch': 167, 'train_loss': tensor(42914.7383), 'train_loss_nll': tensor(42367.8516), 'train_loss_kld': tensor(546.8923)}\n",
            "{'epoch': 168, 'train_loss': tensor(42990.6562), 'train_loss_nll': tensor(42445.3984), 'train_loss_kld': tensor(545.2533)}\n",
            "{'epoch': 169, 'train_loss': tensor(42739.6484), 'train_loss_nll': tensor(42193.1914), 'train_loss_kld': tensor(546.4601)}\n",
            "{'epoch': 170, 'train_loss': tensor(43090.3008), 'train_loss_nll': tensor(42546.8281), 'train_loss_kld': tensor(543.4713)}\n",
            "{'epoch': 171, 'train_loss': tensor(42995.1562), 'train_loss_nll': tensor(42449.8789), 'train_loss_kld': tensor(545.2742)}\n",
            "{'epoch': 172, 'train_loss': tensor(42872.7109), 'train_loss_nll': tensor(42331.6250), 'train_loss_kld': tensor(541.0876)}\n",
            "{'epoch': 173, 'train_loss': tensor(42740.5586), 'train_loss_nll': tensor(42198.4805), 'train_loss_kld': tensor(542.0777)}\n",
            "{'epoch': 174, 'train_loss': tensor(42736.9297), 'train_loss_nll': tensor(42195.2695), 'train_loss_kld': tensor(541.6603)}\n",
            "{'epoch': 175, 'train_loss': tensor(43084.5508), 'train_loss_nll': tensor(42540.0391), 'train_loss_kld': tensor(544.5082)}\n",
            "{'epoch': 176, 'train_loss': tensor(42894.7891), 'train_loss_nll': tensor(42349.8203), 'train_loss_kld': tensor(544.9736)}\n",
            "{'epoch': 177, 'train_loss': tensor(42753.6641), 'train_loss_nll': tensor(42208.2188), 'train_loss_kld': tensor(545.4473)}\n",
            "{'epoch': 178, 'train_loss': tensor(42732.7695), 'train_loss_nll': tensor(42191.5234), 'train_loss_kld': tensor(541.2443)}\n",
            "{'epoch': 179, 'train_loss': tensor(42878.3594), 'train_loss_nll': tensor(42336.3984), 'train_loss_kld': tensor(541.9604)}\n",
            "{'epoch': 180, 'train_loss': tensor(42574.4102), 'train_loss_nll': tensor(42030.6250), 'train_loss_kld': tensor(543.7852)}\n",
            "{'epoch': 181, 'train_loss': tensor(42807.0898), 'train_loss_nll': tensor(42262.7734), 'train_loss_kld': tensor(544.3159)}\n",
            "{'epoch': 182, 'train_loss': tensor(42689.1094), 'train_loss_nll': tensor(42148.1367), 'train_loss_kld': tensor(540.9810)}\n",
            "{'epoch': 183, 'train_loss': tensor(42701.9453), 'train_loss_nll': tensor(42160.5703), 'train_loss_kld': tensor(541.3728)}\n",
            "{'epoch': 184, 'train_loss': tensor(42708.2383), 'train_loss_nll': tensor(42169.3242), 'train_loss_kld': tensor(538.9171)}\n",
            "{'epoch': 185, 'train_loss': tensor(43070.1602), 'train_loss_nll': tensor(42529.3789), 'train_loss_kld': tensor(540.7766)}\n",
            "{'epoch': 186, 'train_loss': tensor(43039.9609), 'train_loss_nll': tensor(42497.4102), 'train_loss_kld': tensor(542.5494)}\n",
            "{'epoch': 187, 'train_loss': tensor(42824.3984), 'train_loss_nll': tensor(42282.8867), 'train_loss_kld': tensor(541.5123)}\n",
            "{'epoch': 188, 'train_loss': tensor(42918.6562), 'train_loss_nll': tensor(42376.8594), 'train_loss_kld': tensor(541.7928)}\n",
            "{'epoch': 189, 'train_loss': tensor(42658.1406), 'train_loss_nll': tensor(42117.6094), 'train_loss_kld': tensor(540.5305)}\n",
            "{'epoch': 190, 'train_loss': tensor(42855.3164), 'train_loss_nll': tensor(42313.5234), 'train_loss_kld': tensor(541.7941)}\n",
            "{'epoch': 191, 'train_loss': tensor(42879.8906), 'train_loss_nll': tensor(42338.3789), 'train_loss_kld': tensor(541.5092)}\n",
            "{'epoch': 192, 'train_loss': tensor(42887.0547), 'train_loss_nll': tensor(42346.0117), 'train_loss_kld': tensor(541.0475)}\n",
            "{'epoch': 193, 'train_loss': tensor(42857.2852), 'train_loss_nll': tensor(42315.7461), 'train_loss_kld': tensor(541.5367)}\n",
            "{'epoch': 194, 'train_loss': tensor(42675.6055), 'train_loss_nll': tensor(42132.9883), 'train_loss_kld': tensor(542.6195)}\n",
            "{'epoch': 195, 'train_loss': tensor(42790.4766), 'train_loss_nll': tensor(42249.9336), 'train_loss_kld': tensor(540.5396)}\n",
            "{'epoch': 196, 'train_loss': tensor(42733.2852), 'train_loss_nll': tensor(42193.0898), 'train_loss_kld': tensor(540.1975)}\n",
            "{'epoch': 197, 'train_loss': tensor(42928.3984), 'train_loss_nll': tensor(42386.3398), 'train_loss_kld': tensor(542.0649)}\n",
            "{'epoch': 198, 'train_loss': tensor(42913.0195), 'train_loss_nll': tensor(42371.6016), 'train_loss_kld': tensor(541.4177)}\n",
            "{'epoch': 199, 'train_loss': tensor(42832.1211), 'train_loss_nll': tensor(42290.0195), 'train_loss_kld': tensor(542.1023)}\n",
            "{'epoch': 200, 'train_loss': tensor(42794.8008), 'train_loss_nll': tensor(42253.9453), 'train_loss_kld': tensor(540.8498)}\n",
            "{'epoch': 1, 'train_loss': tensor(42836.2812), 'train_loss_nll': tensor(42298.2852), 'train_loss_kld': tensor(537.9963)}\n",
            "{'epoch': 2, 'train_loss': tensor(42859.5938), 'train_loss_nll': tensor(42324.0117), 'train_loss_kld': tensor(535.5804)}\n",
            "{'epoch': 3, 'train_loss': tensor(42775.3203), 'train_loss_nll': tensor(42240.4961), 'train_loss_kld': tensor(534.8262)}\n",
            "{'epoch': 4, 'train_loss': tensor(42891.4766), 'train_loss_nll': tensor(42356.0898), 'train_loss_kld': tensor(535.3860)}\n",
            "{'epoch': 5, 'train_loss': tensor(42923.0156), 'train_loss_nll': tensor(42383.4961), 'train_loss_kld': tensor(539.5173)}\n",
            "{'epoch': 6, 'train_loss': tensor(43014.6016), 'train_loss_nll': tensor(42477.8086), 'train_loss_kld': tensor(536.7932)}\n",
            "{'epoch': 7, 'train_loss': tensor(42646.6094), 'train_loss_nll': tensor(42110.8516), 'train_loss_kld': tensor(535.7628)}\n",
            "{'epoch': 8, 'train_loss': tensor(42831.7617), 'train_loss_nll': tensor(42296.4766), 'train_loss_kld': tensor(535.2869)}\n",
            "{'epoch': 9, 'train_loss': tensor(43030.), 'train_loss_nll': tensor(42495.6289), 'train_loss_kld': tensor(534.3721)}\n",
            "{'epoch': 10, 'train_loss': tensor(43020.9688), 'train_loss_nll': tensor(42486.6914), 'train_loss_kld': tensor(534.2768)}\n",
            "{'epoch': 11, 'train_loss': tensor(42812.2383), 'train_loss_nll': tensor(42276.9609), 'train_loss_kld': tensor(535.2881)}\n",
            "{'epoch': 12, 'train_loss': tensor(43133.3281), 'train_loss_nll': tensor(42598.3555), 'train_loss_kld': tensor(534.9791)}\n",
            "{'epoch': 13, 'train_loss': tensor(42980.8086), 'train_loss_nll': tensor(42446.9102), 'train_loss_kld': tensor(533.8948)}\n",
            "{'epoch': 14, 'train_loss': tensor(42722.0469), 'train_loss_nll': tensor(42189.2656), 'train_loss_kld': tensor(532.7794)}\n",
            "{'epoch': 15, 'train_loss': tensor(42808.8203), 'train_loss_nll': tensor(42275.2695), 'train_loss_kld': tensor(533.5515)}\n",
            "{'epoch': 16, 'train_loss': tensor(42778.7734), 'train_loss_nll': tensor(42244.5469), 'train_loss_kld': tensor(534.2269)}\n",
            "{'epoch': 17, 'train_loss': tensor(42869.7617), 'train_loss_nll': tensor(42336.7852), 'train_loss_kld': tensor(532.9726)}\n",
            "{'epoch': 18, 'train_loss': tensor(42841.9141), 'train_loss_nll': tensor(42307.1914), 'train_loss_kld': tensor(534.7313)}\n",
            "{'epoch': 19, 'train_loss': tensor(42676.2031), 'train_loss_nll': tensor(42139.9336), 'train_loss_kld': tensor(536.2704)}\n",
            "{'epoch': 20, 'train_loss': tensor(42881.8711), 'train_loss_nll': tensor(42345.3633), 'train_loss_kld': tensor(536.5040)}\n",
            "{'epoch': 21, 'train_loss': tensor(42788.5117), 'train_loss_nll': tensor(42252.3789), 'train_loss_kld': tensor(536.1320)}\n",
            "{'epoch': 22, 'train_loss': tensor(43101.4258), 'train_loss_nll': tensor(42566.0898), 'train_loss_kld': tensor(535.3366)}\n",
            "{'epoch': 23, 'train_loss': tensor(42891.8945), 'train_loss_nll': tensor(42355.0234), 'train_loss_kld': tensor(536.8698)}\n",
            "{'epoch': 24, 'train_loss': tensor(43129.8516), 'train_loss_nll': tensor(42592.2383), 'train_loss_kld': tensor(537.6104)}\n",
            "{'epoch': 25, 'train_loss': tensor(42937.6836), 'train_loss_nll': tensor(42402.3281), 'train_loss_kld': tensor(535.3523)}\n",
            "{'epoch': 26, 'train_loss': tensor(42756.6719), 'train_loss_nll': tensor(42221.6641), 'train_loss_kld': tensor(535.0042)}\n",
            "{'epoch': 27, 'train_loss': tensor(42773.7148), 'train_loss_nll': tensor(42239.6719), 'train_loss_kld': tensor(534.0424)}\n",
            "{'epoch': 28, 'train_loss': tensor(42703.7734), 'train_loss_nll': tensor(42167.9648), 'train_loss_kld': tensor(535.8112)}\n",
            "{'epoch': 29, 'train_loss': tensor(42665.0195), 'train_loss_nll': tensor(42130.0312), 'train_loss_kld': tensor(534.9848)}\n",
            "{'epoch': 30, 'train_loss': tensor(43045.4805), 'train_loss_nll': tensor(42506.8203), 'train_loss_kld': tensor(538.6620)}\n",
            "{'epoch': 31, 'train_loss': tensor(42895.8555), 'train_loss_nll': tensor(42353.7734), 'train_loss_kld': tensor(542.0826)}\n",
            "{'epoch': 32, 'train_loss': tensor(42972.6602), 'train_loss_nll': tensor(42426.1367), 'train_loss_kld': tensor(546.5272)}\n",
            "{'epoch': 33, 'train_loss': tensor(42777.8984), 'train_loss_nll': tensor(42235.0508), 'train_loss_kld': tensor(542.8558)}\n",
            "{'epoch': 34, 'train_loss': tensor(43086.6289), 'train_loss_nll': tensor(42547.7852), 'train_loss_kld': tensor(538.8474)}\n",
            "{'epoch': 35, 'train_loss': tensor(42921.1719), 'train_loss_nll': tensor(42384.3242), 'train_loss_kld': tensor(536.8484)}\n",
            "{'epoch': 36, 'train_loss': tensor(42985.1133), 'train_loss_nll': tensor(42447.3086), 'train_loss_kld': tensor(537.8002)}\n",
            "{'epoch': 37, 'train_loss': tensor(43046.3711), 'train_loss_nll': tensor(42510.3555), 'train_loss_kld': tensor(536.0159)}\n",
            "{'epoch': 38, 'train_loss': tensor(42650.0781), 'train_loss_nll': tensor(42116.6719), 'train_loss_kld': tensor(533.4120)}\n",
            "{'epoch': 39, 'train_loss': tensor(42739.0039), 'train_loss_nll': tensor(42202.9648), 'train_loss_kld': tensor(536.0458)}\n",
            "{'epoch': 40, 'train_loss': tensor(42802.9414), 'train_loss_nll': tensor(42267.1055), 'train_loss_kld': tensor(535.8342)}\n",
            "{'epoch': 41, 'train_loss': tensor(42825.8594), 'train_loss_nll': tensor(42293.3867), 'train_loss_kld': tensor(532.4778)}\n",
            "{'epoch': 42, 'train_loss': tensor(42899.3047), 'train_loss_nll': tensor(42366.2500), 'train_loss_kld': tensor(533.0546)}\n",
            "{'epoch': 43, 'train_loss': tensor(42797.7109), 'train_loss_nll': tensor(42265.3281), 'train_loss_kld': tensor(532.3797)}\n",
            "{'epoch': 44, 'train_loss': tensor(42721.1719), 'train_loss_nll': tensor(42188.0234), 'train_loss_kld': tensor(533.1432)}\n",
            "{'epoch': 45, 'train_loss': tensor(42824.8281), 'train_loss_nll': tensor(42293.4492), 'train_loss_kld': tensor(531.3845)}\n",
            "{'epoch': 46, 'train_loss': tensor(42767.2500), 'train_loss_nll': tensor(42234.6797), 'train_loss_kld': tensor(532.5745)}\n",
            "{'epoch': 47, 'train_loss': tensor(42755.8398), 'train_loss_nll': tensor(42222.9141), 'train_loss_kld': tensor(532.9272)}\n",
            "{'epoch': 48, 'train_loss': tensor(42787.8086), 'train_loss_nll': tensor(42256.2500), 'train_loss_kld': tensor(531.5557)}\n",
            "{'epoch': 49, 'train_loss': tensor(42764.2344), 'train_loss_nll': tensor(42230.8164), 'train_loss_kld': tensor(533.4160)}\n",
            "{'epoch': 50, 'train_loss': tensor(42858.7617), 'train_loss_nll': tensor(42324.6406), 'train_loss_kld': tensor(534.1212)}\n",
            "{'epoch': 51, 'train_loss': tensor(42674.0039), 'train_loss_nll': tensor(42138.9844), 'train_loss_kld': tensor(535.0225)}\n",
            "{'epoch': 52, 'train_loss': tensor(42769.6914), 'train_loss_nll': tensor(42235.6211), 'train_loss_kld': tensor(534.0717)}\n",
            "{'epoch': 53, 'train_loss': tensor(42625.3398), 'train_loss_nll': tensor(42091.0742), 'train_loss_kld': tensor(534.2622)}\n",
            "{'epoch': 54, 'train_loss': tensor(42813.1406), 'train_loss_nll': tensor(42278.3555), 'train_loss_kld': tensor(534.7851)}\n",
            "{'epoch': 55, 'train_loss': tensor(42742.9688), 'train_loss_nll': tensor(42205.9609), 'train_loss_kld': tensor(537.0092)}\n",
            "{'epoch': 56, 'train_loss': tensor(42801.0938), 'train_loss_nll': tensor(42265.8633), 'train_loss_kld': tensor(535.2304)}\n",
            "{'epoch': 57, 'train_loss': tensor(42665.3789), 'train_loss_nll': tensor(42128.6953), 'train_loss_kld': tensor(536.6896)}\n",
            "{'epoch': 58, 'train_loss': tensor(42752.7891), 'train_loss_nll': tensor(42217.3633), 'train_loss_kld': tensor(535.4273)}\n",
            "{'epoch': 59, 'train_loss': tensor(42679.1602), 'train_loss_nll': tensor(42143.6641), 'train_loss_kld': tensor(535.4872)}\n",
            "{'epoch': 60, 'train_loss': tensor(42706.7305), 'train_loss_nll': tensor(42168.9961), 'train_loss_kld': tensor(537.7340)}\n",
            "{'epoch': 61, 'train_loss': tensor(42621.1914), 'train_loss_nll': tensor(42081.1562), 'train_loss_kld': tensor(540.0334)}\n",
            "{'epoch': 62, 'train_loss': tensor(42731.5469), 'train_loss_nll': tensor(42194.3242), 'train_loss_kld': tensor(537.2197)}\n",
            "{'epoch': 63, 'train_loss': tensor(43073.8789), 'train_loss_nll': tensor(42537.2852), 'train_loss_kld': tensor(536.5989)}\n",
            "{'epoch': 64, 'train_loss': tensor(42619.4883), 'train_loss_nll': tensor(42082.0781), 'train_loss_kld': tensor(537.4164)}\n",
            "{'epoch': 65, 'train_loss': tensor(42995.7852), 'train_loss_nll': tensor(42458.3086), 'train_loss_kld': tensor(537.4764)}\n",
            "{'epoch': 66, 'train_loss': tensor(42595.5039), 'train_loss_nll': tensor(42059.9609), 'train_loss_kld': tensor(535.5451)}\n",
            "{'epoch': 67, 'train_loss': tensor(42897.5234), 'train_loss_nll': tensor(42361.6719), 'train_loss_kld': tensor(535.8575)}\n",
            "{'epoch': 68, 'train_loss': tensor(42756.3867), 'train_loss_nll': tensor(42221.5195), 'train_loss_kld': tensor(534.8630)}\n",
            "{'epoch': 69, 'train_loss': tensor(42891.0586), 'train_loss_nll': tensor(42356.4648), 'train_loss_kld': tensor(534.5948)}\n",
            "{'epoch': 70, 'train_loss': tensor(42867.8359), 'train_loss_nll': tensor(42331.9102), 'train_loss_kld': tensor(535.9216)}\n",
            "{'epoch': 71, 'train_loss': tensor(42671.5781), 'train_loss_nll': tensor(42134.8086), 'train_loss_kld': tensor(536.7700)}\n",
            "{'epoch': 72, 'train_loss': tensor(42644.2500), 'train_loss_nll': tensor(42106.7109), 'train_loss_kld': tensor(537.5386)}\n",
            "{'epoch': 73, 'train_loss': tensor(42795.4141), 'train_loss_nll': tensor(42258.6562), 'train_loss_kld': tensor(536.7632)}\n",
            "{'epoch': 74, 'train_loss': tensor(42707.4414), 'train_loss_nll': tensor(42171.2539), 'train_loss_kld': tensor(536.1823)}\n",
            "{'epoch': 75, 'train_loss': tensor(42876.8398), 'train_loss_nll': tensor(42337.7539), 'train_loss_kld': tensor(539.0814)}\n",
            "{'epoch': 76, 'train_loss': tensor(42754.0938), 'train_loss_nll': tensor(42214.1055), 'train_loss_kld': tensor(539.9910)}\n",
            "{'epoch': 77, 'train_loss': tensor(42935.1289), 'train_loss_nll': tensor(42395.7656), 'train_loss_kld': tensor(539.3639)}\n",
            "{'epoch': 78, 'train_loss': tensor(43057.0352), 'train_loss_nll': tensor(42516.7969), 'train_loss_kld': tensor(540.2400)}\n",
            "{'epoch': 79, 'train_loss': tensor(42854.2656), 'train_loss_nll': tensor(42315.3906), 'train_loss_kld': tensor(538.8762)}\n",
            "{'epoch': 80, 'train_loss': tensor(42711.6484), 'train_loss_nll': tensor(42171.4883), 'train_loss_kld': tensor(540.1607)}\n",
            "{'epoch': 81, 'train_loss': tensor(42842.9805), 'train_loss_nll': tensor(42304.3203), 'train_loss_kld': tensor(538.6605)}\n",
            "{'epoch': 82, 'train_loss': tensor(42917.4688), 'train_loss_nll': tensor(42379.1836), 'train_loss_kld': tensor(538.2827)}\n",
            "{'epoch': 83, 'train_loss': tensor(42808.5156), 'train_loss_nll': tensor(42272.6484), 'train_loss_kld': tensor(535.8680)}\n",
            "{'epoch': 84, 'train_loss': tensor(42722.8867), 'train_loss_nll': tensor(42186.5195), 'train_loss_kld': tensor(536.3636)}\n",
            "{'epoch': 85, 'train_loss': tensor(42904.6641), 'train_loss_nll': tensor(42365.7734), 'train_loss_kld': tensor(538.8894)}\n",
            "{'epoch': 86, 'train_loss': tensor(42921.4766), 'train_loss_nll': tensor(42382.6992), 'train_loss_kld': tensor(538.7691)}\n",
            "{'epoch': 87, 'train_loss': tensor(42803.2266), 'train_loss_nll': tensor(42263.8633), 'train_loss_kld': tensor(539.3600)}\n",
            "{'epoch': 88, 'train_loss': tensor(42630.3086), 'train_loss_nll': tensor(42092.3633), 'train_loss_kld': tensor(537.9476)}\n",
            "{'epoch': 89, 'train_loss': tensor(43069.7852), 'train_loss_nll': tensor(42531.6992), 'train_loss_kld': tensor(538.0803)}\n",
            "{'epoch': 90, 'train_loss': tensor(42720.0859), 'train_loss_nll': tensor(42181.4805), 'train_loss_kld': tensor(538.6045)}\n",
            "{'epoch': 91, 'train_loss': tensor(42999.8203), 'train_loss_nll': tensor(42456.0781), 'train_loss_kld': tensor(543.7403)}\n",
            "{'epoch': 92, 'train_loss': tensor(42710.4453), 'train_loss_nll': tensor(42165.6406), 'train_loss_kld': tensor(544.7994)}\n",
            "{'epoch': 93, 'train_loss': tensor(42990.5352), 'train_loss_nll': tensor(42445.0156), 'train_loss_kld': tensor(545.5180)}\n",
            "{'epoch': 94, 'train_loss': tensor(43164.0664), 'train_loss_nll': tensor(42616.5234), 'train_loss_kld': tensor(547.5394)}\n",
            "{'epoch': 95, 'train_loss': tensor(42875.2383), 'train_loss_nll': tensor(42331.4805), 'train_loss_kld': tensor(543.7582)}\n",
            "{'epoch': 96, 'train_loss': tensor(42864.9297), 'train_loss_nll': tensor(42320.8359), 'train_loss_kld': tensor(544.0964)}\n",
            "{'epoch': 97, 'train_loss': tensor(42746.1914), 'train_loss_nll': tensor(42202.5156), 'train_loss_kld': tensor(543.6755)}\n",
            "{'epoch': 98, 'train_loss': tensor(42682.1602), 'train_loss_nll': tensor(42140.2734), 'train_loss_kld': tensor(541.8884)}\n",
            "{'epoch': 99, 'train_loss': tensor(42821.7852), 'train_loss_nll': tensor(42277.8438), 'train_loss_kld': tensor(543.9376)}\n",
            "{'epoch': 100, 'train_loss': tensor(42993.3906), 'train_loss_nll': tensor(42452.9453), 'train_loss_kld': tensor(540.4410)}\n",
            "{'epoch': 101, 'train_loss': tensor(42976.5039), 'train_loss_nll': tensor(42432.7109), 'train_loss_kld': tensor(543.7912)}\n",
            "{'epoch': 102, 'train_loss': tensor(42876.3516), 'train_loss_nll': tensor(42332.1094), 'train_loss_kld': tensor(544.2415)}\n",
            "{'epoch': 103, 'train_loss': tensor(43057.2734), 'train_loss_nll': tensor(42513.4219), 'train_loss_kld': tensor(543.8547)}\n",
            "{'epoch': 104, 'train_loss': tensor(42824.1797), 'train_loss_nll': tensor(42277.0664), 'train_loss_kld': tensor(547.1135)}\n",
            "{'epoch': 105, 'train_loss': tensor(43071.9492), 'train_loss_nll': tensor(42528.9766), 'train_loss_kld': tensor(542.9682)}\n",
            "{'epoch': 106, 'train_loss': tensor(42897.5508), 'train_loss_nll': tensor(42353.0938), 'train_loss_kld': tensor(544.4578)}\n",
            "{'epoch': 107, 'train_loss': tensor(42853.4297), 'train_loss_nll': tensor(42310.3711), 'train_loss_kld': tensor(543.0651)}\n",
            "{'epoch': 108, 'train_loss': tensor(42742.), 'train_loss_nll': tensor(42199.0156), 'train_loss_kld': tensor(542.9800)}\n",
            "{'epoch': 109, 'train_loss': tensor(42840.7461), 'train_loss_nll': tensor(42296.7617), 'train_loss_kld': tensor(543.9841)}\n",
            "{'epoch': 110, 'train_loss': tensor(42871.0117), 'train_loss_nll': tensor(42325.7305), 'train_loss_kld': tensor(545.2778)}\n",
            "{'epoch': 111, 'train_loss': tensor(42793.3555), 'train_loss_nll': tensor(42247.0039), 'train_loss_kld': tensor(546.3488)}\n",
            "{'epoch': 112, 'train_loss': tensor(42726.2812), 'train_loss_nll': tensor(42181.3359), 'train_loss_kld': tensor(544.9481)}\n",
            "{'epoch': 113, 'train_loss': tensor(42598.8359), 'train_loss_nll': tensor(42053.5195), 'train_loss_kld': tensor(545.3109)}\n",
            "{'epoch': 114, 'train_loss': tensor(42747.2656), 'train_loss_nll': tensor(42203.1211), 'train_loss_kld': tensor(544.1452)}\n",
            "{'epoch': 115, 'train_loss': tensor(42770.5352), 'train_loss_nll': tensor(42226.8438), 'train_loss_kld': tensor(543.6880)}\n",
            "{'epoch': 116, 'train_loss': tensor(42670.1641), 'train_loss_nll': tensor(42128.4766), 'train_loss_kld': tensor(541.6860)}\n",
            "{'epoch': 117, 'train_loss': tensor(42836.1914), 'train_loss_nll': tensor(42293.4102), 'train_loss_kld': tensor(542.7758)}\n",
            "{'epoch': 118, 'train_loss': tensor(42850.0508), 'train_loss_nll': tensor(42306.1445), 'train_loss_kld': tensor(543.9047)}\n",
            "{'epoch': 119, 'train_loss': tensor(42739.0898), 'train_loss_nll': tensor(42195.8906), 'train_loss_kld': tensor(543.2000)}\n",
            "{'epoch': 120, 'train_loss': tensor(42829.4414), 'train_loss_nll': tensor(42288.6992), 'train_loss_kld': tensor(540.7427)}\n",
            "{'epoch': 121, 'train_loss': tensor(42641.0898), 'train_loss_nll': tensor(42101.8398), 'train_loss_kld': tensor(539.2545)}\n",
            "{'epoch': 122, 'train_loss': tensor(42711.1484), 'train_loss_nll': tensor(42170.4102), 'train_loss_kld': tensor(540.7366)}\n",
            "{'epoch': 123, 'train_loss': tensor(42819.2500), 'train_loss_nll': tensor(42276.3750), 'train_loss_kld': tensor(542.8760)}\n",
            "{'epoch': 124, 'train_loss': tensor(42837.1953), 'train_loss_nll': tensor(42298.1562), 'train_loss_kld': tensor(539.0383)}\n",
            "{'epoch': 125, 'train_loss': tensor(42742.9766), 'train_loss_nll': tensor(42204.5898), 'train_loss_kld': tensor(538.3895)}\n",
            "{'epoch': 126, 'train_loss': tensor(42571.8164), 'train_loss_nll': tensor(42032.0391), 'train_loss_kld': tensor(539.7736)}\n",
            "{'epoch': 127, 'train_loss': tensor(42917.8438), 'train_loss_nll': tensor(42378.3711), 'train_loss_kld': tensor(539.4761)}\n",
            "{'epoch': 128, 'train_loss': tensor(42839.4688), 'train_loss_nll': tensor(42299.7539), 'train_loss_kld': tensor(539.7156)}\n",
            "{'epoch': 129, 'train_loss': tensor(42861.2266), 'train_loss_nll': tensor(42321.9062), 'train_loss_kld': tensor(539.3250)}\n",
            "{'epoch': 130, 'train_loss': tensor(42652.2500), 'train_loss_nll': tensor(42114.8242), 'train_loss_kld': tensor(537.4265)}\n",
            "{'epoch': 131, 'train_loss': tensor(42855.2852), 'train_loss_nll': tensor(42315.1367), 'train_loss_kld': tensor(540.1508)}\n",
            "{'epoch': 132, 'train_loss': tensor(42645.8008), 'train_loss_nll': tensor(42108.4609), 'train_loss_kld': tensor(537.3357)}\n",
            "{'epoch': 133, 'train_loss': tensor(42798.7734), 'train_loss_nll': tensor(42260.4102), 'train_loss_kld': tensor(538.3618)}\n",
            "{'epoch': 134, 'train_loss': tensor(42763.6211), 'train_loss_nll': tensor(42223.7305), 'train_loss_kld': tensor(539.8832)}\n",
            "{'epoch': 135, 'train_loss': tensor(42643.1445), 'train_loss_nll': tensor(42104.4336), 'train_loss_kld': tensor(538.7072)}\n",
            "{'epoch': 136, 'train_loss': tensor(42653.5547), 'train_loss_nll': tensor(42114.6250), 'train_loss_kld': tensor(538.9324)}\n",
            "{'epoch': 137, 'train_loss': tensor(42685.9961), 'train_loss_nll': tensor(42148.9492), 'train_loss_kld': tensor(537.0408)}\n",
            "{'epoch': 138, 'train_loss': tensor(42876.3242), 'train_loss_nll': tensor(42335.8203), 'train_loss_kld': tensor(540.5051)}\n",
            "{'epoch': 139, 'train_loss': tensor(42709.8203), 'train_loss_nll': tensor(42170.1211), 'train_loss_kld': tensor(539.7012)}\n",
            "{'epoch': 140, 'train_loss': tensor(42727.1406), 'train_loss_nll': tensor(42187.0312), 'train_loss_kld': tensor(540.1082)}\n",
            "{'epoch': 141, 'train_loss': tensor(42691.4141), 'train_loss_nll': tensor(42152.5195), 'train_loss_kld': tensor(538.8967)}\n",
            "{'epoch': 142, 'train_loss': tensor(42543.3594), 'train_loss_nll': tensor(42002.9414), 'train_loss_kld': tensor(540.4144)}\n",
            "{'epoch': 143, 'train_loss': tensor(42845.0312), 'train_loss_nll': tensor(42304.3516), 'train_loss_kld': tensor(540.6781)}\n",
            "{'epoch': 144, 'train_loss': tensor(42771.1445), 'train_loss_nll': tensor(42231.9258), 'train_loss_kld': tensor(539.2169)}\n",
            "{'epoch': 145, 'train_loss': tensor(42663.9141), 'train_loss_nll': tensor(42125.4062), 'train_loss_kld': tensor(538.5109)}\n",
            "{'epoch': 146, 'train_loss': tensor(42844.1211), 'train_loss_nll': tensor(42305.4492), 'train_loss_kld': tensor(538.6719)}\n",
            "{'epoch': 147, 'train_loss': tensor(42687.8867), 'train_loss_nll': tensor(42149.6641), 'train_loss_kld': tensor(538.2205)}\n",
            "{'epoch': 148, 'train_loss': tensor(42470.6641), 'train_loss_nll': tensor(41932.9531), 'train_loss_kld': tensor(537.7107)}\n",
            "{'epoch': 149, 'train_loss': tensor(42672.4141), 'train_loss_nll': tensor(42134.7461), 'train_loss_kld': tensor(537.6688)}\n",
            "{'epoch': 150, 'train_loss': tensor(42696.7852), 'train_loss_nll': tensor(42158.1094), 'train_loss_kld': tensor(538.6778)}\n",
            "{'epoch': 151, 'train_loss': tensor(42606.4414), 'train_loss_nll': tensor(42068.8633), 'train_loss_kld': tensor(537.5791)}\n",
            "{'epoch': 152, 'train_loss': tensor(42684.9805), 'train_loss_nll': tensor(42148.5742), 'train_loss_kld': tensor(536.4068)}\n",
            "{'epoch': 153, 'train_loss': tensor(42528.5703), 'train_loss_nll': tensor(41993.8633), 'train_loss_kld': tensor(534.7073)}\n",
            "{'epoch': 154, 'train_loss': tensor(42648.3438), 'train_loss_nll': tensor(42109.2461), 'train_loss_kld': tensor(539.1030)}\n",
            "{'epoch': 155, 'train_loss': tensor(42738.1484), 'train_loss_nll': tensor(42199.3047), 'train_loss_kld': tensor(538.8514)}\n",
            "{'epoch': 156, 'train_loss': tensor(42535.7500), 'train_loss_nll': tensor(41998.7695), 'train_loss_kld': tensor(536.9821)}\n",
            "{'epoch': 157, 'train_loss': tensor(42752.9102), 'train_loss_nll': tensor(42216.5898), 'train_loss_kld': tensor(536.3193)}\n",
            "{'epoch': 158, 'train_loss': tensor(42813.0039), 'train_loss_nll': tensor(42275.0156), 'train_loss_kld': tensor(537.9951)}\n",
            "{'epoch': 159, 'train_loss': tensor(42808.7617), 'train_loss_nll': tensor(42273.2812), 'train_loss_kld': tensor(535.4758)}\n",
            "{'epoch': 160, 'train_loss': tensor(42564.1602), 'train_loss_nll': tensor(42028.1641), 'train_loss_kld': tensor(535.9991)}\n",
            "{'epoch': 161, 'train_loss': tensor(42676.2383), 'train_loss_nll': tensor(42139.5469), 'train_loss_kld': tensor(536.6887)}\n",
            "{'epoch': 162, 'train_loss': tensor(42581.9297), 'train_loss_nll': tensor(42043.6406), 'train_loss_kld': tensor(538.2865)}\n",
            "{'epoch': 163, 'train_loss': tensor(42713.0391), 'train_loss_nll': tensor(42176.5547), 'train_loss_kld': tensor(536.4812)}\n",
            "{'epoch': 164, 'train_loss': tensor(42496.9414), 'train_loss_nll': tensor(41963.2109), 'train_loss_kld': tensor(533.7299)}\n",
            "{'epoch': 165, 'train_loss': tensor(42719.6836), 'train_loss_nll': tensor(42185.1641), 'train_loss_kld': tensor(534.5164)}\n",
            "{'epoch': 166, 'train_loss': tensor(42719.6289), 'train_loss_nll': tensor(42183.6094), 'train_loss_kld': tensor(536.0134)}\n",
            "{'epoch': 167, 'train_loss': tensor(42786.0039), 'train_loss_nll': tensor(42251.7305), 'train_loss_kld': tensor(534.2781)}\n",
            "{'epoch': 168, 'train_loss': tensor(42787.9648), 'train_loss_nll': tensor(42251.2031), 'train_loss_kld': tensor(536.7599)}\n",
            "{'epoch': 169, 'train_loss': tensor(42611.6289), 'train_loss_nll': tensor(42077.2812), 'train_loss_kld': tensor(534.3514)}\n",
            "{'epoch': 170, 'train_loss': tensor(42805.8789), 'train_loss_nll': tensor(42270.6289), 'train_loss_kld': tensor(535.2498)}\n",
            "{'epoch': 171, 'train_loss': tensor(42611.2969), 'train_loss_nll': tensor(42076.4688), 'train_loss_kld': tensor(534.8222)}\n",
            "{'epoch': 172, 'train_loss': tensor(42787.1562), 'train_loss_nll': tensor(42251.7109), 'train_loss_kld': tensor(535.4440)}\n",
            "{'epoch': 173, 'train_loss': tensor(42731.0234), 'train_loss_nll': tensor(42195.9805), 'train_loss_kld': tensor(535.0430)}\n",
            "{'epoch': 174, 'train_loss': tensor(42746.4336), 'train_loss_nll': tensor(42212.1367), 'train_loss_kld': tensor(534.2992)}\n",
            "{'epoch': 175, 'train_loss': tensor(42508.4297), 'train_loss_nll': tensor(41973.5469), 'train_loss_kld': tensor(534.8809)}\n",
            "{'epoch': 176, 'train_loss': tensor(42751.8398), 'train_loss_nll': tensor(42217.1016), 'train_loss_kld': tensor(534.7396)}\n",
            "{'epoch': 177, 'train_loss': tensor(42677.6289), 'train_loss_nll': tensor(42144.6602), 'train_loss_kld': tensor(532.9699)}\n",
            "{'epoch': 178, 'train_loss': tensor(42567.8281), 'train_loss_nll': tensor(42033.0156), 'train_loss_kld': tensor(534.8144)}\n",
            "{'epoch': 179, 'train_loss': tensor(42629.5195), 'train_loss_nll': tensor(42096.4297), 'train_loss_kld': tensor(533.0941)}\n",
            "{'epoch': 180, 'train_loss': tensor(42775.3711), 'train_loss_nll': tensor(42241.4492), 'train_loss_kld': tensor(533.9221)}\n",
            "{'epoch': 181, 'train_loss': tensor(42644.0938), 'train_loss_nll': tensor(42110.5664), 'train_loss_kld': tensor(533.5289)}\n",
            "{'epoch': 182, 'train_loss': tensor(42699.7812), 'train_loss_nll': tensor(42166.4102), 'train_loss_kld': tensor(533.3716)}\n",
            "{'epoch': 183, 'train_loss': tensor(42608.4688), 'train_loss_nll': tensor(42075.5000), 'train_loss_kld': tensor(532.9737)}\n",
            "{'epoch': 184, 'train_loss': tensor(42563.3594), 'train_loss_nll': tensor(42030.9336), 'train_loss_kld': tensor(532.4260)}\n",
            "{'epoch': 185, 'train_loss': tensor(42514.5898), 'train_loss_nll': tensor(41981.9414), 'train_loss_kld': tensor(532.6441)}\n",
            "{'epoch': 186, 'train_loss': tensor(42536.0156), 'train_loss_nll': tensor(42002.8438), 'train_loss_kld': tensor(533.1658)}\n",
            "{'epoch': 187, 'train_loss': tensor(42649.4062), 'train_loss_nll': tensor(42117.0117), 'train_loss_kld': tensor(532.3892)}\n",
            "{'epoch': 188, 'train_loss': tensor(42520.1211), 'train_loss_nll': tensor(41987.7188), 'train_loss_kld': tensor(532.4078)}\n",
            "{'epoch': 189, 'train_loss': tensor(42641.0898), 'train_loss_nll': tensor(42109.1641), 'train_loss_kld': tensor(531.9245)}\n",
            "{'epoch': 190, 'train_loss': tensor(42422.5352), 'train_loss_nll': tensor(41890.5156), 'train_loss_kld': tensor(532.0158)}\n",
            "{'epoch': 191, 'train_loss': tensor(42746.0508), 'train_loss_nll': tensor(42213.6992), 'train_loss_kld': tensor(532.3485)}\n",
            "{'epoch': 192, 'train_loss': tensor(42565.2188), 'train_loss_nll': tensor(42033.3008), 'train_loss_kld': tensor(531.9229)}\n",
            "{'epoch': 193, 'train_loss': tensor(42495.5000), 'train_loss_nll': tensor(41959.5469), 'train_loss_kld': tensor(535.9581)}\n",
            "{'epoch': 194, 'train_loss': tensor(42746.2109), 'train_loss_nll': tensor(42205.8281), 'train_loss_kld': tensor(540.3764)}\n",
            "{'epoch': 195, 'train_loss': tensor(42794.6797), 'train_loss_nll': tensor(42253.), 'train_loss_kld': tensor(541.6797)}\n",
            "{'epoch': 196, 'train_loss': tensor(42530.9805), 'train_loss_nll': tensor(41989.1953), 'train_loss_kld': tensor(541.7845)}\n",
            "{'epoch': 197, 'train_loss': tensor(42794.5469), 'train_loss_nll': tensor(42255.7383), 'train_loss_kld': tensor(538.8020)}\n",
            "{'epoch': 198, 'train_loss': tensor(42985.2617), 'train_loss_nll': tensor(42439.8789), 'train_loss_kld': tensor(545.3819)}\n",
            "{'epoch': 199, 'train_loss': tensor(42836.8711), 'train_loss_nll': tensor(42293.2969), 'train_loss_kld': tensor(543.5757)}\n",
            "{'epoch': 200, 'train_loss': tensor(42801.0469), 'train_loss_nll': tensor(42259.6133), 'train_loss_kld': tensor(541.4296)}\n",
            "{'epoch': 1, 'train_loss': tensor(42928.2344), 'train_loss_nll': tensor(42388.9102), 'train_loss_kld': tensor(539.3287)}\n",
            "{'epoch': 2, 'train_loss': tensor(43130.1289), 'train_loss_nll': tensor(42595.1055), 'train_loss_kld': tensor(535.0232)}\n",
            "{'epoch': 3, 'train_loss': tensor(42818.6602), 'train_loss_nll': tensor(42283.9961), 'train_loss_kld': tensor(534.6685)}\n",
            "{'epoch': 4, 'train_loss': tensor(42626.0898), 'train_loss_nll': tensor(42091.9258), 'train_loss_kld': tensor(534.1633)}\n",
            "{'epoch': 5, 'train_loss': tensor(42680.9766), 'train_loss_nll': tensor(42146.3516), 'train_loss_kld': tensor(534.6255)}\n",
            "{'epoch': 6, 'train_loss': tensor(42688.1602), 'train_loss_nll': tensor(42152.0703), 'train_loss_kld': tensor(536.0922)}\n",
            "{'epoch': 7, 'train_loss': tensor(42770.8281), 'train_loss_nll': tensor(42236.6289), 'train_loss_kld': tensor(534.2039)}\n",
            "{'epoch': 8, 'train_loss': tensor(42636.7812), 'train_loss_nll': tensor(42101.1641), 'train_loss_kld': tensor(535.6103)}\n",
            "{'epoch': 9, 'train_loss': tensor(42923.3906), 'train_loss_nll': tensor(42383.8047), 'train_loss_kld': tensor(539.5911)}\n",
            "{'epoch': 10, 'train_loss': tensor(43006.4609), 'train_loss_nll': tensor(42468.6289), 'train_loss_kld': tensor(537.8303)}\n",
            "{'epoch': 11, 'train_loss': tensor(42996.1445), 'train_loss_nll': tensor(42458.0469), 'train_loss_kld': tensor(538.0977)}\n",
            "{'epoch': 12, 'train_loss': tensor(42685.2109), 'train_loss_nll': tensor(42149.1016), 'train_loss_kld': tensor(536.1082)}\n",
            "{'epoch': 13, 'train_loss': tensor(42817.4062), 'train_loss_nll': tensor(42280.2344), 'train_loss_kld': tensor(537.1661)}\n",
            "{'epoch': 14, 'train_loss': tensor(42753.4258), 'train_loss_nll': tensor(42216.8516), 'train_loss_kld': tensor(536.5730)}\n",
            "{'epoch': 15, 'train_loss': tensor(42945.6797), 'train_loss_nll': tensor(42409.3906), 'train_loss_kld': tensor(536.2905)}\n",
            "{'epoch': 16, 'train_loss': tensor(42925.1914), 'train_loss_nll': tensor(42384.3398), 'train_loss_kld': tensor(540.8524)}\n",
            "{'epoch': 17, 'train_loss': tensor(42937.2969), 'train_loss_nll': tensor(42398.9258), 'train_loss_kld': tensor(538.3723)}\n",
            "{'epoch': 18, 'train_loss': tensor(42716.1094), 'train_loss_nll': tensor(42180.0508), 'train_loss_kld': tensor(536.0635)}\n",
            "{'epoch': 19, 'train_loss': tensor(42862.1758), 'train_loss_nll': tensor(42327.7695), 'train_loss_kld': tensor(534.4050)}\n",
            "{'epoch': 20, 'train_loss': tensor(42770.8398), 'train_loss_nll': tensor(42235.7539), 'train_loss_kld': tensor(535.0817)}\n",
            "{'epoch': 21, 'train_loss': tensor(42904.2695), 'train_loss_nll': tensor(42368.3203), 'train_loss_kld': tensor(535.9520)}\n",
            "{'epoch': 22, 'train_loss': tensor(42765.5586), 'train_loss_nll': tensor(42231.9492), 'train_loss_kld': tensor(533.6118)}\n",
            "{'epoch': 23, 'train_loss': tensor(42791.2188), 'train_loss_nll': tensor(42255.9844), 'train_loss_kld': tensor(535.2405)}\n",
            "{'epoch': 24, 'train_loss': tensor(42685.5859), 'train_loss_nll': tensor(42151.7852), 'train_loss_kld': tensor(533.7981)}\n",
            "{'epoch': 25, 'train_loss': tensor(42533.4102), 'train_loss_nll': tensor(41998.6094), 'train_loss_kld': tensor(534.7955)}\n",
            "{'epoch': 26, 'train_loss': tensor(42495.5508), 'train_loss_nll': tensor(41961.8008), 'train_loss_kld': tensor(533.7475)}\n",
            "{'epoch': 27, 'train_loss': tensor(42702.2305), 'train_loss_nll': tensor(42168.8789), 'train_loss_kld': tensor(533.3583)}\n",
            "{'epoch': 28, 'train_loss': tensor(42678.0547), 'train_loss_nll': tensor(42145.4219), 'train_loss_kld': tensor(532.6423)}\n",
            "{'epoch': 29, 'train_loss': tensor(42491.4062), 'train_loss_nll': tensor(41957.1484), 'train_loss_kld': tensor(534.2551)}\n",
            "{'epoch': 30, 'train_loss': tensor(42497.5742), 'train_loss_nll': tensor(41964.0469), 'train_loss_kld': tensor(533.5260)}\n",
            "{'epoch': 31, 'train_loss': tensor(42661.3398), 'train_loss_nll': tensor(42128.0781), 'train_loss_kld': tensor(533.2581)}\n",
            "{'epoch': 32, 'train_loss': tensor(42551.0195), 'train_loss_nll': tensor(42017.), 'train_loss_kld': tensor(534.0164)}\n",
            "{'epoch': 33, 'train_loss': tensor(42520.8555), 'train_loss_nll': tensor(41987.1953), 'train_loss_kld': tensor(533.6584)}\n",
            "{'epoch': 34, 'train_loss': tensor(42769.2266), 'train_loss_nll': tensor(42234.8984), 'train_loss_kld': tensor(534.3237)}\n",
            "{'epoch': 35, 'train_loss': tensor(42541.0586), 'train_loss_nll': tensor(42007.9688), 'train_loss_kld': tensor(533.0895)}\n",
            "{'epoch': 36, 'train_loss': tensor(42573.7852), 'train_loss_nll': tensor(42040.3203), 'train_loss_kld': tensor(533.4697)}\n",
            "{'epoch': 37, 'train_loss': tensor(42615.7383), 'train_loss_nll': tensor(42079.7891), 'train_loss_kld': tensor(535.9469)}\n",
            "{'epoch': 38, 'train_loss': tensor(42690.4531), 'train_loss_nll': tensor(42154.1797), 'train_loss_kld': tensor(536.2776)}\n",
            "{'epoch': 39, 'train_loss': tensor(42779.2617), 'train_loss_nll': tensor(42242.4961), 'train_loss_kld': tensor(536.7658)}\n",
            "{'epoch': 40, 'train_loss': tensor(42825.0938), 'train_loss_nll': tensor(42284.7891), 'train_loss_kld': tensor(540.3021)}\n",
            "{'epoch': 41, 'train_loss': tensor(42598.8164), 'train_loss_nll': tensor(42059.6484), 'train_loss_kld': tensor(539.1678)}\n",
            "{'epoch': 42, 'train_loss': tensor(42661.7969), 'train_loss_nll': tensor(42124.1914), 'train_loss_kld': tensor(537.5999)}\n",
            "{'epoch': 43, 'train_loss': tensor(42610.5703), 'train_loss_nll': tensor(42073.7305), 'train_loss_kld': tensor(536.8409)}\n",
            "{'epoch': 44, 'train_loss': tensor(42741.3008), 'train_loss_nll': tensor(42204.7109), 'train_loss_kld': tensor(536.5859)}\n",
            "{'epoch': 45, 'train_loss': tensor(42846.8438), 'train_loss_nll': tensor(42308.6914), 'train_loss_kld': tensor(538.1553)}\n",
            "{'epoch': 46, 'train_loss': tensor(42726.1953), 'train_loss_nll': tensor(42189.0117), 'train_loss_kld': tensor(537.1824)}\n",
            "{'epoch': 47, 'train_loss': tensor(42563.3359), 'train_loss_nll': tensor(42026.9805), 'train_loss_kld': tensor(536.3557)}\n",
            "{'epoch': 48, 'train_loss': tensor(42823.0664), 'train_loss_nll': tensor(42284.4141), 'train_loss_kld': tensor(538.6505)}\n",
            "{'epoch': 49, 'train_loss': tensor(42861.7148), 'train_loss_nll': tensor(42321.0117), 'train_loss_kld': tensor(540.7014)}\n",
            "{'epoch': 50, 'train_loss': tensor(42595.1836), 'train_loss_nll': tensor(42054.9883), 'train_loss_kld': tensor(540.1978)}\n",
            "{'epoch': 51, 'train_loss': tensor(42599.8633), 'train_loss_nll': tensor(42061.0352), 'train_loss_kld': tensor(538.8290)}\n",
            "{'epoch': 52, 'train_loss': tensor(42625.4102), 'train_loss_nll': tensor(42087.9258), 'train_loss_kld': tensor(537.4871)}\n",
            "{'epoch': 53, 'train_loss': tensor(42818.0469), 'train_loss_nll': tensor(42277.5117), 'train_loss_kld': tensor(540.5336)}\n",
            "{'epoch': 54, 'train_loss': tensor(42686.7305), 'train_loss_nll': tensor(42146.2031), 'train_loss_kld': tensor(540.5209)}\n",
            "{'epoch': 55, 'train_loss': tensor(42649.7969), 'train_loss_nll': tensor(42107.4844), 'train_loss_kld': tensor(542.3102)}\n",
            "{'epoch': 56, 'train_loss': tensor(42905.0703), 'train_loss_nll': tensor(42366.9688), 'train_loss_kld': tensor(538.1024)}\n",
            "{'epoch': 57, 'train_loss': tensor(42613.3008), 'train_loss_nll': tensor(42074.5859), 'train_loss_kld': tensor(538.7213)}\n",
            "{'epoch': 58, 'train_loss': tensor(42742.6133), 'train_loss_nll': tensor(42204.7031), 'train_loss_kld': tensor(537.9075)}\n",
            "{'epoch': 59, 'train_loss': tensor(42692.4688), 'train_loss_nll': tensor(42153.9414), 'train_loss_kld': tensor(538.5302)}\n",
            "{'epoch': 60, 'train_loss': tensor(42574.6211), 'train_loss_nll': tensor(42038.3633), 'train_loss_kld': tensor(536.2557)}\n",
            "{'epoch': 61, 'train_loss': tensor(42447.7695), 'train_loss_nll': tensor(41910.3516), 'train_loss_kld': tensor(537.4188)}\n",
            "{'epoch': 62, 'train_loss': tensor(42683.6016), 'train_loss_nll': tensor(42147.4609), 'train_loss_kld': tensor(536.1426)}\n",
            "{'epoch': 63, 'train_loss': tensor(42636.4258), 'train_loss_nll': tensor(42096.5781), 'train_loss_kld': tensor(539.8416)}\n",
            "{'epoch': 64, 'train_loss': tensor(42675.2695), 'train_loss_nll': tensor(42137.9844), 'train_loss_kld': tensor(537.2862)}\n",
            "{'epoch': 65, 'train_loss': tensor(42447.6797), 'train_loss_nll': tensor(41911.1094), 'train_loss_kld': tensor(536.5662)}\n",
            "{'epoch': 66, 'train_loss': tensor(42856.2852), 'train_loss_nll': tensor(42319.7031), 'train_loss_kld': tensor(536.5773)}\n",
            "{'epoch': 67, 'train_loss': tensor(42737.8281), 'train_loss_nll': tensor(42199.0469), 'train_loss_kld': tensor(538.7850)}\n",
            "{'epoch': 68, 'train_loss': tensor(42580.3750), 'train_loss_nll': tensor(42044.1094), 'train_loss_kld': tensor(536.2684)}\n",
            "{'epoch': 69, 'train_loss': tensor(42557.5000), 'train_loss_nll': tensor(42019.8008), 'train_loss_kld': tensor(537.7037)}\n",
            "{'epoch': 70, 'train_loss': tensor(42672.7109), 'train_loss_nll': tensor(42134.2344), 'train_loss_kld': tensor(538.4788)}\n",
            "{'epoch': 71, 'train_loss': tensor(42669.3516), 'train_loss_nll': tensor(42132.3516), 'train_loss_kld': tensor(536.9998)}\n",
            "{'epoch': 72, 'train_loss': tensor(42778.2617), 'train_loss_nll': tensor(42241.9688), 'train_loss_kld': tensor(536.2876)}\n",
            "{'epoch': 73, 'train_loss': tensor(42620.5781), 'train_loss_nll': tensor(42083.7617), 'train_loss_kld': tensor(536.8183)}\n",
            "{'epoch': 74, 'train_loss': tensor(42603.0312), 'train_loss_nll': tensor(42065.7539), 'train_loss_kld': tensor(537.2710)}\n",
            "{'epoch': 75, 'train_loss': tensor(42592.0664), 'train_loss_nll': tensor(42057.2539), 'train_loss_kld': tensor(534.8105)}\n",
            "{'epoch': 76, 'train_loss': tensor(42650.2656), 'train_loss_nll': tensor(42112.6562), 'train_loss_kld': tensor(537.6052)}\n",
            "{'epoch': 77, 'train_loss': tensor(42570.0781), 'train_loss_nll': tensor(42030.7695), 'train_loss_kld': tensor(539.3094)}\n",
            "{'epoch': 78, 'train_loss': tensor(42538.7305), 'train_loss_nll': tensor(41998.1016), 'train_loss_kld': tensor(540.6269)}\n",
            "{'epoch': 79, 'train_loss': tensor(42663.6094), 'train_loss_nll': tensor(42124.9531), 'train_loss_kld': tensor(538.6584)}\n",
            "{'epoch': 80, 'train_loss': tensor(42745.0312), 'train_loss_nll': tensor(42204.0391), 'train_loss_kld': tensor(540.9888)}\n",
            "{'epoch': 81, 'train_loss': tensor(42987.6953), 'train_loss_nll': tensor(42446.3555), 'train_loss_kld': tensor(541.3390)}\n",
            "{'epoch': 82, 'train_loss': tensor(42914.2969), 'train_loss_nll': tensor(42373.4297), 'train_loss_kld': tensor(540.8716)}\n",
            "{'epoch': 83, 'train_loss': tensor(42645.9062), 'train_loss_nll': tensor(42107.1953), 'train_loss_kld': tensor(538.7131)}\n",
            "{'epoch': 84, 'train_loss': tensor(42643.0469), 'train_loss_nll': tensor(42105.1289), 'train_loss_kld': tensor(537.9166)}\n",
            "{'epoch': 85, 'train_loss': tensor(42557.5000), 'train_loss_nll': tensor(42019.1562), 'train_loss_kld': tensor(538.3417)}\n",
            "{'epoch': 86, 'train_loss': tensor(42594.5352), 'train_loss_nll': tensor(42056.3750), 'train_loss_kld': tensor(538.1640)}\n",
            "{'epoch': 87, 'train_loss': tensor(42484.4648), 'train_loss_nll': tensor(41946.8164), 'train_loss_kld': tensor(537.6492)}\n",
            "{'epoch': 88, 'train_loss': tensor(42752.0703), 'train_loss_nll': tensor(42215.9844), 'train_loss_kld': tensor(536.0887)}\n",
            "{'epoch': 89, 'train_loss': tensor(42672.6836), 'train_loss_nll': tensor(42134.9336), 'train_loss_kld': tensor(537.7545)}\n",
            "{'epoch': 90, 'train_loss': tensor(42595.2500), 'train_loss_nll': tensor(42056.0586), 'train_loss_kld': tensor(539.1924)}\n",
            "{'epoch': 91, 'train_loss': tensor(42424.2734), 'train_loss_nll': tensor(41881.8945), 'train_loss_kld': tensor(542.3819)}\n",
            "{'epoch': 92, 'train_loss': tensor(42682.3203), 'train_loss_nll': tensor(42142.0312), 'train_loss_kld': tensor(540.2922)}\n",
            "{'epoch': 93, 'train_loss': tensor(42597.4258), 'train_loss_nll': tensor(42055.9844), 'train_loss_kld': tensor(541.4398)}\n",
            "{'epoch': 94, 'train_loss': tensor(42503.9297), 'train_loss_nll': tensor(41964.1719), 'train_loss_kld': tensor(539.7633)}\n",
            "{'epoch': 95, 'train_loss': tensor(42714.7148), 'train_loss_nll': tensor(42177.6133), 'train_loss_kld': tensor(537.0980)}\n",
            "{'epoch': 96, 'train_loss': tensor(42681.2539), 'train_loss_nll': tensor(42141.3711), 'train_loss_kld': tensor(539.8857)}\n",
            "{'epoch': 97, 'train_loss': tensor(42758.1992), 'train_loss_nll': tensor(42218.1953), 'train_loss_kld': tensor(540.0022)}\n",
            "{'epoch': 98, 'train_loss': tensor(42559.0586), 'train_loss_nll': tensor(42020.2344), 'train_loss_kld': tensor(538.8311)}\n",
            "{'epoch': 99, 'train_loss': tensor(42594.3281), 'train_loss_nll': tensor(42054.9648), 'train_loss_kld': tensor(539.3694)}\n",
            "{'epoch': 100, 'train_loss': tensor(42674.3047), 'train_loss_nll': tensor(42135.2266), 'train_loss_kld': tensor(539.0775)}\n",
            "{'epoch': 101, 'train_loss': tensor(42604.8281), 'train_loss_nll': tensor(42067.5703), 'train_loss_kld': tensor(537.2592)}\n",
            "{'epoch': 102, 'train_loss': tensor(42646.9492), 'train_loss_nll': tensor(42109.5508), 'train_loss_kld': tensor(537.4066)}\n",
            "{'epoch': 103, 'train_loss': tensor(42443.2656), 'train_loss_nll': tensor(41905.8203), 'train_loss_kld': tensor(537.4395)}\n",
            "{'epoch': 104, 'train_loss': tensor(42695.4648), 'train_loss_nll': tensor(42159.5938), 'train_loss_kld': tensor(535.8674)}\n",
            "{'epoch': 105, 'train_loss': tensor(42685.5742), 'train_loss_nll': tensor(42146.6914), 'train_loss_kld': tensor(538.8836)}\n",
            "{'epoch': 106, 'train_loss': tensor(42623.6133), 'train_loss_nll': tensor(42081.8750), 'train_loss_kld': tensor(541.7393)}\n",
            "{'epoch': 107, 'train_loss': tensor(42948.9531), 'train_loss_nll': tensor(42407.4531), 'train_loss_kld': tensor(541.4991)}\n",
            "{'epoch': 108, 'train_loss': tensor(42722.1211), 'train_loss_nll': tensor(42181.1016), 'train_loss_kld': tensor(541.0218)}\n",
            "{'epoch': 109, 'train_loss': tensor(42571.9336), 'train_loss_nll': tensor(42034.0039), 'train_loss_kld': tensor(537.9326)}\n",
            "{'epoch': 110, 'train_loss': tensor(42572.2617), 'train_loss_nll': tensor(42032.2500), 'train_loss_kld': tensor(540.0076)}\n",
            "{'epoch': 111, 'train_loss': tensor(42661.9219), 'train_loss_nll': tensor(42124.1758), 'train_loss_kld': tensor(537.7453)}\n",
            "{'epoch': 112, 'train_loss': tensor(42473.9453), 'train_loss_nll': tensor(41935.6797), 'train_loss_kld': tensor(538.2643)}\n",
            "{'epoch': 113, 'train_loss': tensor(42838.1406), 'train_loss_nll': tensor(42301.3008), 'train_loss_kld': tensor(536.8367)}\n",
            "{'epoch': 114, 'train_loss': tensor(42377.7344), 'train_loss_nll': tensor(41840.4531), 'train_loss_kld': tensor(537.2805)}\n",
            "{'epoch': 115, 'train_loss': tensor(42507.3398), 'train_loss_nll': tensor(41971.3242), 'train_loss_kld': tensor(536.0139)}\n",
            "{'epoch': 116, 'train_loss': tensor(42417.2734), 'train_loss_nll': tensor(41878.), 'train_loss_kld': tensor(539.2734)}\n",
            "{'epoch': 117, 'train_loss': tensor(42928.9883), 'train_loss_nll': tensor(42390.5586), 'train_loss_kld': tensor(538.4250)}\n",
            "{'epoch': 118, 'train_loss': tensor(42630.2617), 'train_loss_nll': tensor(42091.8984), 'train_loss_kld': tensor(538.3615)}\n",
            "{'epoch': 119, 'train_loss': tensor(42616.9141), 'train_loss_nll': tensor(42079.8750), 'train_loss_kld': tensor(537.0380)}\n",
            "{'epoch': 120, 'train_loss': tensor(42655.6016), 'train_loss_nll': tensor(42118.3281), 'train_loss_kld': tensor(537.2673)}\n",
            "{'epoch': 121, 'train_loss': tensor(42754.3555), 'train_loss_nll': tensor(42217.5156), 'train_loss_kld': tensor(536.8373)}\n",
            "{'epoch': 122, 'train_loss': tensor(42476.7969), 'train_loss_nll': tensor(41938.8984), 'train_loss_kld': tensor(537.8887)}\n",
            "{'epoch': 123, 'train_loss': tensor(42833.0664), 'train_loss_nll': tensor(42291.7188), 'train_loss_kld': tensor(541.3466)}\n",
            "{'epoch': 124, 'train_loss': tensor(42661.9258), 'train_loss_nll': tensor(42119.9453), 'train_loss_kld': tensor(541.9813)}\n",
            "{'epoch': 125, 'train_loss': tensor(42628.3086), 'train_loss_nll': tensor(42086.3594), 'train_loss_kld': tensor(541.9514)}\n",
            "{'epoch': 126, 'train_loss': tensor(42781.6797), 'train_loss_nll': tensor(42238.5469), 'train_loss_kld': tensor(543.1334)}\n",
            "{'epoch': 127, 'train_loss': tensor(42665.0547), 'train_loss_nll': tensor(42123.1602), 'train_loss_kld': tensor(541.8936)}\n",
            "{'epoch': 128, 'train_loss': tensor(42927.2539), 'train_loss_nll': tensor(42385.4961), 'train_loss_kld': tensor(541.7569)}\n",
            "{'epoch': 129, 'train_loss': tensor(42650.3711), 'train_loss_nll': tensor(42108.3633), 'train_loss_kld': tensor(542.0017)}\n",
            "{'epoch': 130, 'train_loss': tensor(42913.8945), 'train_loss_nll': tensor(42369.3984), 'train_loss_kld': tensor(544.4970)}\n",
            "{'epoch': 131, 'train_loss': tensor(42769.2383), 'train_loss_nll': tensor(42222.3633), 'train_loss_kld': tensor(546.8718)}\n",
            "{'epoch': 132, 'train_loss': tensor(42682.7539), 'train_loss_nll': tensor(42136.1133), 'train_loss_kld': tensor(546.6371)}\n",
            "{'epoch': 133, 'train_loss': tensor(42482.7734), 'train_loss_nll': tensor(41934.6289), 'train_loss_kld': tensor(548.1437)}\n",
            "{'epoch': 134, 'train_loss': tensor(42663.9805), 'train_loss_nll': tensor(42120.7266), 'train_loss_kld': tensor(543.2501)}\n",
            "{'epoch': 135, 'train_loss': tensor(42799.5391), 'train_loss_nll': tensor(42257.0781), 'train_loss_kld': tensor(542.4644)}\n",
            "{'epoch': 136, 'train_loss': tensor(42802.5000), 'train_loss_nll': tensor(42261.7500), 'train_loss_kld': tensor(540.7505)}\n",
            "{'epoch': 137, 'train_loss': tensor(42439.6719), 'train_loss_nll': tensor(41895.6094), 'train_loss_kld': tensor(544.0642)}\n",
            "{'epoch': 138, 'train_loss': tensor(42412.7852), 'train_loss_nll': tensor(41870.6914), 'train_loss_kld': tensor(542.0936)}\n",
            "{'epoch': 139, 'train_loss': tensor(42521.3008), 'train_loss_nll': tensor(41978.1484), 'train_loss_kld': tensor(543.1534)}\n",
            "{'epoch': 140, 'train_loss': tensor(42646.8281), 'train_loss_nll': tensor(42105.3086), 'train_loss_kld': tensor(541.5210)}\n",
            "{'epoch': 141, 'train_loss': tensor(42875.6289), 'train_loss_nll': tensor(42335.3594), 'train_loss_kld': tensor(540.2665)}\n",
            "{'epoch': 142, 'train_loss': tensor(42715.7188), 'train_loss_nll': tensor(42175.2031), 'train_loss_kld': tensor(540.5164)}\n",
            "{'epoch': 143, 'train_loss': tensor(42490.7852), 'train_loss_nll': tensor(41950.8281), 'train_loss_kld': tensor(539.9551)}\n",
            "{'epoch': 144, 'train_loss': tensor(42737.5859), 'train_loss_nll': tensor(42195.5898), 'train_loss_kld': tensor(541.9903)}\n",
            "{'epoch': 145, 'train_loss': tensor(42702.9141), 'train_loss_nll': tensor(42160.5664), 'train_loss_kld': tensor(542.3481)}\n",
            "{'epoch': 146, 'train_loss': tensor(42685.8359), 'train_loss_nll': tensor(42144.9297), 'train_loss_kld': tensor(540.9062)}\n",
            "{'epoch': 147, 'train_loss': tensor(42527.4609), 'train_loss_nll': tensor(41987.6406), 'train_loss_kld': tensor(539.8182)}\n",
            "{'epoch': 148, 'train_loss': tensor(42679.3711), 'train_loss_nll': tensor(42141.4453), 'train_loss_kld': tensor(537.9256)}\n",
            "{'epoch': 149, 'train_loss': tensor(42659.6289), 'train_loss_nll': tensor(42121.9141), 'train_loss_kld': tensor(537.7145)}\n",
            "{'epoch': 150, 'train_loss': tensor(42565.3594), 'train_loss_nll': tensor(42027.8086), 'train_loss_kld': tensor(537.5485)}\n",
            "{'epoch': 151, 'train_loss': tensor(42609.4688), 'train_loss_nll': tensor(42071.9219), 'train_loss_kld': tensor(537.5522)}\n",
            "{'epoch': 152, 'train_loss': tensor(42466.0039), 'train_loss_nll': tensor(41927.7852), 'train_loss_kld': tensor(538.2247)}\n",
            "{'epoch': 153, 'train_loss': tensor(42681.2305), 'train_loss_nll': tensor(42142.5547), 'train_loss_kld': tensor(538.6672)}\n",
            "{'epoch': 154, 'train_loss': tensor(42510.7852), 'train_loss_nll': tensor(41973.1953), 'train_loss_kld': tensor(537.5863)}\n",
            "{'epoch': 155, 'train_loss': tensor(42624.7344), 'train_loss_nll': tensor(42085.8594), 'train_loss_kld': tensor(538.8748)}\n",
            "{'epoch': 156, 'train_loss': tensor(42670.8047), 'train_loss_nll': tensor(42132.3594), 'train_loss_kld': tensor(538.4427)}\n",
            "{'epoch': 157, 'train_loss': tensor(42554.8594), 'train_loss_nll': tensor(42017.0391), 'train_loss_kld': tensor(537.8262)}\n",
            "{'epoch': 158, 'train_loss': tensor(42875.0469), 'train_loss_nll': tensor(42338.6992), 'train_loss_kld': tensor(536.3473)}\n",
            "{'epoch': 159, 'train_loss': tensor(42541.1406), 'train_loss_nll': tensor(42005.1133), 'train_loss_kld': tensor(536.0220)}\n",
            "{'epoch': 160, 'train_loss': tensor(42797.9258), 'train_loss_nll': tensor(42261.5938), 'train_loss_kld': tensor(536.3274)}\n",
            "{'epoch': 161, 'train_loss': tensor(42789.6992), 'train_loss_nll': tensor(42253.2344), 'train_loss_kld': tensor(536.4632)}\n",
            "{'epoch': 162, 'train_loss': tensor(42319.4883), 'train_loss_nll': tensor(41782.2266), 'train_loss_kld': tensor(537.2626)}\n",
            "{'epoch': 163, 'train_loss': tensor(42589.7031), 'train_loss_nll': tensor(42053.5781), 'train_loss_kld': tensor(536.1210)}\n",
            "{'epoch': 164, 'train_loss': tensor(42483.9141), 'train_loss_nll': tensor(41947.6562), 'train_loss_kld': tensor(536.2609)}\n",
            "{'epoch': 165, 'train_loss': tensor(42842.0664), 'train_loss_nll': tensor(42304.8594), 'train_loss_kld': tensor(537.2049)}\n",
            "{'epoch': 166, 'train_loss': tensor(42611.8984), 'train_loss_nll': tensor(42073.3789), 'train_loss_kld': tensor(538.5205)}\n",
            "{'epoch': 167, 'train_loss': tensor(42576.9844), 'train_loss_nll': tensor(42038.4531), 'train_loss_kld': tensor(538.5334)}\n",
            "{'epoch': 168, 'train_loss': tensor(42828.3633), 'train_loss_nll': tensor(42288.9453), 'train_loss_kld': tensor(539.4189)}\n",
            "{'epoch': 169, 'train_loss': tensor(42831.4258), 'train_loss_nll': tensor(42294.5898), 'train_loss_kld': tensor(536.8363)}\n",
            "{'epoch': 170, 'train_loss': tensor(42649.0117), 'train_loss_nll': tensor(42112.3984), 'train_loss_kld': tensor(536.6121)}\n",
            "{'epoch': 171, 'train_loss': tensor(42537.2891), 'train_loss_nll': tensor(41998.8906), 'train_loss_kld': tensor(538.3976)}\n",
            "{'epoch': 172, 'train_loss': tensor(42422.4805), 'train_loss_nll': tensor(41885.2539), 'train_loss_kld': tensor(537.2257)}\n",
            "{'epoch': 173, 'train_loss': tensor(42754.0703), 'train_loss_nll': tensor(42217.5391), 'train_loss_kld': tensor(536.5329)}\n",
            "{'epoch': 174, 'train_loss': tensor(42528.5039), 'train_loss_nll': tensor(41991.5352), 'train_loss_kld': tensor(536.9705)}\n",
            "{'epoch': 175, 'train_loss': tensor(42462.2188), 'train_loss_nll': tensor(41925.9180), 'train_loss_kld': tensor(536.3051)}\n",
            "{'epoch': 176, 'train_loss': tensor(42461.8242), 'train_loss_nll': tensor(41926.4609), 'train_loss_kld': tensor(535.3621)}\n",
            "{'epoch': 177, 'train_loss': tensor(42455.7891), 'train_loss_nll': tensor(41918.8438), 'train_loss_kld': tensor(536.9504)}\n",
            "{'epoch': 178, 'train_loss': tensor(42439.3203), 'train_loss_nll': tensor(41903.4609), 'train_loss_kld': tensor(535.8605)}\n",
            "{'epoch': 179, 'train_loss': tensor(42579.9648), 'train_loss_nll': tensor(42041.4688), 'train_loss_kld': tensor(538.5020)}\n",
            "{'epoch': 180, 'train_loss': tensor(42808.3008), 'train_loss_nll': tensor(42272.6797), 'train_loss_kld': tensor(535.6201)}\n",
            "{'epoch': 181, 'train_loss': tensor(42963.2148), 'train_loss_nll': tensor(42427.7969), 'train_loss_kld': tensor(535.4224)}\n",
            "{'epoch': 182, 'train_loss': tensor(42544.4961), 'train_loss_nll': tensor(42010.0312), 'train_loss_kld': tensor(534.4662)}\n",
            "{'epoch': 183, 'train_loss': tensor(42652.8242), 'train_loss_nll': tensor(42116.9141), 'train_loss_kld': tensor(535.9121)}\n",
            "{'epoch': 184, 'train_loss': tensor(42430.3633), 'train_loss_nll': tensor(41894.8906), 'train_loss_kld': tensor(535.4744)}\n",
            "{'epoch': 185, 'train_loss': tensor(42583.1016), 'train_loss_nll': tensor(42045.7383), 'train_loss_kld': tensor(537.3589)}\n",
            "{'epoch': 186, 'train_loss': tensor(42519.0859), 'train_loss_nll': tensor(41985.9688), 'train_loss_kld': tensor(533.1104)}\n",
            "{'epoch': 187, 'train_loss': tensor(42498.0781), 'train_loss_nll': tensor(41963.3047), 'train_loss_kld': tensor(534.7678)}\n",
            "{'epoch': 188, 'train_loss': tensor(42612.5938), 'train_loss_nll': tensor(42076.5898), 'train_loss_kld': tensor(536.0052)}\n",
            "{'epoch': 189, 'train_loss': tensor(42594.3867), 'train_loss_nll': tensor(42059.9609), 'train_loss_kld': tensor(534.4254)}\n",
            "{'epoch': 190, 'train_loss': tensor(42643.6992), 'train_loss_nll': tensor(42108.3711), 'train_loss_kld': tensor(535.3289)}\n",
            "{'epoch': 191, 'train_loss': tensor(42421.4766), 'train_loss_nll': tensor(41885.5312), 'train_loss_kld': tensor(535.9442)}\n",
            "{'epoch': 192, 'train_loss': tensor(42563.1016), 'train_loss_nll': tensor(42027.6016), 'train_loss_kld': tensor(535.4969)}\n",
            "{'epoch': 193, 'train_loss': tensor(42756.5234), 'train_loss_nll': tensor(42218.1211), 'train_loss_kld': tensor(538.4041)}\n",
            "{'epoch': 194, 'train_loss': tensor(42622.6094), 'train_loss_nll': tensor(42085.3945), 'train_loss_kld': tensor(537.2155)}\n",
            "{'epoch': 195, 'train_loss': tensor(42537.0898), 'train_loss_nll': tensor(42000.7812), 'train_loss_kld': tensor(536.3076)}\n",
            "{'epoch': 196, 'train_loss': tensor(42805.8906), 'train_loss_nll': tensor(42269.1289), 'train_loss_kld': tensor(536.7595)}\n",
            "{'epoch': 197, 'train_loss': tensor(42436.8516), 'train_loss_nll': tensor(41899.0859), 'train_loss_kld': tensor(537.7650)}\n",
            "{'epoch': 198, 'train_loss': tensor(42553.6797), 'train_loss_nll': tensor(42016.1289), 'train_loss_kld': tensor(537.5530)}\n",
            "{'epoch': 199, 'train_loss': tensor(42772.1289), 'train_loss_nll': tensor(42232.6133), 'train_loss_kld': tensor(539.5117)}\n",
            "{'epoch': 200, 'train_loss': tensor(42582.8242), 'train_loss_nll': tensor(42046.1836), 'train_loss_kld': tensor(536.6410)}\n"
          ]
        }
      ],
      "source": [
        "v = custom_vec.vocabulary_\n",
        "\n",
        "alpha = [0.1,0.5,1.0,2.0,10.0]\n",
        "\n",
        "topic_list = [] \n",
        "for i in alpha:\n",
        "  wfile = open(\"/content/sample_data/new_topics.txt\", \"w\")\n",
        "\n",
        "  wfile.write(\"-----------Top 10 words for New Alpha----------\\n\")\n",
        "\n",
        "  new_beta = new_alphas(i)\n",
        "\n",
        "  def get_Topics_DVAE(beta, vocab, path,num_topics,wfile):\n",
        "    for topic in new_beta:\n",
        "      wfile.write(\"-----------Topic-----------\\n\")\n",
        "      indices = []\n",
        "      lis = []\n",
        "      s = topic.sort()\n",
        "      indices = s.indices[-10:]\n",
        "      indices = indices.tolist()\n",
        "\n",
        "      for i in indices:  \n",
        "        lis.append( [k for k, val in v.items() if val == i])\n",
        "  \n",
        "      wfile.write(str(lis)+\"\\n\\n\\n\")\n",
        "      topic_list.append(lis)\n",
        "\n",
        "  get_Topics_DVAE(new_beta, vocab,path, num_topics,wfile)\n",
        "  wfile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5155a89",
      "metadata": {
        "id": "e5155a89"
      },
      "source": [
        "# Task 2: Evaluation Measure"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c5a97f",
      "metadata": {
        "id": "53c5a97f"
      },
      "source": [
        "## TODO: Get Reference Corpus\n",
        "The preprocessed data will be used as Reference Corpus to calculate topic coherence, diversity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11aeaf7c",
      "metadata": {
        "id": "11aeaf7c"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "# TODO: Import the data and get ten year data from the file.\n",
        "\n",
        "print('reading raw data...')\n",
        "\n",
        "data = pd.read_csv(r'/content/train/papers.csv')\n",
        "\n",
        "#taking 10 years of data from the csv\n",
        "df = data.query('year >= 1989 and year <= 1998')\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "data = df['full_text']\n",
        "data.dropna(inplace=True)\n",
        "df.shape \n",
        "# TODO: Use the same preprocessing step that used for training the model \n",
        "#       (such as tokenization, remove stopwords, punctuations, words with word length less than three,\n",
        "#       min_df/max_df in CountVectorizer to remove term with lower/higher document frequency)\n",
        "\n",
        "cvectorizer = CountVectorizer(stop_words = 'english',min_df = 2,max_df = 25) \n",
        "\n",
        "\n",
        "tokens = []\n",
        "\n",
        "for sent in data:\n",
        "\n",
        "  # lower case\n",
        "  sent = sent.lower() \n",
        "\n",
        "  #remove whitespaces\n",
        "  sent_w = re.sub(r'\\b\\w{1,3}\\b', '', sent)\n",
        "\n",
        "  #remove punctuations\n",
        "  sent_p = \"\".join([char for char in sent_w if char not in string.punctuation])\n",
        "\n",
        "  #remove numbers\n",
        "  sent_n =  re.sub(r'\\d+', '', sent_p)\n",
        "\n",
        "  #tokenisation\n",
        "  words = word_tokenize(sent_n)\n",
        "\n",
        "  #remove short words\n",
        "  sent_b= ' '.join(word for word in words if len(word)>3)\n",
        "  tokens.append(sent_b)\n",
        "\n",
        "# TODO: Use fit_transform from CountVectorizer to get document-term matrix.\n",
        "cvz = cvectorizer.fit_transform(tokens)\n",
        "print(\"Shape of Tokenizer\")\n",
        "print(cwm.shape)\n",
        "\n",
        "# Save it to csv file. This csv file will be used as refernece corpus for evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffebc6db",
      "metadata": {
        "id": "ffebc6db"
      },
      "source": [
        "## TODO: Get topic coherence \n",
        "Definition for pointwise mutual information is:\n",
        "    $$ p m i \\equiv \\log \\left[\\frac{p(x, y)}{p(x) p(y)}\\right] $$\n",
        "Whereas for normalized pointwise mutual information is:\n",
        "    $$ n p m i \\equiv \\frac{p m i}{-\\log p(x, y)} $$\n",
        "NPMI must be found within a certain window size. Using a window size of 10, the window would move over the documents 10 word tokens at a time. The window size can be used here as a document. In other words, you need to find the word count in each document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "748734ff",
      "metadata": {
        "id": "748734ff"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from math import log\n",
        "# Calculate the coherence using the NPMI equation\n",
        "\n",
        "def topic_coherence(ref_data, beta, n_top_words=10):\n",
        "    \"\"\"Returns topic coherence.\n",
        "    \"\"\"\n",
        "    vocab = construct_vocab(data)\n",
        "\n",
        "    for (w1, w2, pmi) in calculate_pmi(vocab):\n",
        "        print(\"{}_{}: {:.3f}\".format(w1, w2, pmi))\n",
        "    \n",
        "    \n",
        "    return (pmi - log(joint_prob)) / -log(joint_prob)\n",
        "    \n",
        "\n",
        "def gen_bigrams(data, window_size=5):\n",
        "    for idx in range(len(data)):\n",
        "        window = data[idx: idx + window_size]\n",
        "       \n",
        "        if len(window) < 2:\n",
        "            break\n",
        "            \n",
        "        w = window[0]\n",
        "        for next_word in window[1:]:\n",
        "            yield (w, next_word)\n",
        "            \n",
        "\n",
        "def construct_vocab(data):\n",
        "    vocab = Counter()\n",
        "    \n",
        "    for (w1, w2) in gen_bigrams(data, window_size=10): # count 1gram & 2gram\n",
        "        vocab.update([w1, w2, (w1, w2)])\n",
        "    return vocab\n",
        "        \n",
        "\n",
        "def calculate_pmi(vocab):\n",
        "    det = sum(vocab.values())\n",
        "    \n",
        "    for (w1, w2) in filter(lambda el: isinstance(el, tuple), vocab):\n",
        "        p_a, p_b = float(vocab[w1]), float(vocab[w2])\n",
        "        p_ab = float(vocab[(w1, w2)])\n",
        "        \n",
        "        yield (w1, w2, log((det * p_ab) / (p_a * p_b), 2))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0171b78f",
      "metadata": {
        "id": "0171b78f"
      },
      "source": [
        "## TODO: Get topic diversity\n",
        "Diversity is how many unique words are in the top 10 words among all topics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdfeacb6",
      "metadata": {
        "id": "fdfeacb6"
      },
      "outputs": [],
      "source": [
        "def _diversity(beta, num_topics, num_words):\n",
        "    \"\"\"Returns topic diversity.\n",
        "    \"\"\"\n",
        "    n_unique = \n",
        "    diversity = \n",
        "    \n",
        "    return diversity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbd0d75f",
      "metadata": {
        "id": "bbd0d75f"
      },
      "source": [
        "## TODO: Find the topic quality for all α-values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b50090bc",
      "metadata": {
        "id": "b50090bc"
      },
      "outputs": [],
      "source": [
        "def get_topic_quality(beta, ref_data):\n",
        "    \"\"\"Returns topic quality.\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame()\n",
        "    num_topics = beta.shape[0]\n",
        "    num_words = beta.shape[1]\n",
        "    diversity = _diversity(beta[:,:], num_topics, num_words)\n",
        "    coherence = topic_coherence(ref_data,beta[:, :])\n",
        "    \n",
        "    # TODO: calculate topic quality\n",
        "    quality = \n",
        "    print('Topic Quality is: {}'.format(quality))\n",
        "    data['tq'] = quality\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0756164",
      "metadata": {
        "id": "a0756164"
      },
      "outputs": [],
      "source": [
        "def evaluation(filename, dataToEval):\n",
        "    lines = []\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            lines.append(line[0:-1].split(sep=' '))\n",
        "    beta = np.array(lines)\n",
        "    ref_data = pd.read_csv(dataToEval)\n",
        "    results = get_topic_quality(beta, ref_data)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    refCorpus = \n",
        "    topicsPath = \n",
        "    \n",
        "    evaluation(topicsPath, refCorpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "183c3737",
      "metadata": {
        "id": "183c3737"
      },
      "source": [
        "## TODO:  What relation between α and the topic quality do you find?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b590f504",
      "metadata": {
        "id": "b590f504"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}