{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbGOxT_8qq4t"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huivIBJvm0Y9"
      },
      "source": [
        "# 1. (b). Attention\n",
        "\n",
        "Define $X$, $W_Q$, $W_K$, and $W_V$. Remember that you need to convert them to tensors. Print the values.\n",
        "\n",
        "### NOTE: Remember to round up your results maybe to 1 or 2 decimal places."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k37t9_iz7cSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6b8356-ea2d-4a0f-931b-4db32590e597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 0, 1, 0],\n",
            "        [0, 2, 0, 2],\n",
            "        [1, 1, 1, 1]])\n",
            "tensor([[0, 0, 1],\n",
            "        [1, 1, 0],\n",
            "        [0, 1, 0],\n",
            "        [1, 1, 0]])\n",
            "tensor([[1, 0, 1],\n",
            "        [1, 0, 0],\n",
            "        [0, 0, 1],\n",
            "        [0, 1, 1]])\n",
            "tensor([[0, 2, 0],\n",
            "        [0, 3, 0],\n",
            "        [1, 0, 3],\n",
            "        [1, 1, 0]])\n"
          ]
        }
      ],
      "source": [
        "# Initialisation\n",
        "\n",
        "x = [\n",
        "  [1, 0, 1, 0],\n",
        "  [0, 2, 0, 2],\n",
        "  [1, 1, 1, 1]\n",
        " ]\n",
        "\n",
        "w_k = [\n",
        "  [0, 0, 1],\n",
        "  [1, 1, 0],\n",
        "  [0, 1, 0],\n",
        "  [1, 1, 0]\n",
        "]\n",
        "\n",
        "w_q = [\n",
        "  [1, 0, 1],\n",
        "  [1, 0, 0],\n",
        "  [0, 0, 1],\n",
        "  [0, 1, 1]\n",
        "]\n",
        "\n",
        "w_v = [\n",
        "  [0, 2, 0],\n",
        "  [0, 3, 0],\n",
        "  [1, 0, 3],\n",
        "  [1, 1, 0]\n",
        "]\n",
        "\n",
        "# TODO: Convert to tensors (use the tensor function from the torch library)\n",
        "\n",
        "x = torch.tensor(x)\n",
        "w_k = torch.tensor(w_k)\n",
        "w_q = torch.tensor(w_q)\n",
        "w_v = torch.tensor(w_v)\n",
        "\n",
        "# TODO: Print the values\n",
        "\n",
        "print(x)\n",
        "print(w_k)\n",
        "print(w_q)\n",
        "print(w_v)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRKPPxt6pHVk"
      },
      "source": [
        "Calculate the values of $Q$, $K$, and $V$. Print the values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NUcH-CbpHsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a47e3c2-a13d-4be3-e9ed-74dd91dc082c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 1],\n",
            "        [4, 4, 0],\n",
            "        [2, 3, 1]])\n",
            "tensor([[1, 0, 2],\n",
            "        [2, 2, 2],\n",
            "        [2, 1, 3]])\n",
            "tensor([[1, 2, 3],\n",
            "        [2, 8, 0],\n",
            "        [2, 6, 3]])\n"
          ]
        }
      ],
      "source": [
        "# TODO: Calculate Q, K, and V\n",
        "\n",
        "k = torch.matmul(x , w_k)\n",
        "q = torch.matmul(x , w_q)\n",
        "v = torch.matmul(x , w_v)\n",
        "\n",
        "# TODO: Print the values of Q, K, and V\n",
        "\n",
        "print(k)\n",
        "print(q)\n",
        "print(v)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-nmL4ttpOyl"
      },
      "source": [
        "Calculate the attention scores from the queries. Print the attention scores.\n",
        "\n",
        "*Hint: Think which matrices you need for this.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10Yf8BCXpPFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d692965-589b-4e5e-8491-c82e0a7e2676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2,  4,  4],\n",
            "        [ 4, 16, 12],\n",
            "        [ 4, 12, 10]])\n"
          ]
        }
      ],
      "source": [
        "# TODO: Calculate the attention scores matrix\n",
        "\n",
        "attn_scores = torch.matmul(q , torch.transpose(k , 0 ,1))\n",
        "\n",
        "# TODO: Print the matrix\n",
        "\n",
        "print(attn_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU-u5H1upPX_"
      },
      "source": [
        "Calculate the *softmax* for the attention scores. Print the value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvR78ytRpPxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fbe621-a74e-4bc2-cca2-c97af761bed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1000, 0.5000, 0.5000],\n",
            "        [0.0000, 1.0000, 0.0000],\n",
            "        [0.0000, 0.9000, 0.1000]])\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.functional import softmax\n",
        "\n",
        "# TODO: Calculate the softmax\n",
        "attn_scores_softmax = softmax(attn_scores.type(torch.FloatTensor),dim=-1)\n",
        "\n",
        "attn_scores_softmax = torch.round(attn_scores_softmax,decimals = 1)\n",
        "\n",
        "# TODO: An extra step needs to be performed here. What could it be?\n",
        "# Hint: Check the notebook again ;)\n",
        "\n",
        "# TODO: Print the value\n",
        "print(attn_scores_softmax)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iv8drIsrBJh"
      },
      "source": [
        "Calculate the weighted values by multiplying the softmax attention scores with the values. Print the weighted values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HOcaFBKrCS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1cfe1cf-3f40-4209-be8a-782f130838f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1000, 0.2000, 0.3000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[1.0000, 4.0000, 0.0000],\n",
            "         [2.0000, 8.0000, 0.0000],\n",
            "         [1.8000, 7.2000, 0.0000]],\n",
            "\n",
            "        [[1.0000, 3.0000, 1.5000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.2000, 0.6000, 0.3000]]])\n"
          ]
        }
      ],
      "source": [
        "# TODO: Calculate the weighted values (value matrix with attention scores)\n",
        "v = v.type(torch.FloatTensor)\n",
        "weighted_values = v[:,None] * attn_scores_softmax.T[:,:,None]\n",
        "\n",
        "# TODO: Print the weighted values\n",
        "\n",
        "print(weighted_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVFDauzbrPNo"
      },
      "source": [
        "Finally, sum up the weighted values to get your final result. Print the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XDwJOcWrPfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817bebb9-2a2b-4fd6-c95a-1afb6ce2f721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.1000, 7.2000, 1.8000],\n",
            "        [2.0000, 8.0000, 0.0000],\n",
            "        [2.0000, 7.8000, 0.3000]])\n"
          ]
        }
      ],
      "source": [
        "# TODO: Sum up the weighted values\n",
        "\n",
        "outputs = torch.sum(weighted_values , dim=0)\n",
        "\n",
        "# TODO: Print the final result\n",
        "\n",
        "print(outputs)\n",
        "\n",
        "# You may round up the values or leave them as they are.\n",
        "# Did you get the same results as 1.(b)?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J996FC2kNDVZ"
      },
      "source": [
        "# 2. (b). Transfer Learning\n",
        "\n",
        "The task that you will be working on here is to classify whether a given English sentence is grammatically correct or not. So, this is a task of text classification. You will be working with the CoLA dataset about which you will get know in one of the other slides below.\n",
        "\n",
        "##*NOTE: Most of the code below is already completed for you. You need to complete the missing code in the cells. Also, do not miss any question that is asked in the text cells below. You need to complete the code in this Notebook and submit it. For the text answers, you may answer it here in the text cells, or you may answer them in the PDF along with other answers. If you do not submit the notebook, no marks will be awarded!*\n",
        "\n",
        "First we will install some libraries that we need here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koEeYymA5Enx",
        "outputId": "18dc7174-11ea-4e43-b1e7-92bba8801aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=9766adfcf68f8f4c1722532bf5cd1e886a383c543ea36127a73af917ffa7fbc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 18.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 73.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcy_dI7s5Hxi"
      },
      "source": [
        "Next, we want to import all the important libraries we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTSPhPl-zWsF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import (TensorDataset, \n",
        "                              DataLoader, \n",
        "                              RandomSampler, \n",
        "                              SequentialSampler)\n",
        "\n",
        "from transformers import (BertTokenizer, \n",
        "                          BertForSequenceClassification,\n",
        "                          AdamW,\n",
        "                          BertConfig,\n",
        "                          get_linear_schedule_with_warmup)\n",
        "\n",
        "# Don't worry, we are not using Tensorflow here.\n",
        "# Just using a function from the Keras library\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUn7sNv_5OrC"
      },
      "source": [
        "We now assign the device on which we want our model to train. Preferbly a GPU, if not, then your CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIkUqzYa5PFU",
        "outputId": "489f6dc5-dc1f-4e6a-b726-7ac750feed2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMdnN9xy5rpz"
      },
      "source": [
        "# TODO: Download the dataset\n",
        "\n",
        "Here we download our data. We use the CoLA dataset.\n",
        "\n",
        "The Corpus of Linguistic Acceptability (CoLA) dataset [here](https://nyu-mll.github.io/CoLA/cola_public_1.1.zip) consists of 10657 sentences from 23 linguistics publications, expertly annotated for acceptability (grammaticality) by their original authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPN9CBoR0bzq",
        "outputId": "6efa5eba-d1b0-4b06-c160-ab986d12277d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "--2022-12-10 11:21:22--  https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
            "Resolving nyu-mll.github.io (nyu-mll.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to nyu-mll.github.io (nyu-mll.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255330 (249K) [application/zip]\n",
            "Saving to: ‘cola_public_1.1.zip.1’\n",
            "\n",
            "\rcola_public_1.1.zip   0%[                    ]       0  --.-KB/s               \rcola_public_1.1.zip 100%[===================>] 249.35K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-12-10 11:21:22 (82.6 MB/s) - ‘cola_public_1.1.zip.1’ saved [255330/255330]\n",
            "\n",
            "Archive:  /content/cola_public_1.1.zip\n",
            "replace cola_public/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: cola_public/README      \n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ]
        }
      ],
      "source": [
        "print('Downloading dataset...')\n",
        "\n",
        "# TODO:\n",
        "# Download the file\n",
        "!wget https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
        "\n",
        "\n",
        "# TODO:\n",
        "# Unzip the dataset (if you have not already)\n",
        "\n",
        "!unzip /content/cola_public_1.1.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EXufzbTOlJk"
      },
      "source": [
        "# TODO: Load the dataset\n",
        "\n",
        "Here we load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "WxdQBkhQ0jG2",
        "outputId": "53d80e11-5b3d-4d21-c963-0c00a1a3b7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sentence_source  label label_notes  \\\n",
              "0            gj04      1         NaN   \n",
              "1            gj04      1         NaN   \n",
              "2            gj04      1         NaN   \n",
              "3            gj04      1         NaN   \n",
              "4            gj04      1         NaN   \n",
              "5            gj04      1         NaN   \n",
              "6            gj04      1         NaN   \n",
              "7            gj04      1         NaN   \n",
              "8            gj04      1         NaN   \n",
              "9            gj04      1         NaN   \n",
              "\n",
              "                                            sentence  \n",
              "0  Our friends won't buy this analysis, let alone...  \n",
              "1  One more pseudo generalization and I'm giving up.  \n",
              "2   One more pseudo generalization or I'm giving up.  \n",
              "3     The more we study verbs, the crazier they get.  \n",
              "4          Day by day the facts are getting murkier.  \n",
              "5                              I'll fix you a drink.  \n",
              "6                      Fred watered the plants flat.  \n",
              "7        Bill coughed his way out of the restaurant.  \n",
              "8                      We're dancing the night away.  \n",
              "9                    Herman hammered the metal flat.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc0f8ce8-594d-4f34-9a46-eef80be018f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'll fix you a drink.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fred watered the plants flat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bill coughed his way out of the restaurant.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We're dancing the night away.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Herman hammered the metal flat.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc0f8ce8-594d-4f34-9a46-eef80be018f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc0f8ce8-594d-4f34-9a46-eef80be018f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc0f8ce8-594d-4f34-9a46-eef80be018f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# TODO:\n",
        "# Load the dataset (in_domain_train.tsv) into a pandas dataframe.\n",
        "# use the tab delimiter, and the columns ['sentence_source', 'label', 'label_notes', 'sentence']\n",
        "\n",
        "df = pd.read_csv('cola_public/raw/in_domain_train.tsv', sep='\\t', names = ['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# TODO:\n",
        "# Display top 10 rows from the data\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sguebGes0sAu"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Store the sentences and labels of the data in the variables\n",
        "\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1JwgrqMQhcn"
      },
      "source": [
        "# TODO: Text Preprocessing\n",
        "\n",
        "Here we initialize the BERT tokenizer. You need to complete the code so that the tokenizer is loaded. Next, run the piece of code below and it should work properly if you have loaded the tokenizer without errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "737519d15d644ff4b3ca3a02ac9fca88",
            "dc69fca4d8fa44988ca77afd3afb7b32",
            "dbd9cf50a08747e88489dc18b8fb7281",
            "9894cd17af2d4a239138e589f9fedabc",
            "828411e3885245bd8b1f99a6b3336dfa",
            "f9389d6399384b0882e2f52761de6703",
            "27433c43e82044d4bb910b601ef6c8e7",
            "1fc6eb94a68348abbfba0f8475f0c9ba",
            "60bb266aef4a4617a66a8d9100ca96a5",
            "5be2c591d19c4edfacfb298e53fa4344",
            "5cfc0304b9f643bc8a71925a2fe010ee",
            "a5cb5df34f8a47d4975aca75cc7a39d2",
            "b3566e90e720485ab72bd677e450dc9f",
            "d217f091abc44c06a7741f43e4d8927d",
            "e89b8911ab8d46ce85c020948d0fa995",
            "36cc4328b4bc4a9ab99b4d468e2e0605",
            "eec7f8b1343d480f9aa5680384add121",
            "3107404c85e0486bbabfcb51f5b88192",
            "53889c2f59784f399165c4c436955846",
            "f9d400e836614fa5a59208ed75480076",
            "7160ca9c5b5947ca87437dc20422793a",
            "951eee2bfea241348dfc2e6e179603ba",
            "5ab3295c9b864838b5933038062e5ea1",
            "8a4ceee0ebd745d2a0e28167462f09a1",
            "b8b9da2a022b4fa586b46d1e2e75d919",
            "0aadb49ee87346aca4dc5b1c1c13c561",
            "750b74d8e6fc43199b7d6df7aa4838a6",
            "9f5d78939b22402787ffcf50e4c7905d",
            "980c133f91a647cc84adf82cea74eb02",
            "bad67f9c46744781aa8f8fbd06791750",
            "430f16a5493948cdab5e0a9b135f739d",
            "a0179aa480664bafa180c721e423dc2a",
            "69f821ae6f8541978dd6ef51f628d73e"
          ]
        },
        "id": "xrDLFqbb0uUe",
        "outputId": "2a59822b-63e4-4fa4-98a4-22046a9dc73f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "737519d15d644ff4b3ca3a02ac9fca88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5cb5df34f8a47d4975aca75cc7a39d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ab3295c9b864838b5933038062e5ea1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "MODEL_TOKENIZER_NAME = 'bert-base-uncased'\n",
        "\n",
        "# TODO:\n",
        "# Initialise the BertTokenizer here using the MODEL_TOKENIZER_NAME above and make sure the text is lowercase\n",
        "# Refer: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_TOKENIZER_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "She2ORjnSIOq"
      },
      "source": [
        "Here we apply the tokenization to the data and encode the tokens to ids.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_jlL8Fl0xdj"
      },
      "outputs": [],
      "source": [
        "input_ids = []\n",
        "for sent in sentences:\n",
        "\n",
        "    # TODO:\n",
        "    # Use the tokenizer to tokenize each sentence 'sent'\n",
        "    # Remember to add the special [CLS] and [SEP] tokens\n",
        "    # If you are confused, refer the link in the previous cell\n",
        "\n",
        "    encoded_sent = tokenizer.encode(text = sent, add_special_tokens = True)\n",
        "    input_ids.append(encoded_sent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MmiRGNVamn5"
      },
      "source": [
        "Here we first find the max sequence length of our data and then apply padding to the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBiJ112307d0",
        "outputId": "04e84b9d-28d3-4724-f708-16ee9f5addc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n",
            "\n",
            "Padding all sentences in data ...\n",
            "\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# TODO:\n",
        "# Calculate the max sequence length of the data (input_ids)\n",
        "\n",
        "print('Max sentence length: ', max(len(x) for x in input_ids))\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# Although the max length is 47, we choose 64 as the max length here.\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding all sentences in data ...')\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')\n",
        "type(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LeskUm-bTxF"
      },
      "source": [
        "Here we create the attention mask for our sentences.\n",
        "\n",
        "If a token ID is 0, then its padding. Set mask to 0.\n",
        "\n",
        "If a token ID is not 0, then its a real token. Set mask to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtbQ8taq09Uz"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # TODO:\n",
        "    # Calculate the attention mask here using the logic in the description above\n",
        "      # for x in sent:\n",
        "      #     if x!=0:\n",
        "      #       att_mask.append(1)\n",
        "      #     else:\n",
        "      #       att_mask.append(0)\n",
        "    att_mask = [1 if x != 0 else 0 for x in sent ] \n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrVPRrMLbrp4"
      },
      "source": [
        "# TODO: Data split\n",
        "\n",
        "Here we split the dataset into train and validation sets. You may use the train_test_split() function from sklearn for this. Use any random_state value so that your results are reproducible. You may use the test set size of 10%.\n",
        "\n",
        "Remember you also need to convert the values to tensors as this is pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7AADh9C1YdS"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Split the data into 90% training and 10% validation\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, test_size=0.1)\n",
        "\n",
        "# # TODO:\n",
        "# Now split the masks in the same way\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, test_size=0.1)\n",
        "\n",
        "\n",
        "\n",
        "# TODO:\n",
        "#Convert the values to the tensors here\n",
        "\n",
        "train_inputs = torch.from_numpy(train_inputs)\n",
        "validation_inputs = torch.from_numpy(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG5dDC6AeGUN"
      },
      "source": [
        "Use the PyTorch DataLoader here to load the data into batches of BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsG55D1X1aEg"
      },
      "outputs": [],
      "source": [
        "# PyTorch DataLoader needs to know our batch size for training\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# TODO:\n",
        "# Create the DataLoader for our training set\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_labels, train_masks)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader( train_data, batch_size = BATCH_SIZE, sampler=train_sampler)\n",
        "\n",
        "# TODO:\n",
        "# Now do the same for the validation set\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = RandomSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=BATCH_SIZE, sampler = validation_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax2xwXsHfqzu"
      },
      "source": [
        "# TODO: Your Model\n",
        "\n",
        "Here you load the pretrained model and load it into an instance of BertForSequenceClassification. This part is already done for you.\n",
        "\n",
        "NOTE: This takes some time to download the pretrained model (~440 MB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIC8q27s1eub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43be3ec1-6753-45b1-e917-107eaf556623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYKRMIWWhLVJ"
      },
      "source": [
        "Next we prepare the Optimizer and the learning rate scheduler. AdamW is a class from the HuggingFace library. We use this as our optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsPlPzjY1myB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b26691-5ba0-43ba-fb36-5483fc0bf5e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Initialise the optimizer here using AdamW.\n",
        "# Use the parameters of your model above, and the learning rate and epsilon values given below.\n",
        "# Refer: Check the AdamW library from HuggingFace\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "EPSILON = 1e-8\n",
        "optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps = EPSILON)\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# TODO:\n",
        "# Create the learning rate scheduler with the optimizer\n",
        "# Use zero warmup steps and the total steps of training as inputs\n",
        "# Check the get_linear_schedule_with_warmup function from HuggingFace\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrxY7TMmhMIw"
      },
      "source": [
        "Here you will define the function to find the accuracy of your predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyOLvC1J1qNm"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Function to calculate the accuracy\n",
        "# You need to find how many times predictions are equal to labels, and then divide it by number of labels\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    return  np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy1kv1Zdur4U"
      },
      "source": [
        "Training and Validation phases. Complete the missing pieces of code, and ensure that the code runs properly with errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv-sa5KH1utW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4e2c8b-0573-4711-d261-bff1a0e81e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    50  of    241\n",
            "  Batch   100  of    241\n",
            "  Batch   150  of    241\n",
            "  Batch   200  of    241\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    50  of    241\n",
            "  Batch   100  of    241\n",
            "  Batch   150  of    241\n",
            "  Batch   200  of    241\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    50  of    241\n",
            "  Batch   100  of    241\n",
            "  Batch   150  of    241\n",
            "  Batch   200  of    241\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    50  of    241\n",
            "  Batch   100  of    241\n",
            "  Batch   150  of    241\n",
            "  Batch   200  of    241\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "Training DONE.\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Set your own seed value for easy reproducibility of your results\n",
        "\n",
        "seed_val = 56\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "######### TRAINING PHASE ###########\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress logged every 50 batches\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "\n",
        "            print('  Batch {:>5,}  of  {:>5,}'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # TODO: \n",
        "        # The batch variable contains input_ids, input_masks, and labels.\n",
        "        # You need to assign each of them to the 'device' for training\n",
        "        \n",
        "        #print(batch[2])\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[2].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "#         # TODO:\n",
        "#         # Here you need to clear any previously calculated gradients\n",
        "        model.zero_grad()  \n",
        "        \n",
        "\n",
        "#         # TODO:\n",
        "#         # Perform a forward pass here\n",
        "#         # Remember that your model will need input_ids, input_mask, and labels\n",
        "        \n",
        "        #print( b_labels.size())\n",
        "        outputs = model(b_input_ids, attention_mask= b_input_mask,  labels= b_labels)\t\n",
        "        \n",
        "        # TODO:\n",
        "        # The outputs variable above should now have the loss.\n",
        "        # Extract the loss, and add it to the total_loss variable\n",
        "        # NOTE THAT THESE ARE ALL TENSORS!!!\n",
        "        #print(outputs['loss'])\n",
        "\n",
        "        total_loss += outputs['loss'].item()\n",
        "\n",
        "        # TODO:\n",
        "        # Perform a backward pass here\n",
        "\n",
        "        outputs['loss'].backward()\n",
        "        \n",
        "\n",
        "\n",
        "        # The below code clips the gradients to 1.0 to prevent \n",
        "        # the \"exploding gradients\" problem.\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # TODO:\n",
        "        # Update the parameters of the model here\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        # TODO:\n",
        "        # Update the learning rate here\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "    # TODO:\n",
        "    # Calculate the average loss over the training data\n",
        "    \n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        \n",
        "######### VALIDATION PHASE ###########\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # TODO:\n",
        "            # Perform a forward here too, this time for validation\n",
        "\n",
        "            outputs = model(b_input_ids, labels = b_labels, attention_mask = b_input_mask)\n",
        "        \n",
        "        #logits = outputs[0]\n",
        "        logits = outputs[1] # i think it should outputs[1] as outputs[0} would give loss but we need logits to calculate validation accuracy for this run\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training DONE.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "737519d15d644ff4b3ca3a02ac9fca88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc69fca4d8fa44988ca77afd3afb7b32",
              "IPY_MODEL_dbd9cf50a08747e88489dc18b8fb7281",
              "IPY_MODEL_9894cd17af2d4a239138e589f9fedabc"
            ],
            "layout": "IPY_MODEL_828411e3885245bd8b1f99a6b3336dfa"
          }
        },
        "dc69fca4d8fa44988ca77afd3afb7b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9389d6399384b0882e2f52761de6703",
            "placeholder": "​",
            "style": "IPY_MODEL_27433c43e82044d4bb910b601ef6c8e7",
            "value": "Downloading: 100%"
          }
        },
        "dbd9cf50a08747e88489dc18b8fb7281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fc6eb94a68348abbfba0f8475f0c9ba",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60bb266aef4a4617a66a8d9100ca96a5",
            "value": 231508
          }
        },
        "9894cd17af2d4a239138e589f9fedabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be2c591d19c4edfacfb298e53fa4344",
            "placeholder": "​",
            "style": "IPY_MODEL_5cfc0304b9f643bc8a71925a2fe010ee",
            "value": " 232k/232k [00:00&lt;00:00, 256kB/s]"
          }
        },
        "828411e3885245bd8b1f99a6b3336dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9389d6399384b0882e2f52761de6703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27433c43e82044d4bb910b601ef6c8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fc6eb94a68348abbfba0f8475f0c9ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60bb266aef4a4617a66a8d9100ca96a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5be2c591d19c4edfacfb298e53fa4344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cfc0304b9f643bc8a71925a2fe010ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5cb5df34f8a47d4975aca75cc7a39d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3566e90e720485ab72bd677e450dc9f",
              "IPY_MODEL_d217f091abc44c06a7741f43e4d8927d",
              "IPY_MODEL_e89b8911ab8d46ce85c020948d0fa995"
            ],
            "layout": "IPY_MODEL_36cc4328b4bc4a9ab99b4d468e2e0605"
          }
        },
        "b3566e90e720485ab72bd677e450dc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eec7f8b1343d480f9aa5680384add121",
            "placeholder": "​",
            "style": "IPY_MODEL_3107404c85e0486bbabfcb51f5b88192",
            "value": "Downloading: 100%"
          }
        },
        "d217f091abc44c06a7741f43e4d8927d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53889c2f59784f399165c4c436955846",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9d400e836614fa5a59208ed75480076",
            "value": 28
          }
        },
        "e89b8911ab8d46ce85c020948d0fa995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7160ca9c5b5947ca87437dc20422793a",
            "placeholder": "​",
            "style": "IPY_MODEL_951eee2bfea241348dfc2e6e179603ba",
            "value": " 28.0/28.0 [00:00&lt;00:00, 889B/s]"
          }
        },
        "36cc4328b4bc4a9ab99b4d468e2e0605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec7f8b1343d480f9aa5680384add121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3107404c85e0486bbabfcb51f5b88192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53889c2f59784f399165c4c436955846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d400e836614fa5a59208ed75480076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7160ca9c5b5947ca87437dc20422793a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951eee2bfea241348dfc2e6e179603ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ab3295c9b864838b5933038062e5ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a4ceee0ebd745d2a0e28167462f09a1",
              "IPY_MODEL_b8b9da2a022b4fa586b46d1e2e75d919",
              "IPY_MODEL_0aadb49ee87346aca4dc5b1c1c13c561"
            ],
            "layout": "IPY_MODEL_750b74d8e6fc43199b7d6df7aa4838a6"
          }
        },
        "8a4ceee0ebd745d2a0e28167462f09a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5d78939b22402787ffcf50e4c7905d",
            "placeholder": "​",
            "style": "IPY_MODEL_980c133f91a647cc84adf82cea74eb02",
            "value": "Downloading: 100%"
          }
        },
        "b8b9da2a022b4fa586b46d1e2e75d919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad67f9c46744781aa8f8fbd06791750",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_430f16a5493948cdab5e0a9b135f739d",
            "value": 570
          }
        },
        "0aadb49ee87346aca4dc5b1c1c13c561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0179aa480664bafa180c721e423dc2a",
            "placeholder": "​",
            "style": "IPY_MODEL_69f821ae6f8541978dd6ef51f628d73e",
            "value": " 570/570 [00:00&lt;00:00, 21.0kB/s]"
          }
        },
        "750b74d8e6fc43199b7d6df7aa4838a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5d78939b22402787ffcf50e4c7905d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980c133f91a647cc84adf82cea74eb02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad67f9c46744781aa8f8fbd06791750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "430f16a5493948cdab5e0a9b135f739d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0179aa480664bafa180c721e423dc2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f821ae6f8541978dd6ef51f628d73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}