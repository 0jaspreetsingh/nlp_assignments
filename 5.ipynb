{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c33d6a22-ecfa-44db-b072-0ead37fd6780",
      "metadata": {
        "id": "c33d6a22-ecfa-44db-b072-0ead37fd6780"
      },
      "source": [
        "# Parallel Text Style Transfer\n",
        "In this tutorial we are going to implement an encoder-decoder model based on recurrent neural networks to perform text style transfer. You will implement it step-by-step.\n",
        "## Prerequisites\n",
        "We first need to select a device where we run our model and seed the libraries for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8733e80d-d8c2-4f8f-acaf-e908b940747c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8733e80d-d8c2-4f8f-acaf-e908b940747c",
        "outputId": "f0415359-42e1-4490-e7a3-ebf360954f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# we will use CUDA if it is available\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(DEVICE)\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1428ef44-ddc8-4c46-9c07-d0c5bc138ff3",
      "metadata": {
        "id": "1428ef44-ddc8-4c46-9c07-d0c5bc138ff3"
      },
      "source": [
        "## Data loading\n",
        "In the first step we are going to download and prepare the parallel dataset for text style. We will use the Shakespeare dataset with modern and \"Shakespearean\" sentences. Therefore, download it from https://github.com/harsh19/Shakespearizing-Modern-English/tree/master/data into ./data.\n",
        "\n",
        "Afterwards, we load the dataset, clean it and remove long source sentences. We choose modern sentences as our source style and the original \"Shakespearean\" sentences as the target style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "eHRkXoZ3F0o7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHRkXoZ3F0o7",
        "outputId": "30830814-5cb3-441f-ac25-fc7b12ee05fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Shakespearizing-Modern-English' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone  https://github.com/harsh19/Shakespearizing-Modern-English.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "6863d1f7-5702-454b-8a14-aa3f53cbf600",
      "metadata": {
        "id": "6863d1f7-5702-454b-8a14-aa3f53cbf600"
      },
      "outputs": [],
      "source": [
        "def load_sent(path):\n",
        "    sents = []\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            sents.append(line.split())\n",
        "    return sents\n",
        "\n",
        "\n",
        "def clean_lines(lines):\n",
        "    cleaned = []\n",
        "    for line in lines:\n",
        "        # convert to lower case\n",
        "        line = [word.lower() for word in line]\n",
        "        cleaned.append(line)\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def filter_lines(lines, max_len):\n",
        "    filtered_lines = []\n",
        "    for line in lines:\n",
        "        if len(line[0]) <= max_len:\n",
        "            filtered_lines.append(line)\n",
        "    return filtered_lines\n",
        "\n",
        "MAX_LEN = 20\n",
        "\n",
        "# download data from https://github.com/harsh19/Shakespearizing-Modern-English/tree/master/data into ./data\n",
        "train_modern_sents = clean_lines(load_sent('data/train.modern.nltktok'))\n",
        "train_original_sents = clean_lines(load_sent('data/train.original.nltktok'))\n",
        "train_sents = filter_lines(zip(train_modern_sents, train_original_sents), MAX_LEN)\n",
        "valid_modern_sents = clean_lines(load_sent('data/valid.modern.nltktok'))\n",
        "valid_original_sents = clean_lines(load_sent('data/valid.original.nltktok'))\n",
        "valid_sents = filter_lines(zip(valid_modern_sents, valid_original_sents), MAX_LEN)\n",
        "test_modern_sents = clean_lines(load_sent('data/test.modern.nltktok'))\n",
        "test_original_sents = clean_lines(load_sent('data/test.original.nltktok'))\n",
        "test_sents = filter_lines(zip(test_modern_sents, test_original_sents), MAX_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be43d463-c171-47a7-9695-5688d7f12b4b",
      "metadata": {
        "id": "be43d463-c171-47a7-9695-5688d7f12b4b"
      },
      "source": [
        "## Vocabulary\n",
        "In this step, we are building our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e35c1fc5-1eb3-44e4-9528-ece39921e28b",
      "metadata": {
        "id": "e35c1fc5-1eb3-44e4-9528-ece39921e28b"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold):\n",
        "        self.itos = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
        "        self.stoi = {k: j for j, k in self.itos.items()}\n",
        "\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def build_vocabulary(self, sentence_list):\n",
        "        frequencies = {}  # init the freq dict\n",
        "        idx = 4  # index from which we want our dict to start. We already used 4 indexes for pad, start, end, unk\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "            for word in sentence:\n",
        "                if word not in frequencies.keys():\n",
        "                    frequencies[word] = 1\n",
        "                else:\n",
        "                    frequencies[word] += 1\n",
        "\n",
        "        # limit vocab by removing low freq words\n",
        "        frequencies = {k: v for k, v in frequencies.items() if v > self.freq_threshold}\n",
        "\n",
        "        # create vocab\n",
        "        for word in frequencies.keys():\n",
        "            self.stoi[word] = idx\n",
        "            self.itos[idx] = word\n",
        "            idx += 1\n",
        "\n",
        "    def numericalize(self, text, remove_unk=False):\n",
        "        numericalized_text = []\n",
        "        for token in text:\n",
        "            if token in self.stoi.keys():\n",
        "                numericalized_text.append(self.stoi[token])\n",
        "            elif not remove_unk:  # out-of-vocab words are represented by UNK token index\n",
        "                numericalized_text.append(self.stoi['<UNK>'])\n",
        "        return numericalized_text\n",
        "\n",
        "\n",
        "FREQ_THRESHOLD = 5\n",
        "modern_vocab = Vocabulary(FREQ_THRESHOLD)\n",
        "modern_vocab.build_vocabulary(train_modern_sents)\n",
        "original_vocab = Vocabulary(FREQ_THRESHOLD)\n",
        "original_vocab.build_vocabulary(train_original_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbdb7bf4-d507-461e-ad59-1c995b176bbd",
      "metadata": {
        "id": "dbdb7bf4-d507-461e-ad59-1c995b176bbd"
      },
      "source": [
        "## Numericalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "3505a3e5-b47e-446d-8f89-e8935b70f060",
      "metadata": {
        "id": "3505a3e5-b47e-446d-8f89-e8935b70f060"
      },
      "outputs": [],
      "source": [
        "def numericalize(sentences, remove_unk=False):\n",
        "    numericalized_sentences = []\n",
        "    for sent in sentences:\n",
        "        numericalized_sentences.append((modern_vocab.numericalize(sent[0],remove_unk), original_vocab.numericalize(sent[1],remove_unk)))\n",
        "    return numericalized_sentences\n",
        "\n",
        "\n",
        "PAD_IDX = modern_vocab.stoi['<PAD>']\n",
        "numericalized_train = numericalize(train_sents)\n",
        "numericalized_valid = numericalize(valid_sents)\n",
        "numericalized_test = numericalize(test_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29cffdae-c761-43ed-81fb-a9be06d31f32",
      "metadata": {
        "id": "29cffdae-c761-43ed-81fb-a9be06d31f32",
        "tags": []
      },
      "source": [
        "## Dataset\n",
        "In this part, you are asked to write a Dataset class that holds the parallel dataset, the source and the target vocabulary. It should return the numericalized version of each sentence including start and end of sequence tokens. Think about whether you need these for source as well as target sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "239e3dd9-2168-4396-812c-3d332363e75c",
      "metadata": {
        "id": "239e3dd9-2168-4396-812c-3d332363e75c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class StyleTransferDataset(Dataset):\n",
        "    def __init__(self, data, source_vocab, target_vocab):\n",
        "        #implement\n",
        "        self.data = data\n",
        "        self.source_vocab = source_vocab\n",
        "        self.target_vocab = target_vocab\n",
        "        for sentences in self.data:\n",
        "            sentences[0].insert(0,modern_vocab.stoi['<SOS>'])\n",
        "            sentences[0].append(modern_vocab.stoi['<EOS>'])\n",
        "            sentences[1].insert(0,modern_vocab.stoi['<SOS>'])\n",
        "            sentences[1].append(modern_vocab.stoi['<EOS>'])\n",
        "\n",
        "    def __len__(self):\n",
        "        #implement\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #implement\n",
        "        return self.data[index][0] , self.data[index][1]\n",
        "    \n",
        "\n",
        "\n",
        "train_dataset = StyleTransferDataset(numericalized_train, modern_vocab, original_vocab)\n",
        "valid_dataset = StyleTransferDataset(numericalized_valid, modern_vocab, original_vocab)\n",
        "test_dataset = StyleTransferDataset(numericalized_test, modern_vocab, original_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4df17e9-a559-4617-adff-a668eae641f1",
      "metadata": {
        "id": "c4df17e9-a559-4617-adff-a668eae641f1"
      },
      "source": [
        "## DataLoader\n",
        "Now, use a DataLoader to load the data in batches. The collate function should pad the sequences with the batch dimension as the first dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "48e0f00f-e0c3-40d2-b060-a22159c6f469",
      "metadata": {
        "id": "48e0f00f-e0c3-40d2-b060-a22159c6f469"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "train_batch_size = 64\n",
        "valid_batch_size = 1\n",
        "\n",
        "\n",
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        # implement\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # implement\n",
        "        data_batch, label_batch = [torch.Tensor(data).type(torch.long) for data , label in batch],[torch.Tensor(label).type(torch.long) for data , label in batch]\n",
        "        x_lens = [len(x) for x in data_batch]\n",
        "        y_lens = [len(y) for y in label_batch]\n",
        "        data_batch = pad_sequence(data_batch, batch_first=True, padding_value=self.pad_idx)\n",
        "        label_batch = pad_sequence(label_batch, batch_first=True,\n",
        "                             padding_value=self.pad_idx)\n",
        "        data_batch = data_batch,x_lens\n",
        "        label_batch = label_batch,y_lens\n",
        "        return [data_batch, label_batch]\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True,\n",
        "                          collate_fn=MyCollate(pad_idx=PAD_IDX))\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=valid_batch_size, shuffle=False,\n",
        "                          collate_fn=MyCollate(pad_idx=PAD_IDX))\n",
        "test_loader = DataLoader(test_dataset, batch_size=valid_batch_size, shuffle=False,\n",
        "                         collate_fn=MyCollate(pad_idx=PAD_IDX))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab4644d-60f1-49ed-a44b-7c3d6b4abffc",
      "metadata": {
        "id": "7ab4644d-60f1-49ed-a44b-7c3d6b4abffc"
      },
      "source": [
        "# Model\n",
        "## Encoder-Decoder\n",
        "The encoder-decoder class has references to the encoder, the decoder, the embeddings and the generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "dad2f81d-ec4c-4076-b0dc-b0af1b599893",
      "metadata": {
        "id": "dad2f81d-ec4c-4076-b0dc-b0af1b599893"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many \n",
        "    other models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.trg_embed = trg_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
        "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
        "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
        "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
        "\n",
        "    def encode(self, src, src_mask, src_lengths):\n",
        "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
        "\n",
        "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
        "               decoder_hidden=None):\n",
        "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
        "                            src_mask, trg_mask, hidden=decoder_hidden)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffde54ce-c213-4978-83c8-bc387748c7e2",
      "metadata": {
        "id": "ffde54ce-c213-4978-83c8-bc387748c7e2"
      },
      "source": [
        "## Generator\n",
        "The generator is needed to project from the hidden representation to our target vocab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "fb94b675-0b48-42fb-a196-63a966f0ff5b",
      "metadata": {
        "id": "fb94b675-0b48-42fb-a196-63a966f0ff5b"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89bd9bd1-3134-4353-b1b5-b83c862a6219",
      "metadata": {
        "id": "89bd9bd1-3134-4353-b1b5-b83c862a6219"
      },
      "source": [
        "## Encoder\n",
        "The encoder encodes a given input sequence into list of hidden states of the same length. Here, we use Gated Recurrent Units (GRUs). They are very similar to Long Short-Term Memory (LSTM) with a forget gate, have fewer parameters and lack an output gate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "415991bf-85a5-47ad-9631-590151af2b55",
      "metadata": {
        "id": "415991bf-85a5-47ad-9631-590151af2b55"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers,\n",
        "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
        "\n",
        "    def forward(self, x, mask, lengths):\n",
        "        \"\"\"\n",
        "        Applies a bidirectional GRU to sequence of embeddings x.\n",
        "        The input mini-batch x needs to be sorted by length.\n",
        "        x should have dimensions [batch, time, dim].\n",
        "        \"\"\"\n",
        "        packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "        output, final = self.rnn(packed)\n",
        "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        # we need to manually concatenate the final states for both directions\n",
        "        fwd_final = final[0:final.size(0):2]\n",
        "        bwd_final = final[1:final.size(0):2]\n",
        "        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n",
        "\n",
        "        return output, final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41922e1d-141c-49d1-a363-1882fc815e8e",
      "metadata": {
        "id": "41922e1d-141c-49d1-a363-1882fc815e8e",
        "tags": []
      },
      "source": [
        "## Decoder\n",
        "The decoder is conditioned on the output from the encoder. Its initial hidden state is initialized from the encoder's final hidden vector.\n",
        "\n",
        "For training, we will use teacher forcing. The decoder gets the \"true\" target words as input. You can read this post for details: https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c\n",
        "\n",
        "In inference mode, the decoder will see its own output as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "8ce76634-c3b2-4a52-bce5-822a5c8940f4",
      "metadata": {
        "id": "8ce76634-c3b2-4a52-bce5-822a5c8940f4"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
        "\n",
        "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n",
        "                 bridge=True):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.attention = attention\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_size + 2 * hidden_size, hidden_size, num_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "\n",
        "        # to initialize from the final encoder state\n",
        "        self.bridge = nn.Linear(2 * hidden_size, hidden_size, bias=True) if bridge else None\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.pre_output_layer = nn.Linear(hidden_size + 2 * hidden_size + emb_size,\n",
        "                                          hidden_size, bias=False)\n",
        "\n",
        "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
        "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
        "\n",
        "        # compute context vector using attention mechanism\n",
        "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
        "        context, attn_probs = self.attention(\n",
        "            query=query, proj_key=proj_key,\n",
        "            value=encoder_hidden, mask=src_mask)\n",
        "\n",
        "        # update rnn hidden state\n",
        "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
        "        pre_output = self.dropout_layer(pre_output)\n",
        "        pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "        return output, hidden, pre_output\n",
        "\n",
        "    def forward(self, trg_embed, encoder_hidden, encoder_final,\n",
        "                src_mask, trg_mask, hidden=None, max_len=None):\n",
        "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
        "\n",
        "        # the maximum number of steps to unroll the RNN\n",
        "        if max_len is None:\n",
        "            max_len = trg_mask.size(-1)\n",
        "\n",
        "        # initialize decoder hidden state\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_final)\n",
        "\n",
        "        # pre-compute projected encoder hidden states\n",
        "        # (the \"keys\" for the attention mechanism)\n",
        "        # this is only done for efficiency\n",
        "        proj_key = self.attention.key_layer(encoder_hidden)\n",
        "\n",
        "        # here we store all intermediate hidden states and pre-output vectors\n",
        "        decoder_states = []\n",
        "        pre_output_vectors = []\n",
        "\n",
        "        # unroll the decoder RNN for max_len steps\n",
        "        for i in range(max_len):\n",
        "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
        "            \n",
        "            #implement\n",
        "            out, hidden, pre_output = self.forward_step(\n",
        "            prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
        "            decoder_states.append(out)\n",
        "            pre_output_vectors.append(pre_output)\n",
        "\n",
        "        decoder_states = torch.cat(decoder_states, dim=1)\n",
        "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
        "\n",
        "    def init_hidden(self, encoder_final):\n",
        "        \"\"\"Returns the initial decoder state,\n",
        "        conditioned on the final encoder state.\"\"\"\n",
        "\n",
        "        if encoder_final is None:\n",
        "            return None  # start with zeros\n",
        "\n",
        "        return torch.tanh(self.bridge(encoder_final))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lfTYyddZoGJq",
      "metadata": {
        "id": "lfTYyddZoGJq"
      },
      "source": [
        "##Teacher Forcing\n",
        "Advantage -  During training decoder receives the correct outpur from the training set as the previously decoded result to predict the next output. However, during inference decoder receives the previously decoded result to predict the next output. Teacher forcing improves the training process.\n",
        "\\\n",
        "Disadvantage - suffers from Exposure Bias as the model has to feed its prediction back to itself which causes poor model performance and instability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1340a7-55d3-4d9c-8acd-72e793cc6731",
      "metadata": {
        "id": "4a1340a7-55d3-4d9c-8acd-72e793cc6731"
      },
      "source": [
        "## Attention\n",
        "In this step, you are asked to implement the additive attention mechanism introduced by Bahdanau et al. in this paper https://arxiv.org/pdf/1409.0473.pdf. You can also read this blogpost https://lilianweng.github.io/posts/2018-06-24-attention/ for further explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "dff2d2a9-d0aa-4717-94c8-5d5312bc7d17",
      "metadata": {
        "id": "dff2d2a9-d0aa-4717-94c8-5d5312bc7d17"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
        "## todo\n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "        \n",
        "        self.alphas = None\n",
        "\n",
        "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "\n",
        "        query = self.query_layer(query)\n",
        "        \n",
        "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas        \n",
        "        \n",
        "        context = torch.bmm(alphas, value)\n",
        "        \n",
        "        return context, alphas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7271f6fd-c096-4101-9d13-ce0b32f3f70d",
      "metadata": {
        "id": "7271f6fd-c096-4101-9d13-ce0b32f3f70d"
      },
      "source": [
        "## Creating the model\n",
        "We will use this auxilary function in order to create our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ff147061-4d55-4898-b9cb-401c8c979c8f",
      "metadata": {
        "id": "ff147061-4d55-4898-b9cb-401c8c979c8f"
      },
      "outputs": [],
      "source": [
        "def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "\n",
        "    attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
        "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
        "        nn.Embedding(src_vocab, emb_size),\n",
        "        nn.Embedding(tgt_vocab, emb_size),\n",
        "        Generator(hidden_size, tgt_vocab))\n",
        "\n",
        "    return model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1287459d-1d8e-418c-a726-c9e536a7c650",
      "metadata": {
        "id": "1287459d-1d8e-418c-a726-c9e536a7c650"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "0e45fa3d-7e66-4567-b476-95ada1bc1097",
      "metadata": {
        "id": "0e45fa3d-7e66-4567-b476-95ada1bc1097"
      },
      "outputs": [],
      "source": [
        "class SimpleLossCompute:\n",
        "    \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                              y.contiguous().view(-1))\n",
        "        loss = loss / norm\n",
        "\n",
        "        if self.opt is not None:\n",
        "            loss.backward()\n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "        return loss.data.item() * norm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "998a6b20-41c7-4fac-8796-952e63804a33",
      "metadata": {
        "id": "998a6b20-41c7-4fac-8796-952e63804a33"
      },
      "source": [
        "## Auxiliary batch class\n",
        "This class holds additional information about our sequences, like lenghts, masking for padding that needs to be added before we feed our batches into the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "f6ab3506-7db1-478f-8439-562bbb729a7b",
      "metadata": {
        "id": "f6ab3506-7db1-478f-8439-562bbb729a7b"
      },
      "outputs": [],
      "source": [
        "class Batch:\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\n",
        "    Input is a batch from a torch text iterator.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, src, trg, pad_index):\n",
        "\n",
        "        src, src_lengths = src\n",
        "\n",
        "        self.src = src\n",
        "        self.src_lengths = src_lengths\n",
        "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
        "        self.nseqs = src.size(0)\n",
        "\n",
        "        self.trg = None\n",
        "        self.trg_y = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        if trg is not None:\n",
        "            trg, trg_lengths = trg\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_lengths = trg_lengths\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = (self.trg_y != pad_index)\n",
        "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
        "\n",
        "        self.src = self.src.to(DEVICE)\n",
        "        self.src_mask = self.src_mask.to(DEVICE)\n",
        "\n",
        "        if trg is not None:\n",
        "            self.trg = self.trg.to(DEVICE)\n",
        "            self.trg_y = self.trg_y.to(DEVICE)\n",
        "            self.trg_mask = self.trg_mask.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32eea7a3-9c0b-473c-a87d-6875822273d9",
      "metadata": {
        "id": "32eea7a3-9c0b-473c-a87d-6875822273d9"
      },
      "source": [
        "## Auxiliary functions\n",
        "Here, we implement two additional functions to lookup words in the vocab and create Batch objects from the batch class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "54c5722c-720b-487e-a538-73a4aeffe1ca",
      "metadata": {
        "id": "54c5722c-720b-487e-a538-73a4aeffe1ca"
      },
      "outputs": [],
      "source": [
        "def lookup_words(x, vocab=None):\n",
        "    if vocab is not None:\n",
        "        x = [vocab.itos[i] for i in x]\n",
        "    return [str(t) for t in x]\n",
        "\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
        "    # print(batch[0])\n",
        "    return Batch(batch[0], batch[1], pad_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "570a8fc8-5c62-439a-9751-80c862d4169a",
      "metadata": {
        "id": "570a8fc8-5c62-439a-9751-80c862d4169a"
      },
      "source": [
        "## Greedy decode\n",
        "We will use this function to generate the output in inference mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "3f63ba79-6fb8-479e-a865-28322ecfc67b",
      "metadata": {
        "id": "3f63ba79-6fb8-479e-a865-28322ecfc67b"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
        "    \"\"\"Greedily decode a sentence.\"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
        "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
        "        trg_mask = torch.ones_like(prev_y)\n",
        "\n",
        "    output = []\n",
        "    attention_scores = []\n",
        "    hidden = None\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out, hidden, pre_output = model.decode(\n",
        "                encoder_hidden, encoder_final, src_mask,\n",
        "                prev_y, trg_mask, hidden)\n",
        "\n",
        "            # we predict from the pre-output layer, which is\n",
        "            # a combination of Decoder state, prev emb, and context\n",
        "            prob = model.generator(pre_output[:, -1])\n",
        "\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data.item()\n",
        "        output.append(next_word)\n",
        "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
        "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
        "\n",
        "    output = np.array(output)\n",
        "\n",
        "    # cut off everything starting from\n",
        "    # (only when eos_index provided)\n",
        "    if eos_index is not None:\n",
        "        #implement\n",
        "        f_eos = np.where(output==eos_index)[0]\n",
        "        if len(f_eos) > 0:\n",
        "            output = output[:f_eos[0]]  \n",
        "    \n",
        "    \n",
        "    return output, np.concatenate(attention_scores, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba0f14ed-2a0b-47cb-9b67-a1eb23e7a00b",
      "metadata": {
        "id": "ba0f14ed-2a0b-47cb-9b67-a1eb23e7a00b"
      },
      "source": [
        "## Auxiliary function to print some examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "9bf3bdb0-ffdb-4eca-8f30-446a1a4b22fc",
      "metadata": {
        "id": "9bf3bdb0-ffdb-4eca-8f30-446a1a4b22fc"
      },
      "outputs": [],
      "source": [
        "def print_examples(example_iter, model, n=2, max_len=100,\n",
        "                   sos_index=1,\n",
        "                   src_eos_index=None,\n",
        "                   trg_eos_index=None,\n",
        "                   src_vocab=None, trg_vocab=None):\n",
        "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print()\n",
        "\n",
        "    if src_vocab is not None and trg_vocab is not None:\n",
        "        src_eos_index = src_vocab.stoi['<EOS>']\n",
        "        trg_sos_index = trg_vocab.stoi['<SOS>']\n",
        "        trg_eos_index = trg_vocab.stoi['<EOS>']\n",
        "    else:\n",
        "        src_eos_index = None\n",
        "        trg_sos_index = 1\n",
        "        trg_eos_index = None\n",
        "\n",
        "    for i, batch in enumerate(example_iter):\n",
        "\n",
        "        src = batch.src.cpu().numpy()[0, :]\n",
        "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
        "\n",
        "        # remove  (if it is there)\n",
        "        src = src[:-1] if src[-1] == src_eos_index else src\n",
        "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg\n",
        "\n",
        "        result, _ = greedy_decode(\n",
        "            model, batch.src, batch.src_mask, batch.src_lengths,\n",
        "            max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
        "        print(\"Example #%d\" % (i + 1))\n",
        "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
        "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
        "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
        "        print()\n",
        "\n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d431052e-03ce-4c0a-86a9-cb05452ea32b",
      "metadata": {
        "id": "d431052e-03ce-4c0a-86a9-cb05452ea32b"
      },
      "source": [
        "## Run one epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "7b3509bd-0ee4-48b4-9646-4f3c8f1bd58b",
      "metadata": {
        "id": "7b3509bd-0ee4-48b4-9646-4f3c8f1bd58b"
      },
      "outputs": [],
      "source": [
        "import time, math\n",
        "\n",
        "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
        "    \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    print_tokens = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter, 1):\n",
        "       \n",
        "        out, _, pre_output = model.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask, batch.src_lengths, batch.trg_lengths)\n",
        "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        print_tokens += batch.ntokens\n",
        "\n",
        "        if model.training and i % print_every == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
        "                  (i, loss / batch.nseqs, print_tokens / elapsed))\n",
        "            start = time.time()\n",
        "            print_tokens = 0\n",
        "\n",
        "    return math.exp(total_loss / float(total_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749b1251-8616-40ac-944d-c75f8b511738",
      "metadata": {
        "id": "749b1251-8616-40ac-944d-c75f8b511738"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "36a7e7df-844d-42d1-b7d6-f1b44207ce70",
      "metadata": {
        "id": "36a7e7df-844d-42d1-b7d6-f1b44207ce70"
      },
      "outputs": [],
      "source": [
        "def train(model, num_epochs=10, lr=0.0003, print_every=100):\n",
        "    model.to(DEVICE)\n",
        "    \n",
        "    # implement\n",
        "    \n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_IDX)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_perplexities = []\n",
        "    dev_perplexities = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch\", epoch)\n",
        "        model.train()\n",
        "        train_perplexity = run_epoch((rebatch(PAD_IDX, b) for b in train_loader),\n",
        "                                     model,\n",
        "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
        "                                     print_every=print_every)\n",
        "        train_perplexities.append(train_perplexity)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print_examples((rebatch(PAD_IDX, x) for x in valid_loader),\n",
        "                           model, n=3, src_vocab=modern_vocab, trg_vocab=original_vocab)\n",
        "\n",
        "            dev_perplexity = run_epoch((rebatch(PAD_IDX, b) for b in valid_loader),\n",
        "                                       model,\n",
        "                                       SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
        "            dev_perplexities.append(dev_perplexity)\n",
        "\n",
        "    return train_perplexities, dev_perplexities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02fa4b0d-a4a7-4949-bae1-8b7b6de90ef3",
      "metadata": {
        "id": "02fa4b0d-a4a7-4949-bae1-8b7b6de90ef3"
      },
      "source": [
        "## Run and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "7b510dfd-6582-47f9-b5d6-ddd08f97d759",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7b510dfd-6582-47f9-b5d6-ddd08f97d759",
        "outputId": "1ae53637-3de5-4565-dd9a-cbf83352c1a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaspreet/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 100 Loss: 48.825207 Tokens per Sec: 14811.776733\n",
            "Epoch Step: 200 Loss: 52.991856 Tokens per Sec: 14548.230379\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  o , you are <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  if i am <UNK> , i am <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK> , and <UNK> <UNK>\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  <UNK> , <UNK> , and <UNK> <UNK> <UNK> , and <UNK> <UNK> <UNK> .\n",
            "\n",
            "Validation perplexity: 52.443038\n",
            "Epoch 1\n",
            "Epoch Step: 100 Loss: 38.747753 Tokens per Sec: 14093.805154\n",
            "Epoch Step: 200 Loss: 37.802784 Tokens per Sec: 14858.463540\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , you are not the <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she is if she was <UNK> , and <UNK> in the <UNK> of <UNK> , and <UNK> it be <UNK> .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  nay , she is <UNK> me , <UNK> , and <UNK> <UNK> the <UNK> .\n",
            "\n",
            "Validation perplexity: 35.838600\n",
            "Epoch 2\n",
            "Epoch Step: 100 Loss: 42.295570 Tokens per Sec: 13867.315727\n",
            "Epoch Step: 200 Loss: 37.273022 Tokens per Sec: 14342.625410\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , you are not <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were if she were <UNK> in the <UNK> of <UNK> , and i have been <UNK> that <UNK> <UNK> me .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  but she she <UNK> me <UNK> <UNK> than the <UNK> .\n",
            "\n",
            "Validation perplexity: 30.216586\n",
            "Epoch 3\n",
            "Epoch Step: 100 Loss: 30.848763 Tokens per Sec: 14060.456619\n",
            "Epoch Step: 200 Loss: 31.588936 Tokens per Sec: 14854.324680\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , you must be <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were if she were she had <UNK> , and be <UNK> to be <UNK> .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  <UNK> , she <UNK> me more than the <UNK> .\n",
            "\n",
            "Validation perplexity: 27.004630\n",
            "Epoch 4\n",
            "Epoch Step: 100 Loss: 31.376701 Tokens per Sec: 13510.654540\n",
            "Epoch Step: 200 Loss: 30.171150 Tokens per Sec: 14248.091582\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , thou liest , there is there on the <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were if she were <UNK> in the <UNK> , would be <UNK> in such a <UNK> .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  <UNK> , she <UNK> me more than the <UNK> <UNK> .\n",
            "\n",
            "Validation perplexity: 25.255335\n",
            "Epoch 5\n",
            "Epoch Step: 100 Loss: 24.966656 Tokens per Sec: 14203.307128\n",
            "Epoch Step: 200 Loss: 33.669090 Tokens per Sec: 13757.720965\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , you <UNK> there on the <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were if she were <UNK> in the <UNK> , would be <UNK> .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  besides , she <UNK> me more than the <UNK> .\n",
            "\n",
            "Validation perplexity: 24.526440\n",
            "Epoch 6\n",
            "Epoch Step: 100 Loss: 27.807158 Tokens per Sec: 13554.841330\n",
            "Epoch Step: 200 Loss: 24.305265 Tokens per Sec: 15181.799378\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , you <UNK> there on the <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were if she were <UNK> in such a <UNK> , would be a <UNK> that <UNK> me .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  besides , she <UNK> me more than <UNK> than the <UNK> .\n",
            "\n",
            "Validation perplexity: 23.748631\n",
            "Epoch 7\n",
            "Epoch Step: 100 Loss: 28.176632 Tokens per Sec: 14609.079358\n",
            "Epoch Step: 200 Loss: 22.874756 Tokens per Sec: 14549.637335\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , you lie there on the <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were if she were <UNK> , would be <UNK> that <UNK> me .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  besides , she <UNK> me more than the <UNK> .\n",
            "\n",
            "Validation perplexity: 23.538413\n",
            "Epoch 8\n",
            "Epoch Step: 100 Loss: 22.994947 Tokens per Sec: 15136.103762\n",
            "Epoch Step: 200 Loss: 26.021727 Tokens per Sec: 14807.372725\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , you lie there on the <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were if she were were in <UNK> , would be <UNK> in such a <UNK> .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  besides , she <UNK> me more than the other <UNK> of them .\n",
            "\n",
            "Validation perplexity: 23.506240\n",
            "Epoch 9\n",
            "Epoch Step: 100 Loss: 25.035748 Tokens per Sec: 14498.217651\n",
            "Epoch Step: 200 Loss: 25.638376 Tokens per Sec: 14485.950128\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the <UNK> .\n",
            "Trg :  lie thou there ( <UNK> down a letter ) , for here comes the <UNK> that must be caught with <UNK> .\n",
            "Pred:  now , you lie there , there is there on the <UNK> .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were <UNK> in someone , it would be someone who looked like me .\n",
            "Trg :  <UNK> once told me she did <UNK> me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were if she were <UNK> in such a <UNK> <UNK> , that she should be <UNK> in me .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she <UNK> me more <UNK> than the other servants .\n",
            "Trg :  besides , she <UNK> me with a more <UNK> respect than <UNK> else that follows her .\n",
            "Pred:  besides , she <UNK> me more than the other <UNK> .\n",
            "\n",
            "Validation perplexity: 24.004337\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = make_model(len(modern_vocab), len(original_vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "train_perplexities, dev_perplexities = train(model, num_epochs=10, print_every=100)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_perplexity(perplexities):\n",
        "    #implement\n",
        "    plt.title(\"Perplexity for each Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Perplexity\")\n",
        "    plt.plot(perplexities)\n",
        "\n",
        "plot_perplexity(train_perplexities)\n",
        "plot_perplexity(dev_perplexities)\n",
        "\n",
        "def test():\n",
        "    style_transferred_sent = []\n",
        "    alphas = []  # save the last attention scores\n",
        "    for batch in test_loader:\n",
        "        batch = rebatch(PAD_IDX, batch)\n",
        "        pred, attention = greedy_decode(\n",
        "            model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "            sos_index=modern_vocab.stoi['<SOS>'],\n",
        "            eos_index=original_vocab.stoi['<EOS>'])\n",
        "        style_transferred_sent.append(pred)\n",
        "        alphas.append(attention)\n",
        "    return style_transferred_sent\n",
        "\n",
        "style_transferred_sent = test()\n",
        "style_transferred_sent = [lookup_words(x, original_vocab) for x in style_transferred_sent]\n",
        "style_transferred_sent = [\" \".join(x) for x in style_transferred_sent]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ad4b8c96",
      "metadata": {},
      "source": [
        "## Training Model without unknown tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "10c2ec65",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 100 Loss: 48.483326 Tokens per Sec: 15755.261656\n",
            "Epoch Step: 200 Loss: 43.292500 Tokens per Sec: 14471.206488\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  why , you , you are the .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  he is it is it is it is it , i will not be .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  why , i am me , i will not the .\n",
            "\n",
            "Validation perplexity: 58.687620\n",
            "Epoch 1\n",
            "Epoch Step: 100 Loss: 41.626564 Tokens per Sec: 14736.757943\n",
            "Epoch Step: 200 Loss: 37.815865 Tokens per Sec: 14677.418852\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now , thou art thou the .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she is it , and i have it be , and be not be so .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  i am she me , for the of the of the of the of the of the of the .\n",
            "\n",
            "Validation perplexity: 40.010486\n",
            "Epoch 2\n",
            "Epoch Step: 100 Loss: 44.095337 Tokens per Sec: 14981.243575\n",
            "Epoch Step: 200 Loss: 40.949764 Tokens per Sec: 14312.273377\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now , you are you .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she is she she , and it be so .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  i pray you , and i have more than the .\n",
            "\n",
            "Validation perplexity: 33.549868\n",
            "Epoch 3\n",
            "Epoch Step: 100 Loss: 37.229443 Tokens per Sec: 14391.716758\n",
            "Epoch Step: 200 Loss: 38.595470 Tokens per Sec: 14016.135069\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now now , you are not the .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she had so she were in the , and so it be so much .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  my lord , she me more than the .\n",
            "\n",
            "Validation perplexity: 30.769062\n",
            "Epoch 4\n",
            "Epoch Step: 100 Loss: 34.945816 Tokens per Sec: 15144.730325\n",
            "Epoch Step: 200 Loss: 34.432495 Tokens per Sec: 13147.567571\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now , you are not .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she had she were in the , if it were it .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  besides , she me more than the .\n",
            "\n",
            "Validation perplexity: 28.388750\n",
            "Epoch 5\n",
            "Epoch Step: 100 Loss: 29.775606 Tokens per Sec: 14092.191535\n",
            "Epoch Step: 200 Loss: 36.406563 Tokens per Sec: 13858.803057\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now , you are not the .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she were not , she were it , that would be so much .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  besides , she me more than the other .\n",
            "\n",
            "Validation perplexity: 27.333532\n",
            "Epoch 6\n",
            "Epoch Step: 100 Loss: 26.520262 Tokens per Sec: 14423.137841\n",
            "Epoch Step: 200 Loss: 29.015379 Tokens per Sec: 14907.419720\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now , you lie with the .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she said , she were in the world , it should be so much .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  besides , she me more than the .\n",
            "\n",
            "Validation perplexity: 26.522970\n",
            "Epoch 7\n",
            "Epoch Step: 100 Loss: 32.555473 Tokens per Sec: 14041.830884\n",
            "Epoch Step: 200 Loss: 30.611431 Tokens per Sec: 15227.506819\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now , thou liest .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she said , she were in , and would be so much .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  besides , she more than the other .\n",
            "\n",
            "Validation perplexity: 26.207148\n",
            "Epoch 8\n",
            "Epoch Step: 100 Loss: 28.594416 Tokens per Sec: 15834.837634\n",
            "Epoch Step: 200 Loss: 24.727100 Tokens per Sec: 15263.326943\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now , you lie with the .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she said , she were in the of it , and so should be so much .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  besides , she me more than the .\n",
            "\n",
            "Validation perplexity: 26.831650\n",
            "Epoch 9\n",
            "Epoch Step: 100 Loss: 23.614107 Tokens per Sec: 13947.672922\n",
            "Epoch Step: 200 Loss: 27.673452 Tokens per Sec: 14297.708432\n",
            "\n",
            "Example #1\n",
            "Src :  <SOS> now , you lie there on the .\n",
            "Trg :  lie thou there ( down a letter ) , for here comes the that must be caught with .\n",
            "Pred:  now , thou liest .\n",
            "\n",
            "Example #2\n",
            "Src :  <SOS> she said if she were in someone , it would be someone who looked like me .\n",
            "Trg :  once told me she did me , and i have heard herself come thus near , that , should she fancy , it should be one of my complexion .\n",
            "Pred:  she said , she were in an hour , would it were so much .\n",
            "\n",
            "Example #3\n",
            "Src :  <SOS> besides , she me more than the other servants .\n",
            "Trg :  besides , she me with a more respect than else that follows her .\n",
            "Pred:  besides , she me more than the other .\n",
            "\n",
            "Validation perplexity: 27.214276\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "numericalized_train = numericalize(train_sents,remove_unk=True)\n",
        "numericalized_valid = numericalize(valid_sents,remove_unk=True)\n",
        "numericalized_test = numericalize(test_sents,remove_unk=True)\n",
        "\n",
        "train_dataset = StyleTransferDataset(numericalized_train, modern_vocab, original_vocab)\n",
        "valid_dataset = StyleTransferDataset(numericalized_valid, modern_vocab, original_vocab)\n",
        "test_dataset = StyleTransferDataset(numericalized_test, modern_vocab, original_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True,\n",
        "                          collate_fn=MyCollate(pad_idx=PAD_IDX))\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=valid_batch_size, shuffle=False,\n",
        "                          collate_fn=MyCollate(pad_idx=PAD_IDX))\n",
        "test_loader = DataLoader(test_dataset, batch_size=valid_batch_size, shuffle=False,\n",
        "                         collate_fn=MyCollate(pad_idx=PAD_IDX))\n",
        "\n",
        "model = make_model(len(modern_vocab), len(original_vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "train_perplexities, dev_perplexities = train(model, num_epochs=10, print_every=100)\n",
        "\n",
        "plot_perplexity(train_perplexities)\n",
        "plot_perplexity(dev_perplexities)\n",
        "\n",
        "def test():\n",
        "    style_transferred_sent = []\n",
        "    alphas = []  # save the last attention scores\n",
        "    for batch in test_loader:\n",
        "        batch = rebatch(PAD_IDX, batch)\n",
        "        pred, attention = greedy_decode(\n",
        "            model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "            sos_index=modern_vocab.stoi['<SOS>'],\n",
        "            eos_index=original_vocab.stoi['<EOS>'])\n",
        "        style_transferred_sent.append(pred)\n",
        "        alphas.append(attention)\n",
        "    return style_transferred_sent\n",
        "\n",
        "style_transferred_sent = test()\n",
        "style_transferred_sent = [lookup_words(x, original_vocab) for x in style_transferred_sent]\n",
        "style_transferred_sent = [\" \".join(x) for x in style_transferred_sent]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d69202b-bef7-46df-8fed-d8ae066477a6",
      "metadata": {
        "id": "2d69202b-bef7-46df-8fed-d8ae066477a6"
      },
      "source": [
        "## Save output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "0a3fb133-0720-4ef2-aa36-8a03f3072256",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a3fb133-0720-4ef2-aa36-8a03f3072256",
        "outputId": "6408be06-d6ae-4ce7-bcf5-1f12f8cfe43b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1350\n"
          ]
        }
      ],
      "source": [
        "#implement save to file \n",
        "print(len(style_transferred_sent))\n",
        "with open('style_transferred_sent.txt', 'w') as f:\n",
        "    for line in style_transferred_sent:\n",
        "        f.write(line)\n",
        "        f.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b9de7f8-7391-4452-8f4e-2027bd0de728",
      "metadata": {
        "id": "1b9de7f8-7391-4452-8f4e-2027bd0de728"
      },
      "source": [
        "## Evaluate the output using BLEU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "FEQuEauaibXk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEQuEauaibXk",
        "outputId": "c4713c02-6345-498d-b97d-ddd10776f4f6"
      },
      "outputs": [],
      "source": [
        "# !pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "371af43c-2e75-4e48-a3dd-b2ecdac15992",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "371af43c-2e75-4e48-a3dd-b2ecdac15992",
        "outputId": "e5e0348b-acb6-4de0-98fa-c6ab0039ce79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU = 7.75 72.7/5.6/3.6/2.5 (BP = 1.000 ratio = 2.750 hyp_len = 11 ref_len = 4)\n"
          ]
        }
      ],
      "source": [
        "from sacrebleu.metrics import BLEU\n",
        "\n",
        "bleu = BLEU()\n",
        "\n",
        "#BLEU metric \n",
        "temp = filter_lines(test_original_sents, MAX_LEN) # removing UNK tokens \n",
        "\n",
        "result = bleu.corpus_score(style_transferred_sent, temp)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lOEkenU5jjBM",
      "metadata": {
        "id": "lOEkenU5jjBM"
      },
      "source": [
        " LSTM-RNNs can perform better than encoder-decoder\n",
        "architectures for style transfer because they are\n",
        "able to capture long-term dependencies in the data.\n",
        "This means that they can better capture the nuances\n",
        "of the style being transferred, allowing for more\n",
        "accurate and detailed style transfer. Additionally,\n",
        "LSTM-RNNs are able to learn from the data in an\n",
        "unsupervised manner, meaning that they can learn\n",
        "from the data without the need for labeled data.\n",
        "This makes them more efficient and effective than\n",
        "encoder-decoder architectures, which require labeled\n",
        "data for training."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ff29ac03daff1520ad4db205576eb60a0bef263ceae411ab8bd5552b57cbc1fd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
